{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "389a2c00-fa75-4b05-b117-3f7549d75c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)\n",
    "import joblib\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "raw",
   "id": "66c2e3ee-7642-4d80-b5a1-fc68910f4812",
   "metadata": {},
   "source": [
    "engine = create_engine(f\"postgresql+psycopg2://postgres:{os.getenv('POSTGRES_PASSWORD')}@localhost:5432/movie_recommendation\")\n",
    "conn = engine.connect()\n",
    "\n",
    "ratings = pl.read_database(query='SELECT * FROM raw.ratings ORDER BY RANDOM() LIMIT 2000000', connection=conn)\n",
    "movies = pl.read_database(query='SELECT * FROM raw.movies', connection=conn)\n",
    "conn.close()\n",
    "\n",
    "conn = engine.connect()\n",
    "ratings.write_database(\n",
    "    table_name=\"data_lake.ratings\",\n",
    "    connection=conn,\n",
    ")\n",
    "\n",
    "print(\"Uspesno upisani redovi\")\n",
    "\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "75de5585-934a-44db-8807-b16907436c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 8.09 s\n",
      "Wall time: 11.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "engine = create_engine(f\"postgresql+psycopg2://postgres:{os.getenv('POSTGRES_PASSWORD')}@localhost:5432/movie_recommendation\")\n",
    "conn = engine.connect()\n",
    "ratings = pl.read_database(query='SELECT * FROM data_lake.ratings', connection=conn)\n",
    "movies = pl.read_database(query='SELECT * FROM raw.movies', connection=conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f53652eb-ce9e-4490-a7ca-576c8bfe88a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2_000_000, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>userid</th><th>movieid</th><th>rating</th></tr><tr><td>i64</td><td>i64</td><td>f64</td></tr></thead><tbody><tr><td>65836</td><td>92259</td><td>5.0</td></tr><tr><td>199922</td><td>1653</td><td>4.5</td></tr><tr><td>28788</td><td>3408</td><td>3.0</td></tr><tr><td>3003</td><td>3949</td><td>4.5</td></tr><tr><td>137418</td><td>2840</td><td>3.0</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>185104</td><td>5989</td><td>3.5</td></tr><tr><td>115669</td><td>2858</td><td>4.0</td></tr><tr><td>73865</td><td>1924</td><td>3.0</td></tr><tr><td>90990</td><td>497</td><td>5.0</td></tr><tr><td>153783</td><td>52</td><td>4.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2_000_000, 3)\n",
       "┌────────┬─────────┬────────┐\n",
       "│ userid ┆ movieid ┆ rating │\n",
       "│ ---    ┆ ---     ┆ ---    │\n",
       "│ i64    ┆ i64     ┆ f64    │\n",
       "╞════════╪═════════╪════════╡\n",
       "│ 65836  ┆ 92259   ┆ 5.0    │\n",
       "│ 199922 ┆ 1653    ┆ 4.5    │\n",
       "│ 28788  ┆ 3408    ┆ 3.0    │\n",
       "│ 3003   ┆ 3949    ┆ 4.5    │\n",
       "│ 137418 ┆ 2840    ┆ 3.0    │\n",
       "│ …      ┆ …       ┆ …      │\n",
       "│ 185104 ┆ 5989    ┆ 3.5    │\n",
       "│ 115669 ┆ 2858    ┆ 4.0    │\n",
       "│ 73865  ┆ 1924    ┆ 3.0    │\n",
       "│ 90990  ┆ 497     ┆ 5.0    │\n",
       "│ 153783 ┆ 52      ┆ 4.0    │\n",
       "└────────┴─────────┴────────┘"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5a612fe0-3041-4389-b948-ac8b99e5a4f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (9, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>statistic</th><th>rating</th></tr><tr><td>str</td><td>f64</td></tr></thead><tbody><tr><td>&quot;count&quot;</td><td>2e6</td></tr><tr><td>&quot;null_count&quot;</td><td>0.0</td></tr><tr><td>&quot;mean&quot;</td><td>3.540351</td></tr><tr><td>&quot;std&quot;</td><td>1.059335</td></tr><tr><td>&quot;min&quot;</td><td>0.5</td></tr><tr><td>&quot;25%&quot;</td><td>3.0</td></tr><tr><td>&quot;50%&quot;</td><td>3.5</td></tr><tr><td>&quot;75%&quot;</td><td>4.0</td></tr><tr><td>&quot;max&quot;</td><td>5.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (9, 2)\n",
       "┌────────────┬──────────┐\n",
       "│ statistic  ┆ rating   │\n",
       "│ ---        ┆ ---      │\n",
       "│ str        ┆ f64      │\n",
       "╞════════════╪══════════╡\n",
       "│ count      ┆ 2e6      │\n",
       "│ null_count ┆ 0.0      │\n",
       "│ mean       ┆ 3.540351 │\n",
       "│ std        ┆ 1.059335 │\n",
       "│ min        ┆ 0.5      │\n",
       "│ 25%        ┆ 3.0      │\n",
       "│ 50%        ┆ 3.5      │\n",
       "│ 75%        ┆ 4.0      │\n",
       "│ max        ┆ 5.0      │\n",
       "└────────────┴──────────┘"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.describe()[['statistic', 'rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d0bc37d4-0621-4a60-9d1d-28ef98936e67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (87_585, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>movieid</th><th>title</th><th>genres</th></tr><tr><td>i64</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>1</td><td>&quot;Toy Story (1995)&quot;</td><td>&quot;Adventure|Animation|Children|C…</td></tr><tr><td>2</td><td>&quot;Jumanji (1995)&quot;</td><td>&quot;Adventure|Children|Fantasy&quot;</td></tr><tr><td>3</td><td>&quot;Grumpier Old Men (1995)&quot;</td><td>&quot;Comedy|Romance&quot;</td></tr><tr><td>4</td><td>&quot;Waiting to Exhale (1995)&quot;</td><td>&quot;Comedy|Drama|Romance&quot;</td></tr><tr><td>5</td><td>&quot;Father of the Bride Part II (1…</td><td>&quot;Comedy&quot;</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>292731</td><td>&quot;The Monroy Affaire (2022)&quot;</td><td>&quot;Drama&quot;</td></tr><tr><td>292737</td><td>&quot;Shelter in Solitude (2023)&quot;</td><td>&quot;Comedy|Drama&quot;</td></tr><tr><td>292753</td><td>&quot;Orca (2023)&quot;</td><td>&quot;Drama&quot;</td></tr><tr><td>292755</td><td>&quot;The Angry Breed (1968)&quot;</td><td>&quot;Drama&quot;</td></tr><tr><td>292757</td><td>&quot;Race to the Summit (2023)&quot;</td><td>&quot;Action|Adventure|Documentary&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (87_585, 3)\n",
       "┌─────────┬─────────────────────────────────┬─────────────────────────────────┐\n",
       "│ movieid ┆ title                           ┆ genres                          │\n",
       "│ ---     ┆ ---                             ┆ ---                             │\n",
       "│ i64     ┆ str                             ┆ str                             │\n",
       "╞═════════╪═════════════════════════════════╪═════════════════════════════════╡\n",
       "│ 1       ┆ Toy Story (1995)                ┆ Adventure|Animation|Children|C… │\n",
       "│ 2       ┆ Jumanji (1995)                  ┆ Adventure|Children|Fantasy      │\n",
       "│ 3       ┆ Grumpier Old Men (1995)         ┆ Comedy|Romance                  │\n",
       "│ 4       ┆ Waiting to Exhale (1995)        ┆ Comedy|Drama|Romance            │\n",
       "│ 5       ┆ Father of the Bride Part II (1… ┆ Comedy                          │\n",
       "│ …       ┆ …                               ┆ …                               │\n",
       "│ 292731  ┆ The Monroy Affaire (2022)       ┆ Drama                           │\n",
       "│ 292737  ┆ Shelter in Solitude (2023)      ┆ Comedy|Drama                    │\n",
       "│ 292753  ┆ Orca (2023)                     ┆ Drama                           │\n",
       "│ 292755  ┆ The Angry Breed (1968)          ┆ Drama                           │\n",
       "│ 292757  ┆ Race to the Summit (2023)       ┆ Action|Adventure|Documentary    │\n",
       "└─────────┴─────────────────────────────────┴─────────────────────────────────┘"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "65bc5be4-07c9-4e77-8d0d-e4baafec2a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_pipeline(user, movies):\n",
    "    #PROSECAN BROJ OCENA PO FILMU\n",
    "    num_ratings = ratings.group_by('movieid').agg(pl.len().alias('#ratings_film')).filter(pl.col('#ratings_film') > 40)\n",
    "    user = ratings.join(num_ratings, on = 'movieid', how = 'inner').sort(['movieid', 'userid'])\n",
    "    movies = movies.with_columns(pl.col(\"genres\").str.split(\"|\"))\n",
    "    unique_genres = sorted(set(g for genre_list in movies[\"genres\"] for g in genre_list))\n",
    "    #LAZY!\n",
    "    user = user.lazy()\n",
    "    movies = movies.lazy()\n",
    "    #SVI ZANROVI\n",
    "    for genre in unique_genres:\n",
    "        movies = movies.with_columns(pl.col(\"genres\").list.contains(genre).cast(pl.Int8).alias(genre))\n",
    "    movies = movies.drop('genres')\n",
    "    #KOLONA GODINA\n",
    "    movies = movies.with_columns(pl.col(\"title\").str.extract(r\"\\((\\d{4})\\)\", 1).cast(pl.Int16).alias(\"year\"))\n",
    "    movies =movies.select(['movieid', 'title', 'year', *unique_genres])\n",
    "    \n",
    "    #ISTI FORMAT TABELE KAO MOVIES\n",
    "    user_zanr_train = user.join(movies, on='movieid', how='inner')\n",
    "    \n",
    "    #PIVOT LONGER --> ZANROVE PREBACUJEM U JEDNU KOLONU\n",
    "    user_longer = (user_zanr_train.unpivot(index=['userid', 'rating'],\n",
    "                                           on=unique_genres).filter(pl.col('value') == 1).rename({'variable': 'genre', 'value': 'is_genre'}))\n",
    "    \n",
    "    #RACUNAM PROSEK ZA SVAKOG USERA ZA SVAKI ZANR I VRACAM U WIDE FORMAT\n",
    "    user_feature = user_longer.group_by('userid').agg([(pl.when(pl.col('genre') == genre).then(pl.col('rating'))\n",
    "                                                        .otherwise(None).mean().alias(genre)) for genre in unique_genres]).fill_null(0)\n",
    "    movie_avg_rating = (user.group_by('movieid').agg(pl.col('rating').mean().alias('avg_rating')))\n",
    "    movie_features = movies.join(movie_avg_rating, on='movieid', how='left').fill_null(0)\n",
    "    movie_features = movie_features.select(['movieid', 'title','year','avg_rating', *unique_genres])\n",
    "    df = user.join(user_feature, on=\"userid\", how=\"inner\").join(movie_features, on=\"movieid\", how=\"inner\")\n",
    "    df = df.collect()\n",
    "    movie_features = movie_features.rename({\"(no genres listed)\": \"no genres listed\"})\n",
    "    user_feature = user_feature.rename({\"(no genres listed)\": \"no genres listed\"})\n",
    "    df = df.rename({\"(no genres listed)\": \"no genres listed\"})\n",
    "\n",
    "    return user_feature.collect(), movie_features.collect(), df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "930a7e24-361f-497f-8c03-be49add25531",
   "metadata": {},
   "outputs": [],
   "source": [
    "user, movies, df =  prep_pipeline(ratings, movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9201deb4-de29-4064-84d4-41b650fc5ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb9508c-144e-44aa-bb45-dc4a7644a771",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2fb4b3-147f-4870-967d-81ea94eab61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6a2ebd18-3ecc-4187-b88c-990ad9d9b30d",
   "metadata": {},
   "source": [
    "engine = create_engine(f\"postgresql+psycopg2://postgres:{os.getenv('POSTGRES_PASSWORD')}@localhost:5432/movie_recommendation\")\n",
    "conn = engine.connect()\n",
    "user.write_database(table_name=\"data_storage.ratings\", connection=conn, if_table_exists= 'append')\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9745683a-31bc-4792-adf3-3b213951df35",
   "metadata": {},
   "source": [
    "conn = engine.connect()\n",
    "movies.write_database(table_name=\"data_storage.movies\", connection=conn, if_table_exists= 'append')\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2845df0a-7950-416d-bd88-98247eef5741",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "91d4e9f8-e804-4e4b-80a1-09f6b0ae1807",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_prep(df):\n",
    "    # #U NUMPY I SKALIRANJE\n",
    "    \n",
    "    y = df.select(pl.col('rating')).to_numpy()\n",
    "    X_user = df.select(user.select(pl.exclude('userid')).columns)\n",
    "    X_movie = df.select(movies.select(pl.exclude(['movieid','title'])).columns + ['#ratings_film'])\n",
    "    SS_movie = StandardScaler()\n",
    "    SS_user = StandardScaler()\n",
    "    SS_target = MinMaxScaler((-1,1))\n",
    "    movie_num = SS_movie.fit_transform(X_movie['#ratings_film', 'year', 'avg_rating'])\n",
    "    movie_cat = X_movie.select(pl.all().exclude(['#ratings_film', 'year', 'avg_rating'])).to_numpy()\n",
    "    X_movie_numpy = np.column_stack([movie_num,movie_cat])\n",
    "    X_user_numpy = SS_user.fit_transform(X_user)\n",
    "    y = SS_target.fit_transform(y)\n",
    "    return X_user_numpy, X_movie_numpy, y, SS_movie, SS_user, SS_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "3d0d7fb9-f95e-4954-91ad-66a1c2807f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_user_numpy, X_movie_numpy, y, SS_movie, SS_user, SS_target = NN_prep(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "4beb12bc-192c-48e8-83b2-1e44f6c2d699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1840589, 20),\n",
       " (1840589, 23),\n",
       " (1840589, 1),\n",
       " array(['#ratings_film', 'year', 'avg_rating'], dtype=object),\n",
       " array(['no genres listed', 'Action', 'Adventure', 'Animation', 'Children',\n",
       "        'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir',\n",
       "        'Horror', 'IMAX', 'Musical', 'Mystery', 'Romance', 'Sci-Fi',\n",
       "        'Thriller', 'War', 'Western'], dtype=object),\n",
       " (-1, 1))"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_user_numpy.shape, X_movie_numpy.shape, y.shape, SS_movie.feature_names_in_, SS_user.feature_names_in_,SS_target.feature_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "c1521e71-bfca-4646-816c-aadb855855a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.column_stack([X_user_numpy, X_movie_numpy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "31689f85-a0f1-460d-a4d5-c9606ebec7a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1840589, 43), (1840589, 1))"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "6686e028-10d1-409a-b162-ad17640b7b16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.55555556,  0.33333333,  0.55555556, ...,  0.77777778,\n",
       "        0.55555556, -0.33333333])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.reshape(-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "f8b6876c-80d3-4a24-96c5-27f5fb4c243d",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "4331c17f-3d9a-40a1-b44b-e186d157a9b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LinearRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LinearRegression()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.fit(X, y.reshape(-1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "0060cc12-3a2b-40be-81ba-022db49879e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = reg.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "1e7ee8fb-336b-49a9-8e02-3e654de0e0d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.15952552492599298, 0.3067778177294631)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(pred, y), mean_absolute_error(pred, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2e9ff6-8a31-471d-b2af-9246348a58e1",
   "metadata": {},
   "source": [
    "### NN COLABORATIVE FILTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "69768752-22ba-460c-a61c-7cca85195d22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_7\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_7\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ item_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_79 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">420</span> │ user_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_80 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">480</span> │ item_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lambda_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_79[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lambda_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_80[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ cosine_similarity (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lambda_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],            │\n",
       "│                               │                           │                 │ lambda_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_input (\u001b[38;5;33mInputLayer\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ item_input (\u001b[38;5;33mInputLayer\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_79 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                │             \u001b[38;5;34m420\u001b[0m │ user_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_80 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                │             \u001b[38;5;34m480\u001b[0m │ item_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lambda_2 (\u001b[38;5;33mLambda\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_79[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lambda_3 (\u001b[38;5;33mLambda\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_80[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ cosine_similarity (\u001b[38;5;33mDot\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │ lambda_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],            │\n",
       "│                               │                           │                 │ lambda_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">900</span> (3.52 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m900\u001b[0m (3.52 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">900</span> (3.52 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m900\u001b[0m (3.52 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_user_features = X_user_numpy.shape[1]\n",
    "num_item_features = X_movie_numpy.shape[1]\n",
    "num_outputs = 20\n",
    "\n",
    "# ---------------- USER MODEL ----------------\n",
    "user_input = keras.Input(shape=(num_user_features,), name='user_input')\n",
    "x_user = layers.Dense(num_outputs, activation='relu')(user_input)\n",
    "user_embedding = layers.Lambda(lambda x: tf.nn.l2_normalize(x, axis=1))(x_user)\n",
    "\n",
    "# ---------------- ITEM MODEL ----------------\n",
    "item_input = keras.Input(shape=(num_item_features,), name='item_input')\n",
    "x_item = layers.Dense(num_outputs, activation='relu')(item_input)\n",
    "item_embedding = layers.Lambda(lambda x: tf.nn.l2_normalize(x, axis=1))(x_item)\n",
    "\n",
    "# ---------------- COSINE SIMILARITY ----------------\n",
    "cos_sim = layers.Dot(axes=1, name='cosine_similarity')([user_embedding, item_embedding])\n",
    "# rezultat je u [-1, 1]\n",
    "\n",
    "# ---------------- FINAL MODEL ----------------\n",
    "model = keras.Model(inputs=[user_input, item_input], outputs=cos_sim)\n",
    "\n",
    "# Kompajliraj model\n",
    "model.compile(optimizer= keras.optimizers.Nadam(learning_rate= 0.01), loss='mse', metrics=['mae', 'mse'])\n",
    "\n",
    "# Prikaži arhitekturu\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "a942d04b-0d64-42dc-b597-2c7e5f183274",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_user_train, X_user_dev, X_movie_train, X_movie_dev, y_train, y_dev = train_test_split(X_user_numpy, X_movie_numpy,\n",
    "                                                                                        y, test_size=0.15, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "bf678ec2-a480-4eac-8346-46965c0d561d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1564500, 1)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "87f0f64f-5820-40b0-8f8b-48fc1cf6a8e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.1430 - mae: 0.2857 - mse: 0.1430 - val_loss: 0.1417 - val_mae: 0.2855 - val_mse: 0.1417\n",
      "Epoch 2/30\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.1413 - mae: 0.2837 - mse: 0.1413 - val_loss: 0.1414 - val_mae: 0.2832 - val_mse: 0.1414\n",
      "Epoch 3/30\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1409 - mae: 0.2836 - mse: 0.1409 - val_loss: 0.1410 - val_mae: 0.2849 - val_mse: 0.1410\n",
      "Epoch 4/30\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.1407 - mae: 0.2833 - mse: 0.1407 - val_loss: 0.1407 - val_mae: 0.2844 - val_mse: 0.1407\n",
      "Epoch 5/30\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1405 - mae: 0.2830 - mse: 0.1405 - val_loss: 0.1407 - val_mae: 0.2848 - val_mse: 0.1407\n",
      "Epoch 6/30\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1405 - mae: 0.2831 - mse: 0.1405 - val_loss: 0.1405 - val_mae: 0.2841 - val_mse: 0.1405\n",
      "Epoch 7/30\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1398 - mae: 0.2823 - mse: 0.1398 - val_loss: 0.1403 - val_mae: 0.2835 - val_mse: 0.1403\n",
      "Epoch 8/30\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1398 - mae: 0.2823 - mse: 0.1398 - val_loss: 0.1407 - val_mae: 0.2850 - val_mse: 0.1407\n",
      "Epoch 9/30\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1396 - mae: 0.2820 - mse: 0.1396 - val_loss: 0.1401 - val_mae: 0.2819 - val_mse: 0.1401\n",
      "Epoch 10/30\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1397 - mae: 0.2820 - mse: 0.1397 - val_loss: 0.1398 - val_mae: 0.2820 - val_mse: 0.1398\n",
      "Epoch 11/30\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.1397 - mae: 0.2822 - mse: 0.1397 - val_loss: 0.1402 - val_mae: 0.2845 - val_mse: 0.1402\n",
      "Epoch 12/30\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1396 - mae: 0.2822 - mse: 0.1396 - val_loss: 0.1400 - val_mae: 0.2821 - val_mse: 0.1400\n",
      "Epoch 13/30\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1395 - mae: 0.2820 - mse: 0.1395 - val_loss: 0.1398 - val_mae: 0.2825 - val_mse: 0.1398\n",
      "Epoch 14/30\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1393 - mae: 0.2820 - mse: 0.1393 - val_loss: 0.1396 - val_mae: 0.2825 - val_mse: 0.1396\n",
      "Epoch 15/30\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1394 - mae: 0.2819 - mse: 0.1394 - val_loss: 0.1395 - val_mae: 0.2820 - val_mse: 0.1395\n",
      "Epoch 16/30\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1394 - mae: 0.2818 - mse: 0.1394 - val_loss: 0.1396 - val_mae: 0.2828 - val_mse: 0.1396\n",
      "Epoch 17/30\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1390 - mae: 0.2814 - mse: 0.1390 - val_loss: 0.1394 - val_mae: 0.2822 - val_mse: 0.1394\n",
      "Epoch 18/30\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1393 - mae: 0.2816 - mse: 0.1393 - val_loss: 0.1395 - val_mae: 0.2815 - val_mse: 0.1395\n",
      "Epoch 19/30\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1393 - mae: 0.2817 - mse: 0.1393 - val_loss: 0.1394 - val_mae: 0.2817 - val_mse: 0.1394\n",
      "Epoch 20/30\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1391 - mae: 0.2816 - mse: 0.1391 - val_loss: 0.1394 - val_mae: 0.2819 - val_mse: 0.1394\n",
      "Epoch 21/30\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1392 - mae: 0.2815 - mse: 0.1392 - val_loss: 0.1394 - val_mae: 0.2819 - val_mse: 0.1394\n",
      "Epoch 22/30\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1392 - mae: 0.2816 - mse: 0.1392 - val_loss: 0.1394 - val_mae: 0.2820 - val_mse: 0.1394\n",
      "Epoch 23/30\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1392 - mae: 0.2814 - mse: 0.1392 - val_loss: 0.1393 - val_mae: 0.2818 - val_mse: 0.1393\n",
      "Epoch 24/30\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1391 - mae: 0.2815 - mse: 0.1391 - val_loss: 0.1393 - val_mae: 0.2823 - val_mse: 0.1393\n",
      "Epoch 25/30\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1391 - mae: 0.2815 - mse: 0.1391 - val_loss: 0.1393 - val_mae: 0.2818 - val_mse: 0.1393\n",
      "Epoch 26/30\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1389 - mae: 0.2813 - mse: 0.1389 - val_loss: 0.1394 - val_mae: 0.2815 - val_mse: 0.1394\n",
      "Epoch 27/30\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1393 - mae: 0.2817 - mse: 0.1393 - val_loss: 0.1394 - val_mae: 0.2812 - val_mse: 0.1394\n",
      "Epoch 28/30\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.1387 - mae: 0.2811 - mse: 0.1387 - val_loss: 0.1392 - val_mae: 0.2815 - val_mse: 0.1392\n",
      "Epoch 29/30\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1388 - mae: 0.2812 - mse: 0.1388 - val_loss: 0.1396 - val_mae: 0.2816 - val_mse: 0.1396\n",
      "Epoch 30/30\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1389 - mae: 0.2813 - mse: 0.1389 - val_loss: 0.1394 - val_mae: 0.2828 - val_mse: 0.1394\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=[X_user_train, X_movie_train],y=y_train,\n",
    "    validation_data=([X_user_dev, X_movie_dev], y_dev),epochs=30, batch_size=512, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "29375b2e-f95c-4d7c-8864-2ef6f0613c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True,)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-6, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "86ebbb71-7f59-4eab-ac85-17af426b822b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_9\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_9\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ item_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_83 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">672</span> │ user_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_84 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> │ item_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lambda_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_83[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lambda_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_84[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ cosine_similarity (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lambda_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],            │\n",
       "│                               │                           │                 │ lambda_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_input (\u001b[38;5;33mInputLayer\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ item_input (\u001b[38;5;33mInputLayer\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_83 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │             \u001b[38;5;34m672\u001b[0m │ user_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_84 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │             \u001b[38;5;34m768\u001b[0m │ item_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lambda_6 (\u001b[38;5;33mLambda\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_83[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lambda_7 (\u001b[38;5;33mLambda\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_84[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ cosine_similarity (\u001b[38;5;33mDot\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │ lambda_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],            │\n",
       "│                               │                           │                 │ lambda_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,440</span> (5.62 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,440\u001b[0m (5.62 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,440</span> (5.62 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,440\u001b[0m (5.62 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_user_features = X_user_numpy.shape[1]\n",
    "num_item_features = X_movie_numpy.shape[1]\n",
    "num_outputs = 32\n",
    "\n",
    "# ---------------- USER MODEL ----------------\n",
    "user_input = keras.Input(shape=(num_user_features,), name='user_input')\n",
    "x_user = layers.Dense(num_outputs, activation='relu', kernel_initializer='he_normal')(user_input)\n",
    "user_embedding = layers.Lambda(lambda x: tf.nn.l2_normalize(x, axis=1))(x_user)\n",
    "\n",
    "# ---------------- ITEM MODEL ----------------\n",
    "item_input = keras.Input(shape=(num_item_features,), name='item_input')\n",
    "x_item = layers.Dense(num_outputs, activation='relu', kernel_initializer='he_normal')(item_input)\n",
    "item_embedding = layers.Lambda(lambda x: tf.nn.l2_normalize(x, axis=1))(x_item)\n",
    "\n",
    "# ---------------- COSINE SIMILARITY ----------------\n",
    "cos_sim = layers.Dot(axes=1, name='cosine_similarity')([user_embedding, item_embedding])\n",
    "# rezultat je u [-1, 1]\n",
    "\n",
    "# ---------------- FINAL MODEL ----------------\n",
    "model = keras.Model(inputs=[user_input, item_input], outputs=cos_sim)\n",
    "\n",
    "# Kompajliraj model\n",
    "model.compile(optimizer= keras.optimizers.Nadam(learning_rate= 0.01), loss='mse', metrics=['mae', 'mse'])\n",
    "\n",
    "# Prikaži arhitekturu\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "7d5b2610-eff5-49ae-8ef9-3a9122ac93bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.1498 - mae: 0.2937 - mse: 0.1498 - val_loss: 0.1422 - val_mae: 0.2864 - val_mse: 0.1422 - learning_rate: 0.0100\n",
      "Epoch 2/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1416 - mae: 0.2839 - mse: 0.1416 - val_loss: 0.1408 - val_mae: 0.2832 - val_mse: 0.1408 - learning_rate: 0.0100\n",
      "Epoch 3/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1404 - mae: 0.2830 - mse: 0.1404 - val_loss: 0.1404 - val_mae: 0.2831 - val_mse: 0.1404 - learning_rate: 0.0100\n",
      "Epoch 4/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1404 - mae: 0.2828 - mse: 0.1404 - val_loss: 0.1402 - val_mae: 0.2828 - val_mse: 0.1402 - learning_rate: 0.0100\n",
      "Epoch 5/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1397 - mae: 0.2822 - mse: 0.1397 - val_loss: 0.1400 - val_mae: 0.2826 - val_mse: 0.1400 - learning_rate: 0.0100\n",
      "Epoch 6/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.1395 - mae: 0.2821 - mse: 0.1395 - val_loss: 0.1401 - val_mae: 0.2837 - val_mse: 0.1401 - learning_rate: 0.0100\n",
      "Epoch 7/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1394 - mae: 0.2819 - mse: 0.1394 - val_loss: 0.1395 - val_mae: 0.2819 - val_mse: 0.1395 - learning_rate: 0.0100\n",
      "Epoch 8/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1392 - mae: 0.2817 - mse: 0.1392 - val_loss: 0.1396 - val_mae: 0.2821 - val_mse: 0.1396 - learning_rate: 0.0100\n",
      "Epoch 9/50\n",
      "\u001b[1m3053/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1397 - mae: 0.2823 - mse: 0.1397\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1397 - mae: 0.2823 - mse: 0.1397 - val_loss: 0.1396 - val_mae: 0.2820 - val_mse: 0.1396 - learning_rate: 0.0100\n",
      "Epoch 10/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1392 - mae: 0.2815 - mse: 0.1392 - val_loss: 0.1394 - val_mae: 0.2815 - val_mse: 0.1394 - learning_rate: 0.0050\n",
      "Epoch 11/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1387 - mae: 0.2812 - mse: 0.1387 - val_loss: 0.1392 - val_mae: 0.2810 - val_mse: 0.1392 - learning_rate: 0.0050\n",
      "Epoch 12/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1382 - mae: 0.2806 - mse: 0.1382 - val_loss: 0.1391 - val_mae: 0.2814 - val_mse: 0.1391 - learning_rate: 0.0050\n",
      "Epoch 13/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1383 - mae: 0.2807 - mse: 0.1383 - val_loss: 0.1391 - val_mae: 0.2812 - val_mse: 0.1391 - learning_rate: 0.0050\n",
      "Epoch 14/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1387 - mae: 0.2811 - mse: 0.1387 - val_loss: 0.1390 - val_mae: 0.2823 - val_mse: 0.1390 - learning_rate: 0.0050\n",
      "Epoch 15/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1386 - mae: 0.2810 - mse: 0.1386 - val_loss: 0.1390 - val_mae: 0.2824 - val_mse: 0.1390 - learning_rate: 0.0050\n",
      "Epoch 16/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1385 - mae: 0.2808 - mse: 0.1385 - val_loss: 0.1387 - val_mae: 0.2812 - val_mse: 0.1387 - learning_rate: 0.0050\n",
      "Epoch 17/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1384 - mae: 0.2808 - mse: 0.1384 - val_loss: 0.1388 - val_mae: 0.2807 - val_mse: 0.1388 - learning_rate: 0.0050\n",
      "Epoch 18/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1382 - mae: 0.2806 - mse: 0.1382 - val_loss: 0.1386 - val_mae: 0.2816 - val_mse: 0.1386 - learning_rate: 0.0050\n",
      "Epoch 19/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1384 - mae: 0.2807 - mse: 0.1384 - val_loss: 0.1386 - val_mae: 0.2808 - val_mse: 0.1386 - learning_rate: 0.0050\n",
      "Epoch 20/50\n",
      "\u001b[1m3052/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1382 - mae: 0.2804 - mse: 0.1382\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1382 - mae: 0.2804 - mse: 0.1382 - val_loss: 0.1387 - val_mae: 0.2819 - val_mse: 0.1387 - learning_rate: 0.0050\n",
      "Epoch 21/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1382 - mae: 0.2806 - mse: 0.1382 - val_loss: 0.1385 - val_mae: 0.2815 - val_mse: 0.1385 - learning_rate: 0.0025\n",
      "Epoch 22/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1378 - mae: 0.2803 - mse: 0.1378 - val_loss: 0.1384 - val_mae: 0.2813 - val_mse: 0.1384 - learning_rate: 0.0025\n",
      "Epoch 23/50\n",
      "\u001b[1m3041/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1382 - mae: 0.2805 - mse: 0.1382\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1382 - mae: 0.2805 - mse: 0.1382 - val_loss: 0.1385 - val_mae: 0.2804 - val_mse: 0.1385 - learning_rate: 0.0025\n",
      "Epoch 24/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1380 - mae: 0.2803 - mse: 0.1380 - val_loss: 0.1383 - val_mae: 0.2806 - val_mse: 0.1383 - learning_rate: 0.0012\n",
      "Epoch 25/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1378 - mae: 0.2799 - mse: 0.1378 - val_loss: 0.1383 - val_mae: 0.2811 - val_mse: 0.1383 - learning_rate: 0.0012\n",
      "Epoch 26/50\n",
      "\u001b[1m3054/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1380 - mae: 0.2803 - mse: 0.1380\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1380 - mae: 0.2803 - mse: 0.1380 - val_loss: 0.1383 - val_mae: 0.2805 - val_mse: 0.1383 - learning_rate: 0.0012\n",
      "Epoch 27/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1378 - mae: 0.2800 - mse: 0.1378 - val_loss: 0.1383 - val_mae: 0.2811 - val_mse: 0.1383 - learning_rate: 6.2500e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m3036/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1377 - mae: 0.2799 - mse: 0.1377\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1377 - mae: 0.2799 - mse: 0.1377 - val_loss: 0.1382 - val_mae: 0.2805 - val_mse: 0.1382 - learning_rate: 6.2500e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1376 - mae: 0.2798 - mse: 0.1376 - val_loss: 0.1382 - val_mae: 0.2807 - val_mse: 0.1382 - learning_rate: 3.1250e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1376 - mae: 0.2799 - mse: 0.1376 - val_loss: 0.1382 - val_mae: 0.2809 - val_mse: 0.1382 - learning_rate: 3.1250e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1380 - mae: 0.2804 - mse: 0.1380 - val_loss: 0.1382 - val_mae: 0.2808 - val_mse: 0.1382 - learning_rate: 3.1250e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m3054/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1374 - mae: 0.2795 - mse: 0.1374\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1374 - mae: 0.2795 - mse: 0.1374 - val_loss: 0.1382 - val_mae: 0.2808 - val_mse: 0.1382 - learning_rate: 3.1250e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1376 - mae: 0.2798 - mse: 0.1376 - val_loss: 0.1382 - val_mae: 0.2806 - val_mse: 0.1382 - learning_rate: 1.5625e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m3037/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1377 - mae: 0.2799 - mse: 0.1377\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1377 - mae: 0.2799 - mse: 0.1377 - val_loss: 0.1382 - val_mae: 0.2807 - val_mse: 0.1382 - learning_rate: 1.5625e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1377 - mae: 0.2799 - mse: 0.1377 - val_loss: 0.1382 - val_mae: 0.2807 - val_mse: 0.1382 - learning_rate: 7.8125e-05\n",
      "Epoch 36/50\n",
      "\u001b[1m3049/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1380 - mae: 0.2801 - mse: 0.1380\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1380 - mae: 0.2801 - mse: 0.1380 - val_loss: 0.1382 - val_mae: 0.2808 - val_mse: 0.1382 - learning_rate: 7.8125e-05\n",
      "Epoch 37/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1376 - mae: 0.2799 - mse: 0.1376 - val_loss: 0.1382 - val_mae: 0.2807 - val_mse: 0.1382 - learning_rate: 3.9062e-05\n",
      "Epoch 38/50\n",
      "\u001b[1m3049/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1375 - mae: 0.2798 - mse: 0.1375\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 1.9531249563442543e-05.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1375 - mae: 0.2798 - mse: 0.1375 - val_loss: 0.1382 - val_mae: 0.2808 - val_mse: 0.1382 - learning_rate: 3.9062e-05\n",
      "Epoch 39/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.1376 - mae: 0.2799 - mse: 0.1376 - val_loss: 0.1382 - val_mae: 0.2807 - val_mse: 0.1382 - learning_rate: 1.9531e-05\n",
      "Epoch 40/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1378 - mae: 0.2800 - mse: 0.1378\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 9.765624781721272e-06.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.1378 - mae: 0.2800 - mse: 0.1378 - val_loss: 0.1382 - val_mae: 0.2807 - val_mse: 0.1382 - learning_rate: 1.9531e-05\n",
      "Epoch 41/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1377 - mae: 0.2800 - mse: 0.1377 - val_loss: 0.1382 - val_mae: 0.2808 - val_mse: 0.1382 - learning_rate: 9.7656e-06\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=[X_user_train, X_movie_train],y=y_train, callbacks=[early_stop, reduce_lr],\n",
    "    validation_data=([X_user_dev, X_movie_dev], y_dev),epochs=50, batch_size=512, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad911d9-70a3-42c1-b360-70c9b5dcd46e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "a63ef5dd-0f83-4c04-9f1a-e19b6ee51002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_12\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_12\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ item_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_93 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,344</span> │ user_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_95 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> │ item_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_94 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dense_93[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_96 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dense_95[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lambda_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_94[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lambda_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_96[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ cosine_similarity (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lambda_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           │\n",
       "│                               │                           │                 │ lambda_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_input (\u001b[38;5;33mInputLayer\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ item_input (\u001b[38;5;33mInputLayer\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_93 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m1,344\u001b[0m │ user_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_95 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m1,536\u001b[0m │ item_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_94 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │           \u001b[38;5;34m2,080\u001b[0m │ dense_93[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_96 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │           \u001b[38;5;34m2,080\u001b[0m │ dense_95[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lambda_12 (\u001b[38;5;33mLambda\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_94[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lambda_13 (\u001b[38;5;33mLambda\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_96[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ cosine_similarity (\u001b[38;5;33mDot\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │ lambda_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           │\n",
       "│                               │                           │                 │ lambda_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,040</span> (27.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,040\u001b[0m (27.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,040</span> (27.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,040\u001b[0m (27.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_user_features = X_user_numpy.shape[1]\n",
    "num_item_features = X_movie_numpy.shape[1]\n",
    "num_outputs = 32\n",
    "\n",
    "# ---------------- USER MODEL ----------------\n",
    "user_input = keras.Input(shape=(num_user_features,), name='user_input')\n",
    "x_user = layers.Dense(64, activation='relu', kernel_initializer='he_normal')(user_input)\n",
    "x_user = layers.Dense(num_outputs, activation='relu', kernel_initializer='he_normal')(x_user)\n",
    "user_embedding = layers.Lambda(lambda x: tf.nn.l2_normalize(x, axis=1))(x_user)\n",
    "\n",
    "# ---------------- ITEM MODEL ----------------\n",
    "item_input = keras.Input(shape=(num_item_features,), name='item_input')\n",
    "x_item = layers.Dense(64, activation='relu', kernel_initializer='he_normal')(item_input)\n",
    "x_item = layers.Dense(num_outputs, activation='relu', kernel_initializer='he_normal')(x_item)\n",
    "item_embedding = layers.Lambda(lambda x: tf.nn.l2_normalize(x, axis=1))(x_item)\n",
    "\n",
    "# ---------------- COSINE SIMILARITY ----------------\n",
    "cos_sim = layers.Dot(axes=1, name='cosine_similarity')([user_embedding, item_embedding])\n",
    "# rezultat je u [-1, 1]\n",
    "\n",
    "# ---------------- FINAL MODEL ----------------\n",
    "model = keras.Model(inputs=[user_input, item_input], outputs=cos_sim)\n",
    "\n",
    "# Kompajliraj model\n",
    "model.compile(optimizer= keras.optimizers.Nadam(learning_rate= 0.01), loss='mse', metrics=['mae', 'mse'])\n",
    "\n",
    "# Prikaži arhitekturu\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "e7b03e97-80de-4ce4-93d2-7577abf506b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.1453 - mae: 0.2885 - mse: 0.1453 - val_loss: 0.1393 - val_mae: 0.2804 - val_mse: 0.1393 - learning_rate: 0.0100\n",
      "Epoch 2/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.1388 - mae: 0.2804 - mse: 0.1388 - val_loss: 0.1381 - val_mae: 0.2794 - val_mse: 0.1381 - learning_rate: 0.0100\n",
      "Epoch 3/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.1375 - mae: 0.2788 - mse: 0.1375 - val_loss: 0.1371 - val_mae: 0.2777 - val_mse: 0.1371 - learning_rate: 0.0100\n",
      "Epoch 4/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.1366 - mae: 0.2778 - mse: 0.1366 - val_loss: 0.1363 - val_mae: 0.2783 - val_mse: 0.1363 - learning_rate: 0.0100\n",
      "Epoch 5/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.1361 - mae: 0.2771 - mse: 0.1361 - val_loss: 0.1361 - val_mae: 0.2761 - val_mse: 0.1361 - learning_rate: 0.0100\n",
      "Epoch 6/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.1354 - mae: 0.2763 - mse: 0.1354 - val_loss: 0.1359 - val_mae: 0.2757 - val_mse: 0.1359 - learning_rate: 0.0100\n",
      "Epoch 7/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.1351 - mae: 0.2758 - mse: 0.1351 - val_loss: 0.1352 - val_mae: 0.2762 - val_mse: 0.1352 - learning_rate: 0.0100\n",
      "Epoch 8/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.1345 - mae: 0.2751 - mse: 0.1345 - val_loss: 0.1348 - val_mae: 0.2751 - val_mse: 0.1348 - learning_rate: 0.0100\n",
      "Epoch 9/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.1348 - mae: 0.2753 - mse: 0.1348 - val_loss: 0.1348 - val_mae: 0.2749 - val_mse: 0.1348 - learning_rate: 0.0100\n",
      "Epoch 10/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.1343 - mae: 0.2748 - mse: 0.1343 - val_loss: 0.1347 - val_mae: 0.2747 - val_mse: 0.1347 - learning_rate: 0.0100\n",
      "Epoch 11/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.1340 - mae: 0.2745 - mse: 0.1340 - val_loss: 0.1349 - val_mae: 0.2765 - val_mse: 0.1349 - learning_rate: 0.0100\n",
      "Epoch 12/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.1342 - mae: 0.2747 - mse: 0.1342 - val_loss: 0.1340 - val_mae: 0.2745 - val_mse: 0.1340 - learning_rate: 0.0100\n",
      "Epoch 13/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.1335 - mae: 0.2740 - mse: 0.1335 - val_loss: 0.1341 - val_mae: 0.2751 - val_mse: 0.1341 - learning_rate: 0.0100\n",
      "Epoch 14/50\n",
      "\u001b[1m3043/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1334 - mae: 0.2737 - mse: 0.1334\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.1334 - mae: 0.2737 - mse: 0.1334 - val_loss: 0.1341 - val_mae: 0.2746 - val_mse: 0.1341 - learning_rate: 0.0100\n",
      "Epoch 15/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.1327 - mae: 0.2728 - mse: 0.1327 - val_loss: 0.1335 - val_mae: 0.2736 - val_mse: 0.1335 - learning_rate: 0.0050\n",
      "Epoch 16/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.1323 - mae: 0.2725 - mse: 0.1323 - val_loss: 0.1335 - val_mae: 0.2737 - val_mse: 0.1335 - learning_rate: 0.0050\n",
      "Epoch 17/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.1328 - mae: 0.2726 - mse: 0.1328 - val_loss: 0.1333 - val_mae: 0.2738 - val_mse: 0.1333 - learning_rate: 0.0050\n",
      "Epoch 18/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.1329 - mae: 0.2729 - mse: 0.1329 - val_loss: 0.1333 - val_mae: 0.2734 - val_mse: 0.1333 - learning_rate: 0.0050\n",
      "Epoch 19/50\n",
      "\u001b[1m3040/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1325 - mae: 0.2726 - mse: 0.1325\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.1325 - mae: 0.2726 - mse: 0.1325 - val_loss: 0.1334 - val_mae: 0.2726 - val_mse: 0.1334 - learning_rate: 0.0050\n",
      "Epoch 20/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.1321 - mae: 0.2722 - mse: 0.1321 - val_loss: 0.1330 - val_mae: 0.2735 - val_mse: 0.1330 - learning_rate: 0.0025\n",
      "Epoch 21/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.1320 - mae: 0.2718 - mse: 0.1320 - val_loss: 0.1329 - val_mae: 0.2733 - val_mse: 0.1329 - learning_rate: 0.0025\n",
      "Epoch 22/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.1321 - mae: 0.2719 - mse: 0.1321 - val_loss: 0.1329 - val_mae: 0.2729 - val_mse: 0.1329 - learning_rate: 0.0025\n",
      "Epoch 23/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.1318 - mae: 0.2715 - mse: 0.1318 - val_loss: 0.1329 - val_mae: 0.2729 - val_mse: 0.1329 - learning_rate: 0.0025\n",
      "Epoch 24/50\n",
      "\u001b[1m3051/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1319 - mae: 0.2718 - mse: 0.1319\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.1319 - mae: 0.2718 - mse: 0.1319 - val_loss: 0.1329 - val_mae: 0.2728 - val_mse: 0.1329 - learning_rate: 0.0025\n",
      "Epoch 25/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.1317 - mae: 0.2715 - mse: 0.1317 - val_loss: 0.1328 - val_mae: 0.2722 - val_mse: 0.1328 - learning_rate: 0.0012\n",
      "Epoch 26/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.1319 - mae: 0.2717 - mse: 0.1319 - val_loss: 0.1328 - val_mae: 0.2727 - val_mse: 0.1328 - learning_rate: 0.0012\n",
      "Epoch 27/50\n",
      "\u001b[1m3044/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1316 - mae: 0.2714 - mse: 0.1316\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.1316 - mae: 0.2714 - mse: 0.1316 - val_loss: 0.1328 - val_mae: 0.2731 - val_mse: 0.1328 - learning_rate: 0.0012\n",
      "Epoch 28/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.1318 - mae: 0.2717 - mse: 0.1318 - val_loss: 0.1327 - val_mae: 0.2726 - val_mse: 0.1327 - learning_rate: 6.2500e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m3053/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1318 - mae: 0.2716 - mse: 0.1318\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.1318 - mae: 0.2716 - mse: 0.1318 - val_loss: 0.1327 - val_mae: 0.2725 - val_mse: 0.1327 - learning_rate: 6.2500e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.1312 - mae: 0.2709 - mse: 0.1312 - val_loss: 0.1327 - val_mae: 0.2727 - val_mse: 0.1327 - learning_rate: 3.1250e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.1319 - mae: 0.2717 - mse: 0.1319 - val_loss: 0.1326 - val_mae: 0.2725 - val_mse: 0.1326 - learning_rate: 3.1250e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.1316 - mae: 0.2713 - mse: 0.1316 - val_loss: 0.1327 - val_mae: 0.2725 - val_mse: 0.1327 - learning_rate: 3.1250e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m3049/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1317 - mae: 0.2714 - mse: 0.1317\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.1317 - mae: 0.2714 - mse: 0.1317 - val_loss: 0.1327 - val_mae: 0.2726 - val_mse: 0.1327 - learning_rate: 3.1250e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.1314 - mae: 0.2712 - mse: 0.1314 - val_loss: 0.1327 - val_mae: 0.2725 - val_mse: 0.1327 - learning_rate: 1.5625e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m3051/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1314 - mae: 0.2711 - mse: 0.1314\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.1314 - mae: 0.2711 - mse: 0.1314 - val_loss: 0.1326 - val_mae: 0.2725 - val_mse: 0.1326 - learning_rate: 1.5625e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.1316 - mae: 0.2713 - mse: 0.1316 - val_loss: 0.1326 - val_mae: 0.2725 - val_mse: 0.1326 - learning_rate: 7.8125e-05\n",
      "Epoch 37/50\n",
      "\u001b[1m3037/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1314 - mae: 0.2712 - mse: 0.1314\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.1314 - mae: 0.2712 - mse: 0.1314 - val_loss: 0.1326 - val_mae: 0.2724 - val_mse: 0.1326 - learning_rate: 7.8125e-05\n",
      "Epoch 38/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.1315 - mae: 0.2711 - mse: 0.1315 - val_loss: 0.1326 - val_mae: 0.2725 - val_mse: 0.1326 - learning_rate: 3.9062e-05\n",
      "Epoch 39/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1315 - mae: 0.2712 - mse: 0.1315\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 1.9531249563442543e-05.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.1315 - mae: 0.2712 - mse: 0.1315 - val_loss: 0.1326 - val_mae: 0.2726 - val_mse: 0.1326 - learning_rate: 3.9062e-05\n",
      "Epoch 40/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.1312 - mae: 0.2709 - mse: 0.1312 - val_loss: 0.1326 - val_mae: 0.2725 - val_mse: 0.1326 - learning_rate: 1.9531e-05\n",
      "Epoch 41/50\n",
      "\u001b[1m3045/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1317 - mae: 0.2714 - mse: 0.1317\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 9.765624781721272e-06.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.1317 - mae: 0.2714 - mse: 0.1317 - val_loss: 0.1326 - val_mae: 0.2725 - val_mse: 0.1326 - learning_rate: 1.9531e-05\n",
      "Epoch 42/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.1316 - mae: 0.2713 - mse: 0.1316 - val_loss: 0.1326 - val_mae: 0.2725 - val_mse: 0.1326 - learning_rate: 9.7656e-06\n",
      "Epoch 43/50\n",
      "\u001b[1m3054/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1315 - mae: 0.2711 - mse: 0.1315\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 4.882812390860636e-06.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.1315 - mae: 0.2711 - mse: 0.1315 - val_loss: 0.1326 - val_mae: 0.2725 - val_mse: 0.1326 - learning_rate: 9.7656e-06\n",
      "Epoch 44/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.1316 - mae: 0.2713 - mse: 0.1316 - val_loss: 0.1326 - val_mae: 0.2725 - val_mse: 0.1326 - learning_rate: 4.8828e-06\n",
      "Epoch 45/50\n",
      "\u001b[1m3042/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1316 - mae: 0.2714 - mse: 0.1316\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 2.441406195430318e-06.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.1316 - mae: 0.2714 - mse: 0.1316 - val_loss: 0.1326 - val_mae: 0.2725 - val_mse: 0.1326 - learning_rate: 4.8828e-06\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=[X_user_train, X_movie_train],y=y_train, callbacks=[early_stop, reduce_lr],\n",
    "    validation_data=([X_user_dev, X_movie_dev], y_dev),epochs=50, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "1f2a6bec-ac39-4021-86e9-845783a5b8b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_13\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_13\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ item_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_97 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,688</span> │ user_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_99 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,072</span> │ item_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_98 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │ dense_97[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_100 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │ dense_99[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lambda_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_98[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lambda_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_100[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ cosine_similarity (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lambda_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           │\n",
       "│                               │                           │                 │ lambda_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_input (\u001b[38;5;33mInputLayer\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ item_input (\u001b[38;5;33mInputLayer\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_97 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │           \u001b[38;5;34m2,688\u001b[0m │ user_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_99 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │           \u001b[38;5;34m3,072\u001b[0m │ item_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_98 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │           \u001b[38;5;34m4,128\u001b[0m │ dense_97[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_100 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │           \u001b[38;5;34m4,128\u001b[0m │ dense_99[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lambda_14 (\u001b[38;5;33mLambda\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_98[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lambda_15 (\u001b[38;5;33mLambda\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_100[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ cosine_similarity (\u001b[38;5;33mDot\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │ lambda_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           │\n",
       "│                               │                           │                 │ lambda_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,016</span> (54.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m14,016\u001b[0m (54.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,016</span> (54.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m14,016\u001b[0m (54.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_user_features = X_user_numpy.shape[1]\n",
    "num_item_features = X_movie_numpy.shape[1]\n",
    "num_outputs = 32\n",
    "\n",
    "# ---------------- USER MODEL ----------------\n",
    "user_input = keras.Input(shape=(num_user_features,), name='user_input')\n",
    "x_user = layers.Dense(128, activation='relu', kernel_initializer='he_normal')(user_input)\n",
    "x_user = layers.Dense(num_outputs, activation='relu', kernel_initializer='he_normal')(x_user)\n",
    "user_embedding = layers.Lambda(lambda x: tf.nn.l2_normalize(x, axis=1))(x_user)\n",
    "\n",
    "# ---------------- ITEM MODEL ----------------\n",
    "item_input = keras.Input(shape=(num_item_features,), name='item_input')\n",
    "x_item = layers.Dense(128, activation='relu', kernel_initializer='he_normal')(item_input)\n",
    "x_item = layers.Dense(num_outputs, activation='relu', kernel_initializer='he_normal')(x_item)\n",
    "item_embedding = layers.Lambda(lambda x: tf.nn.l2_normalize(x, axis=1))(x_item)\n",
    "\n",
    "# ---------------- COSINE SIMILARITY ----------------\n",
    "cos_sim = layers.Dot(axes=1, name='cosine_similarity')([user_embedding, item_embedding])\n",
    "# rezultat je u [-1, 1]\n",
    "\n",
    "# ---------------- FINAL MODEL ----------------\n",
    "model = keras.Model(inputs=[user_input, item_input], outputs=cos_sim)\n",
    "\n",
    "# Kompajliraj model\n",
    "model.compile(optimizer= keras.optimizers.Nadam(learning_rate= 0.01), loss='mse', metrics=['mae', 'mse'])\n",
    "\n",
    "# Prikaži arhitekturu\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe244b03-a045-4772-b1ab-d2b0c2e0bc32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3ef883-bd94-4790-bc13-e936b972c8df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97f069c-975e-49fd-a655-d0e2c6f4e53d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "faa07939-360e-4a2e-ba7f-f73e9af6ec20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.1446 - mae: 0.2879 - mse: 0.1446 - val_loss: 0.1394 - val_mae: 0.2828 - val_mse: 0.1394 - learning_rate: 0.0100\n",
      "Epoch 2/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.1378 - mae: 0.2794 - mse: 0.1378 - val_loss: 0.1375 - val_mae: 0.2786 - val_mse: 0.1375 - learning_rate: 0.0100\n",
      "Epoch 3/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.1369 - mae: 0.2783 - mse: 0.1369 - val_loss: 0.1368 - val_mae: 0.2792 - val_mse: 0.1368 - learning_rate: 0.0100\n",
      "Epoch 4/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.1357 - mae: 0.2769 - mse: 0.1357 - val_loss: 0.1359 - val_mae: 0.2772 - val_mse: 0.1359 - learning_rate: 0.0100\n",
      "Epoch 5/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.1355 - mae: 0.2764 - mse: 0.1355 - val_loss: 0.1355 - val_mae: 0.2758 - val_mse: 0.1355 - learning_rate: 0.0100\n",
      "Epoch 6/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.1351 - mae: 0.2759 - mse: 0.1351 - val_loss: 0.1353 - val_mae: 0.2768 - val_mse: 0.1353 - learning_rate: 0.0100\n",
      "Epoch 7/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.1343 - mae: 0.2750 - mse: 0.1343 - val_loss: 0.1348 - val_mae: 0.2752 - val_mse: 0.1348 - learning_rate: 0.0100\n",
      "Epoch 8/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.1342 - mae: 0.2747 - mse: 0.1342 - val_loss: 0.1344 - val_mae: 0.2745 - val_mse: 0.1344 - learning_rate: 0.0100\n",
      "Epoch 9/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.1336 - mae: 0.2740 - mse: 0.1336 - val_loss: 0.1341 - val_mae: 0.2744 - val_mse: 0.1341 - learning_rate: 0.0100\n",
      "Epoch 10/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.1333 - mae: 0.2737 - mse: 0.1333 - val_loss: 0.1343 - val_mae: 0.2738 - val_mse: 0.1343 - learning_rate: 0.0100\n",
      "Epoch 11/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.1332 - mae: 0.2735 - mse: 0.1332 - val_loss: 0.1339 - val_mae: 0.2744 - val_mse: 0.1339 - learning_rate: 0.0100\n",
      "Epoch 12/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.1330 - mae: 0.2732 - mse: 0.1330 - val_loss: 0.1338 - val_mae: 0.2738 - val_mse: 0.1338 - learning_rate: 0.0100\n",
      "Epoch 13/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.1328 - mae: 0.2730 - mse: 0.1328 - val_loss: 0.1334 - val_mae: 0.2739 - val_mse: 0.1334 - learning_rate: 0.0100\n",
      "Epoch 14/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.1325 - mae: 0.2726 - mse: 0.1325 - val_loss: 0.1335 - val_mae: 0.2737 - val_mse: 0.1335 - learning_rate: 0.0100\n",
      "Epoch 15/50\n",
      "\u001b[1m3039/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1327 - mae: 0.2728 - mse: 0.1327\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.1327 - mae: 0.2728 - mse: 0.1327 - val_loss: 0.1334 - val_mae: 0.2740 - val_mse: 0.1334 - learning_rate: 0.0100\n",
      "Epoch 16/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.1320 - mae: 0.2717 - mse: 0.1320 - val_loss: 0.1328 - val_mae: 0.2729 - val_mse: 0.1328 - learning_rate: 0.0050\n",
      "Epoch 17/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.1315 - mae: 0.2710 - mse: 0.1315 - val_loss: 0.1328 - val_mae: 0.2729 - val_mse: 0.1328 - learning_rate: 0.0050\n",
      "Epoch 18/50\n",
      "\u001b[1m3043/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1314 - mae: 0.2710 - mse: 0.1314\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.1314 - mae: 0.2710 - mse: 0.1314 - val_loss: 0.1327 - val_mae: 0.2726 - val_mse: 0.1327 - learning_rate: 0.0050\n",
      "Epoch 19/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.1310 - mae: 0.2706 - mse: 0.1310 - val_loss: 0.1325 - val_mae: 0.2721 - val_mse: 0.1325 - learning_rate: 0.0025\n",
      "Epoch 20/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.1310 - mae: 0.2707 - mse: 0.1310 - val_loss: 0.1324 - val_mae: 0.2720 - val_mse: 0.1324 - learning_rate: 0.0025\n",
      "Epoch 21/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.1306 - mae: 0.2700 - mse: 0.1306 - val_loss: 0.1324 - val_mae: 0.2723 - val_mse: 0.1324 - learning_rate: 0.0025\n",
      "Epoch 22/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.1308 - mae: 0.2703 - mse: 0.1308 - val_loss: 0.1323 - val_mae: 0.2719 - val_mse: 0.1323 - learning_rate: 0.0025\n",
      "Epoch 23/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.1305 - mae: 0.2700 - mse: 0.1305 - val_loss: 0.1323 - val_mae: 0.2722 - val_mse: 0.1323 - learning_rate: 0.0025\n",
      "Epoch 24/50\n",
      "\u001b[1m3040/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1306 - mae: 0.2703 - mse: 0.1306\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.1306 - mae: 0.2703 - mse: 0.1306 - val_loss: 0.1323 - val_mae: 0.2718 - val_mse: 0.1323 - learning_rate: 0.0025\n",
      "Epoch 25/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.1306 - mae: 0.2699 - mse: 0.1306 - val_loss: 0.1321 - val_mae: 0.2717 - val_mse: 0.1321 - learning_rate: 0.0012\n",
      "Epoch 26/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.1302 - mae: 0.2696 - mse: 0.1302 - val_loss: 0.1322 - val_mae: 0.2717 - val_mse: 0.1322 - learning_rate: 0.0012\n",
      "Epoch 27/50\n",
      "\u001b[1m3046/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1304 - mae: 0.2699 - mse: 0.1304\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.1304 - mae: 0.2699 - mse: 0.1304 - val_loss: 0.1321 - val_mae: 0.2718 - val_mse: 0.1321 - learning_rate: 0.0012\n",
      "Epoch 28/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.1302 - mae: 0.2695 - mse: 0.1302 - val_loss: 0.1321 - val_mae: 0.2714 - val_mse: 0.1321 - learning_rate: 6.2500e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m3043/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1302 - mae: 0.2694 - mse: 0.1302\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.1302 - mae: 0.2694 - mse: 0.1302 - val_loss: 0.1321 - val_mae: 0.2715 - val_mse: 0.1321 - learning_rate: 6.2500e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.1302 - mae: 0.2695 - mse: 0.1302 - val_loss: 0.1321 - val_mae: 0.2715 - val_mse: 0.1321 - learning_rate: 3.1250e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1301 - mae: 0.2694 - mse: 0.1301\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.1301 - mae: 0.2694 - mse: 0.1301 - val_loss: 0.1321 - val_mae: 0.2715 - val_mse: 0.1321 - learning_rate: 3.1250e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.1297 - mae: 0.2690 - mse: 0.1297 - val_loss: 0.1321 - val_mae: 0.2715 - val_mse: 0.1321 - learning_rate: 1.5625e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m3048/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1298 - mae: 0.2693 - mse: 0.1298\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.1298 - mae: 0.2693 - mse: 0.1298 - val_loss: 0.1320 - val_mae: 0.2715 - val_mse: 0.1320 - learning_rate: 1.5625e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.1299 - mae: 0.2693 - mse: 0.1299 - val_loss: 0.1320 - val_mae: 0.2715 - val_mse: 0.1320 - learning_rate: 7.8125e-05\n",
      "Epoch 35/50\n",
      "\u001b[1m3044/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1298 - mae: 0.2692 - mse: 0.1298\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.1298 - mae: 0.2692 - mse: 0.1298 - val_loss: 0.1320 - val_mae: 0.2715 - val_mse: 0.1320 - learning_rate: 7.8125e-05\n",
      "Epoch 36/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.1302 - mae: 0.2695 - mse: 0.1302 - val_loss: 0.1320 - val_mae: 0.2715 - val_mse: 0.1320 - learning_rate: 3.9062e-05\n",
      "Epoch 37/50\n",
      "\u001b[1m3049/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1302 - mae: 0.2695 - mse: 0.1302\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 1.9531249563442543e-05.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.1302 - mae: 0.2695 - mse: 0.1302 - val_loss: 0.1320 - val_mae: 0.2715 - val_mse: 0.1320 - learning_rate: 3.9062e-05\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=[X_user_train, X_movie_train],y=y_train, callbacks=[early_stop, reduce_lr],\n",
    "    validation_data=([X_user_dev, X_movie_dev], y_dev),epochs=50, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "5753cbdb-ec6a-4bd3-9935-ecc1298bc7a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_16\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_16\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ item_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_109 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,688</span> │ user_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_111 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,072</span> │ item_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_110 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dense_109[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_112 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dense_111[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lambda_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_110[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lambda_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_112[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ cosine_similarity (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lambda_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           │\n",
       "│                               │                           │                 │ lambda_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_input (\u001b[38;5;33mInputLayer\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ item_input (\u001b[38;5;33mInputLayer\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_109 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │           \u001b[38;5;34m2,688\u001b[0m │ user_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_111 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │           \u001b[38;5;34m3,072\u001b[0m │ item_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_110 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m8,256\u001b[0m │ dense_109[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_112 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m8,256\u001b[0m │ dense_111[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lambda_20 (\u001b[38;5;33mLambda\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_110[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lambda_21 (\u001b[38;5;33mLambda\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_112[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ cosine_similarity (\u001b[38;5;33mDot\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │ lambda_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           │\n",
       "│                               │                           │                 │ lambda_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,272</span> (87.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m22,272\u001b[0m (87.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,272</span> (87.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m22,272\u001b[0m (87.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_user_features = X_user_numpy.shape[1]\n",
    "num_item_features = X_movie_numpy.shape[1]\n",
    "num_outputs = 64\n",
    "\n",
    "# ---------------- USER MODEL ----------------\n",
    "user_input = keras.Input(shape=(num_user_features,), name='user_input')\n",
    "x_user = layers.Dense(128, activation='relu', kernel_initializer='he_normal')(user_input)\n",
    "x_user = layers.Dense(num_outputs, activation='relu', kernel_initializer='he_normal')(x_user)\n",
    "user_embedding = layers.Lambda(lambda x: tf.nn.l2_normalize(x, axis=1))(x_user)\n",
    "\n",
    "# ---------------- ITEM MODEL ----------------\n",
    "item_input = keras.Input(shape=(num_item_features,), name='item_input')\n",
    "x_item = layers.Dense(128, activation='relu', kernel_initializer='he_normal')(item_input)\n",
    "x_item = layers.Dense(num_outputs, activation='relu', kernel_initializer='he_normal')(x_item)\n",
    "item_embedding = layers.Lambda(lambda x: tf.nn.l2_normalize(x, axis=1))(x_item)\n",
    "\n",
    "# ---------------- COSINE SIMILARITY ----------------\n",
    "cos_sim = layers.Dot(axes=1, name='cosine_similarity')([user_embedding, item_embedding])\n",
    "# rezultat je u [-1, 1]\n",
    "\n",
    "# ---------------- FINAL MODEL ----------------\n",
    "model = keras.Model(inputs=[user_input, item_input], outputs=cos_sim)\n",
    "\n",
    "# Kompajliraj model\n",
    "model.compile(optimizer= keras.optimizers.Nadam(learning_rate= 0.01), loss='mse', metrics=['mae', 'mse'])\n",
    "\n",
    "# Prikaži arhitekturu\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "b872f2de-c76b-4557-9a37-f97b8fddad74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - loss: 0.1447 - mae: 0.2879 - mse: 0.1447 - val_loss: 0.1385 - val_mae: 0.2803 - val_mse: 0.1385 - learning_rate: 0.0100\n",
      "Epoch 2/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 0.1380 - mae: 0.2799 - mse: 0.1380 - val_loss: 0.1374 - val_mae: 0.2791 - val_mse: 0.1374 - learning_rate: 0.0100\n",
      "Epoch 3/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - loss: 0.1368 - mae: 0.2783 - mse: 0.1368 - val_loss: 0.1364 - val_mae: 0.2780 - val_mse: 0.1364 - learning_rate: 0.0100\n",
      "Epoch 4/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - loss: 0.1358 - mae: 0.2769 - mse: 0.1358 - val_loss: 0.1354 - val_mae: 0.2762 - val_mse: 0.1354 - learning_rate: 0.0100\n",
      "Epoch 5/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - loss: 0.1347 - mae: 0.2757 - mse: 0.1347 - val_loss: 0.1347 - val_mae: 0.2762 - val_mse: 0.1347 - learning_rate: 0.0100\n",
      "Epoch 6/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 0.1342 - mae: 0.2750 - mse: 0.1342 - val_loss: 0.1353 - val_mae: 0.2776 - val_mse: 0.1353 - learning_rate: 0.0100\n",
      "Epoch 7/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - loss: 0.1341 - mae: 0.2747 - mse: 0.1341 - val_loss: 0.1342 - val_mae: 0.2743 - val_mse: 0.1342 - learning_rate: 0.0100\n",
      "Epoch 8/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - loss: 0.1335 - mae: 0.2740 - mse: 0.1335 - val_loss: 0.1339 - val_mae: 0.2746 - val_mse: 0.1339 - learning_rate: 0.0100\n",
      "Epoch 9/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - loss: 0.1332 - mae: 0.2737 - mse: 0.1332 - val_loss: 0.1337 - val_mae: 0.2746 - val_mse: 0.1337 - learning_rate: 0.0100\n",
      "Epoch 10/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - loss: 0.1328 - mae: 0.2733 - mse: 0.1328 - val_loss: 0.1335 - val_mae: 0.2733 - val_mse: 0.1335 - learning_rate: 0.0100\n",
      "Epoch 11/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - loss: 0.1326 - mae: 0.2729 - mse: 0.1326 - val_loss: 0.1332 - val_mae: 0.2732 - val_mse: 0.1332 - learning_rate: 0.0100\n",
      "Epoch 12/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - loss: 0.1324 - mae: 0.2726 - mse: 0.1324 - val_loss: 0.1332 - val_mae: 0.2730 - val_mse: 0.1332 - learning_rate: 0.0100\n",
      "Epoch 13/50\n",
      "\u001b[1m3054/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1322 - mae: 0.2725 - mse: 0.1322\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - loss: 0.1322 - mae: 0.2725 - mse: 0.1322 - val_loss: 0.1331 - val_mae: 0.2740 - val_mse: 0.1331 - learning_rate: 0.0100\n",
      "Epoch 14/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - loss: 0.1315 - mae: 0.2713 - mse: 0.1315 - val_loss: 0.1326 - val_mae: 0.2720 - val_mse: 0.1326 - learning_rate: 0.0050\n",
      "Epoch 15/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - loss: 0.1314 - mae: 0.2714 - mse: 0.1314 - val_loss: 0.1326 - val_mae: 0.2729 - val_mse: 0.1326 - learning_rate: 0.0050\n",
      "Epoch 16/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - loss: 0.1310 - mae: 0.2709 - mse: 0.1310 - val_loss: 0.1323 - val_mae: 0.2719 - val_mse: 0.1323 - learning_rate: 0.0050\n",
      "Epoch 17/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - loss: 0.1313 - mae: 0.2711 - mse: 0.1313 - val_loss: 0.1324 - val_mae: 0.2721 - val_mse: 0.1324 - learning_rate: 0.0050\n",
      "Epoch 18/50\n",
      "\u001b[1m3048/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1309 - mae: 0.2708 - mse: 0.1309\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - loss: 0.1309 - mae: 0.2708 - mse: 0.1309 - val_loss: 0.1323 - val_mae: 0.2724 - val_mse: 0.1323 - learning_rate: 0.0050\n",
      "Epoch 19/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - loss: 0.1304 - mae: 0.2702 - mse: 0.1304 - val_loss: 0.1320 - val_mae: 0.2721 - val_mse: 0.1320 - learning_rate: 0.0025\n",
      "Epoch 20/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - loss: 0.1304 - mae: 0.2700 - mse: 0.1304 - val_loss: 0.1320 - val_mae: 0.2717 - val_mse: 0.1320 - learning_rate: 0.0025\n",
      "Epoch 21/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - loss: 0.1304 - mae: 0.2699 - mse: 0.1304 - val_loss: 0.1319 - val_mae: 0.2718 - val_mse: 0.1319 - learning_rate: 0.0025\n",
      "Epoch 22/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - loss: 0.1305 - mae: 0.2700 - mse: 0.1305 - val_loss: 0.1320 - val_mae: 0.2718 - val_mse: 0.1320 - learning_rate: 0.0025\n",
      "Epoch 23/50\n",
      "\u001b[1m3046/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1307 - mae: 0.2704 - mse: 0.1307\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - loss: 0.1307 - mae: 0.2704 - mse: 0.1307 - val_loss: 0.1318 - val_mae: 0.2716 - val_mse: 0.1318 - learning_rate: 0.0025\n",
      "Epoch 24/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - loss: 0.1300 - mae: 0.2695 - mse: 0.1300 - val_loss: 0.1318 - val_mae: 0.2715 - val_mse: 0.1318 - learning_rate: 0.0012\n",
      "Epoch 25/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - loss: 0.1294 - mae: 0.2689 - mse: 0.1294 - val_loss: 0.1318 - val_mae: 0.2713 - val_mse: 0.1318 - learning_rate: 0.0012\n",
      "Epoch 26/50\n",
      "\u001b[1m3052/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1300 - mae: 0.2696 - mse: 0.1300\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - loss: 0.1300 - mae: 0.2696 - mse: 0.1300 - val_loss: 0.1317 - val_mae: 0.2712 - val_mse: 0.1317 - learning_rate: 0.0012\n",
      "Epoch 27/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - loss: 0.1297 - mae: 0.2691 - mse: 0.1297 - val_loss: 0.1317 - val_mae: 0.2712 - val_mse: 0.1317 - learning_rate: 6.2500e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m3042/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1297 - mae: 0.2691 - mse: 0.1297\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - loss: 0.1297 - mae: 0.2691 - mse: 0.1297 - val_loss: 0.1317 - val_mae: 0.2712 - val_mse: 0.1317 - learning_rate: 6.2500e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - loss: 0.1296 - mae: 0.2690 - mse: 0.1296 - val_loss: 0.1317 - val_mae: 0.2712 - val_mse: 0.1317 - learning_rate: 3.1250e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - loss: 0.1297 - mae: 0.2691 - mse: 0.1297 - val_loss: 0.1317 - val_mae: 0.2711 - val_mse: 0.1317 - learning_rate: 3.1250e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m3041/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1295 - mae: 0.2690 - mse: 0.1295\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - loss: 0.1295 - mae: 0.2690 - mse: 0.1295 - val_loss: 0.1317 - val_mae: 0.2711 - val_mse: 0.1317 - learning_rate: 3.1250e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - loss: 0.1297 - mae: 0.2691 - mse: 0.1297 - val_loss: 0.1317 - val_mae: 0.2711 - val_mse: 0.1317 - learning_rate: 1.5625e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m3044/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1297 - mae: 0.2691 - mse: 0.1297\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - loss: 0.1297 - mae: 0.2691 - mse: 0.1297 - val_loss: 0.1317 - val_mae: 0.2712 - val_mse: 0.1317 - learning_rate: 1.5625e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - loss: 0.1297 - mae: 0.2691 - mse: 0.1297 - val_loss: 0.1317 - val_mae: 0.2711 - val_mse: 0.1317 - learning_rate: 7.8125e-05\n",
      "Epoch 35/50\n",
      "\u001b[1m3051/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1293 - mae: 0.2688 - mse: 0.1293\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - loss: 0.1293 - mae: 0.2688 - mse: 0.1293 - val_loss: 0.1317 - val_mae: 0.2711 - val_mse: 0.1317 - learning_rate: 7.8125e-05\n",
      "Epoch 36/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - loss: 0.1295 - mae: 0.2688 - mse: 0.1295 - val_loss: 0.1317 - val_mae: 0.2711 - val_mse: 0.1317 - learning_rate: 3.9062e-05\n",
      "Epoch 37/50\n",
      "\u001b[1m3049/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1293 - mae: 0.2688 - mse: 0.1293\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 1.9531249563442543e-05.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - loss: 0.1293 - mae: 0.2688 - mse: 0.1293 - val_loss: 0.1317 - val_mae: 0.2711 - val_mse: 0.1317 - learning_rate: 3.9062e-05\n",
      "Epoch 38/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - loss: 0.1298 - mae: 0.2693 - mse: 0.1298 - val_loss: 0.1317 - val_mae: 0.2711 - val_mse: 0.1317 - learning_rate: 1.9531e-05\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=[X_user_train, X_movie_train],y=y_train, callbacks=[early_stop, reduce_lr],\n",
    "    validation_data=([X_user_dev, X_movie_dev], y_dev),epochs=50, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "7e630632-52b4-42c7-a8ad-5d3dc8805b99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_18\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_18\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ item_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_117 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,688</span> │ user_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_119 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,072</span> │ item_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_118 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dense_117[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_120 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dense_119[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lambda_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_118[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lambda_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_120[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ cosine_similarity (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lambda_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           │\n",
       "│                               │                           │                 │ lambda_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_input (\u001b[38;5;33mInputLayer\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ item_input (\u001b[38;5;33mInputLayer\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_117 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │           \u001b[38;5;34m2,688\u001b[0m │ user_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_119 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │           \u001b[38;5;34m3,072\u001b[0m │ item_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_118 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m8,256\u001b[0m │ dense_117[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_120 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m8,256\u001b[0m │ dense_119[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lambda_24 (\u001b[38;5;33mLambda\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_118[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lambda_25 (\u001b[38;5;33mLambda\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_120[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ cosine_similarity (\u001b[38;5;33mDot\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │ lambda_24[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           │\n",
       "│                               │                           │                 │ lambda_25[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,272</span> (87.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m22,272\u001b[0m (87.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,272</span> (87.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m22,272\u001b[0m (87.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_user_features = X_user_numpy.shape[1]\n",
    "num_item_features = X_movie_numpy.shape[1]\n",
    "num_outputs = 64\n",
    "\n",
    "# ---------------- USER MODEL ----------------\n",
    "user_input = keras.Input(shape=(num_user_features,), name='user_input')\n",
    "x_user = layers.Dense(128, activation='tanh', kernel_initializer='glorot_uniform')(user_input)\n",
    "x_user = layers.Dense(num_outputs, activation='tanh', kernel_initializer='glorot_uniform')(x_user)\n",
    "user_embedding = layers.Lambda(lambda x: tf.nn.l2_normalize(x, axis=1))(x_user)\n",
    "\n",
    "# ---------------- ITEM MODEL ----------------\n",
    "item_input = keras.Input(shape=(num_item_features,), name='item_input')\n",
    "x_item = layers.Dense(128, activation='tanh', kernel_initializer='glorot_uniform')(item_input)\n",
    "x_item = layers.Dense(num_outputs, activation='tanh', kernel_initializer='glorot_uniform')(x_item)\n",
    "item_embedding = layers.Lambda(lambda x: tf.nn.l2_normalize(x, axis=1))(x_item)\n",
    "\n",
    "# ---------------- COSINE SIMILARITY ----------------\n",
    "cos_sim = layers.Dot(axes=1, name='cosine_similarity')([user_embedding, item_embedding])\n",
    "# rezultat je u [-1, 1]\n",
    "\n",
    "# ---------------- FINAL MODEL ----------------\n",
    "model_tanh = keras.Model(inputs=[user_input, item_input], outputs=cos_sim)\n",
    "\n",
    "# Kompajliraj model\n",
    "model_tanh.compile(optimizer= keras.optimizers.Nadam(learning_rate= 0.01), loss='mse', metrics=['mae', 'mse'])\n",
    "\n",
    "# Prikaži arhitekturu\n",
    "model_tanh.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "4f1ca826-9ade-49ee-a603-e7ce55265fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 5ms/step - loss: 0.1395 - mae: 0.2849 - mse: 0.1395 - val_loss: 0.1334 - val_mae: 0.2782 - val_mse: 0.1334 - learning_rate: 0.0100\n",
      "Epoch 2/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - loss: 0.1331 - mae: 0.2776 - mse: 0.1331 - val_loss: 0.1336 - val_mae: 0.2797 - val_mse: 0.1336 - learning_rate: 0.0100\n",
      "Epoch 3/50\n",
      "\u001b[1m3045/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1334 - mae: 0.2783 - mse: 0.1334\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - loss: 0.1334 - mae: 0.2783 - mse: 0.1334 - val_loss: 0.1336 - val_mae: 0.2793 - val_mse: 0.1336 - learning_rate: 0.0100\n",
      "Epoch 4/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - loss: 0.1318 - mae: 0.2758 - mse: 0.1318 - val_loss: 0.1313 - val_mae: 0.2755 - val_mse: 0.1313 - learning_rate: 0.0050\n",
      "Epoch 5/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - loss: 0.1311 - mae: 0.2747 - mse: 0.1311 - val_loss: 0.1310 - val_mae: 0.2752 - val_mse: 0.1310 - learning_rate: 0.0050\n",
      "Epoch 6/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - loss: 0.1305 - mae: 0.2741 - mse: 0.1305 - val_loss: 0.1309 - val_mae: 0.2746 - val_mse: 0.1309 - learning_rate: 0.0050\n",
      "Epoch 7/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - loss: 0.1303 - mae: 0.2738 - mse: 0.1303 - val_loss: 0.1306 - val_mae: 0.2736 - val_mse: 0.1306 - learning_rate: 0.0050\n",
      "Epoch 8/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - loss: 0.1298 - mae: 0.2732 - mse: 0.1298 - val_loss: 0.1308 - val_mae: 0.2746 - val_mse: 0.1308 - learning_rate: 0.0050\n",
      "Epoch 9/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1296 - mae: 0.2730 - mse: 0.1296 - val_loss: 0.1301 - val_mae: 0.2741 - val_mse: 0.1301 - learning_rate: 0.0050\n",
      "Epoch 10/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - loss: 0.1294 - mae: 0.2728 - mse: 0.1294 - val_loss: 0.1303 - val_mae: 0.2745 - val_mse: 0.1303 - learning_rate: 0.0050\n",
      "Epoch 11/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - loss: 0.1298 - mae: 0.2733 - mse: 0.1298 - val_loss: 0.1299 - val_mae: 0.2738 - val_mse: 0.1299 - learning_rate: 0.0050\n",
      "Epoch 12/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - loss: 0.1293 - mae: 0.2727 - mse: 0.1293 - val_loss: 0.1299 - val_mae: 0.2742 - val_mse: 0.1299 - learning_rate: 0.0050\n",
      "Epoch 13/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - loss: 0.1289 - mae: 0.2724 - mse: 0.1289 - val_loss: 0.1298 - val_mae: 0.2736 - val_mse: 0.1298 - learning_rate: 0.0050\n",
      "Epoch 14/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - loss: 0.1290 - mae: 0.2722 - mse: 0.1290 - val_loss: 0.1296 - val_mae: 0.2739 - val_mse: 0.1296 - learning_rate: 0.0050\n",
      "Epoch 15/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - loss: 0.1289 - mae: 0.2726 - mse: 0.1289 - val_loss: 0.1293 - val_mae: 0.2729 - val_mse: 0.1293 - learning_rate: 0.0050\n",
      "Epoch 16/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1290 - mae: 0.2723 - mse: 0.1290 - val_loss: 0.1296 - val_mae: 0.2737 - val_mse: 0.1296 - learning_rate: 0.0050\n",
      "Epoch 17/50\n",
      "\u001b[1m3046/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1287 - mae: 0.2720 - mse: 0.1287\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - loss: 0.1287 - mae: 0.2720 - mse: 0.1287 - val_loss: 0.1293 - val_mae: 0.2735 - val_mse: 0.1293 - learning_rate: 0.0050\n",
      "Epoch 18/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1279 - mae: 0.2707 - mse: 0.1279 - val_loss: 0.1283 - val_mae: 0.2712 - val_mse: 0.1283 - learning_rate: 0.0025\n",
      "Epoch 19/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1272 - mae: 0.2699 - mse: 0.1272 - val_loss: 0.1282 - val_mae: 0.2716 - val_mse: 0.1282 - learning_rate: 0.0025\n",
      "Epoch 20/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1271 - mae: 0.2699 - mse: 0.1271 - val_loss: 0.1280 - val_mae: 0.2711 - val_mse: 0.1280 - learning_rate: 0.0025\n",
      "Epoch 21/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1269 - mae: 0.2696 - mse: 0.1269 - val_loss: 0.1280 - val_mae: 0.2711 - val_mse: 0.1280 - learning_rate: 0.0025\n",
      "Epoch 22/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - loss: 0.1267 - mae: 0.2693 - mse: 0.1267 - val_loss: 0.1278 - val_mae: 0.2703 - val_mse: 0.1278 - learning_rate: 0.0025\n",
      "Epoch 23/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1263 - mae: 0.2690 - mse: 0.1263 - val_loss: 0.1280 - val_mae: 0.2707 - val_mse: 0.1280 - learning_rate: 0.0025\n",
      "Epoch 24/50\n",
      "\u001b[1m3051/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1261 - mae: 0.2686 - mse: 0.1261\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - loss: 0.1261 - mae: 0.2686 - mse: 0.1261 - val_loss: 0.1277 - val_mae: 0.2707 - val_mse: 0.1277 - learning_rate: 0.0025\n",
      "Epoch 25/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - loss: 0.1260 - mae: 0.2684 - mse: 0.1260 - val_loss: 0.1274 - val_mae: 0.2700 - val_mse: 0.1274 - learning_rate: 0.0012\n",
      "Epoch 26/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - loss: 0.1250 - mae: 0.2674 - mse: 0.1250 - val_loss: 0.1273 - val_mae: 0.2699 - val_mse: 0.1273 - learning_rate: 0.0012\n",
      "Epoch 27/50\n",
      "\u001b[1m3053/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1257 - mae: 0.2680 - mse: 0.1257\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - loss: 0.1257 - mae: 0.2680 - mse: 0.1257 - val_loss: 0.1273 - val_mae: 0.2698 - val_mse: 0.1273 - learning_rate: 0.0012\n",
      "Epoch 28/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - loss: 0.1250 - mae: 0.2672 - mse: 0.1250 - val_loss: 0.1272 - val_mae: 0.2696 - val_mse: 0.1272 - learning_rate: 6.2500e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - loss: 0.1251 - mae: 0.2674 - mse: 0.1251 - val_loss: 0.1272 - val_mae: 0.2696 - val_mse: 0.1272 - learning_rate: 6.2500e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m3048/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1245 - mae: 0.2668 - mse: 0.1245\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - loss: 0.1245 - mae: 0.2668 - mse: 0.1245 - val_loss: 0.1272 - val_mae: 0.2696 - val_mse: 0.1272 - learning_rate: 6.2500e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - loss: 0.1242 - mae: 0.2664 - mse: 0.1242 - val_loss: 0.1271 - val_mae: 0.2697 - val_mse: 0.1271 - learning_rate: 3.1250e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m3053/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1250 - mae: 0.2671 - mse: 0.1250\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - loss: 0.1250 - mae: 0.2671 - mse: 0.1250 - val_loss: 0.1271 - val_mae: 0.2696 - val_mse: 0.1271 - learning_rate: 3.1250e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - loss: 0.1245 - mae: 0.2667 - mse: 0.1245 - val_loss: 0.1271 - val_mae: 0.2696 - val_mse: 0.1271 - learning_rate: 1.5625e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m3046/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1242 - mae: 0.2664 - mse: 0.1242\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - loss: 0.1242 - mae: 0.2664 - mse: 0.1242 - val_loss: 0.1271 - val_mae: 0.2696 - val_mse: 0.1271 - learning_rate: 1.5625e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - loss: 0.1242 - mae: 0.2664 - mse: 0.1242 - val_loss: 0.1271 - val_mae: 0.2696 - val_mse: 0.1271 - learning_rate: 7.8125e-05\n",
      "Epoch 36/50\n",
      "\u001b[1m3053/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1245 - mae: 0.2666 - mse: 0.1245\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - loss: 0.1245 - mae: 0.2666 - mse: 0.1245 - val_loss: 0.1271 - val_mae: 0.2696 - val_mse: 0.1271 - learning_rate: 7.8125e-05\n",
      "Epoch 37/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - loss: 0.1240 - mae: 0.2661 - mse: 0.1240 - val_loss: 0.1271 - val_mae: 0.2696 - val_mse: 0.1271 - learning_rate: 3.9062e-05\n",
      "Epoch 38/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - loss: 0.1239 - mae: 0.2662 - mse: 0.1239 - val_loss: 0.1271 - val_mae: 0.2696 - val_mse: 0.1271 - learning_rate: 3.9062e-05\n",
      "Epoch 39/50\n",
      "\u001b[1m3049/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1242 - mae: 0.2662 - mse: 0.1242\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 1.9531249563442543e-05.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - loss: 0.1242 - mae: 0.2662 - mse: 0.1242 - val_loss: 0.1271 - val_mae: 0.2695 - val_mse: 0.1271 - learning_rate: 3.9062e-05\n",
      "Epoch 40/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - loss: 0.1241 - mae: 0.2661 - mse: 0.1241 - val_loss: 0.1271 - val_mae: 0.2696 - val_mse: 0.1271 - learning_rate: 1.9531e-05\n",
      "Epoch 41/50\n",
      "\u001b[1m3054/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1241 - mae: 0.2662 - mse: 0.1241\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 9.765624781721272e-06.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - loss: 0.1241 - mae: 0.2662 - mse: 0.1241 - val_loss: 0.1271 - val_mae: 0.2696 - val_mse: 0.1271 - learning_rate: 1.9531e-05\n",
      "Epoch 42/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - loss: 0.1239 - mae: 0.2662 - mse: 0.1239 - val_loss: 0.1271 - val_mae: 0.2696 - val_mse: 0.1271 - learning_rate: 9.7656e-06\n",
      "Epoch 43/50\n",
      "\u001b[1m3054/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1239 - mae: 0.2661 - mse: 0.1239\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 4.882812390860636e-06.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - loss: 0.1239 - mae: 0.2661 - mse: 0.1239 - val_loss: 0.1271 - val_mae: 0.2696 - val_mse: 0.1271 - learning_rate: 9.7656e-06\n"
     ]
    }
   ],
   "source": [
    "history_tanh = model_tanh.fit(x=[X_user_train, X_movie_train],y=y_train, callbacks=[early_stop, reduce_lr],\n",
    "    validation_data=([X_user_dev, X_movie_dev], y_dev),epochs=50, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "d50a534a-8635-48b9-8077-58275919657f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_28\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_28\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ item_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_181 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,688</span> │ user_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_183 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,072</span> │ item_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_182 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dense_181[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_184 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dense_183[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lambda_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_182[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lambda_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_184[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ cosine_similarity (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lambda_40[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           │\n",
       "│                               │                           │                 │ lambda_41[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_input (\u001b[38;5;33mInputLayer\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ item_input (\u001b[38;5;33mInputLayer\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_181 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │           \u001b[38;5;34m2,688\u001b[0m │ user_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_183 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │           \u001b[38;5;34m3,072\u001b[0m │ item_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_182 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m8,256\u001b[0m │ dense_181[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_184 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m8,256\u001b[0m │ dense_183[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lambda_40 (\u001b[38;5;33mLambda\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_182[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lambda_41 (\u001b[38;5;33mLambda\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_184[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ cosine_similarity (\u001b[38;5;33mDot\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │ lambda_40[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           │\n",
       "│                               │                           │                 │ lambda_41[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,272</span> (87.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m22,272\u001b[0m (87.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,272</span> (87.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m22,272\u001b[0m (87.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_user_features = X_user_numpy.shape[1]\n",
    "num_item_features = X_movie_numpy.shape[1]\n",
    "num_outputs = 64\n",
    "\n",
    "# ---------------- USER MODEL ----------------\n",
    "user_input = keras.Input(shape=(num_user_features,), name='user_input')\n",
    "x_user = layers.Dense(128, activation='tanh', kernel_initializer='glorot_uniform', kernel_regularizer= keras.regularizers.l2(0.001))(user_input)\n",
    "x_user = layers.Dense(num_outputs, activation='tanh', kernel_initializer='glorot_uniform')(x_user)\n",
    "user_embedding = layers.Lambda(lambda x: tf.nn.l2_normalize(x, axis=1))(x_user)\n",
    "\n",
    "# ---------------- ITEM MODEL ----------------\n",
    "item_input = keras.Input(shape=(num_item_features,), name='item_input')\n",
    "x_item = layers.Dense(128, activation='tanh', kernel_initializer='glorot_uniform')(item_input)\n",
    "x_item = layers.Dense(num_outputs, activation='tanh', kernel_initializer='glorot_uniform')(x_item)\n",
    "item_embedding = layers.Lambda(lambda x: tf.nn.l2_normalize(x, axis=1))(x_item)\n",
    "\n",
    "# ---------------- COSINE SIMILARITY ----------------\n",
    "cos_sim = layers.Dot(axes=1, name='cosine_similarity')([user_embedding, item_embedding])\n",
    "# rezultat je u [-1, 1]\n",
    "\n",
    "# ---------------- FINAL MODEL ----------------\n",
    "model_tanh_l2 = keras.Model(inputs=[user_input, item_input], outputs=cos_sim)\n",
    "\n",
    "# Kompajliraj model\n",
    "model_tanh_l2.compile(optimizer= keras.optimizers.Nadam(learning_rate= 0.01), loss='mse', metrics=['mae', 'mse'])\n",
    "\n",
    "# Prikaži arhitekturu\n",
    "model_tanh_l2.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "792c0ee4-972b-4eb3-8d08-436ffad93033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 5ms/step - loss: 0.1436 - mae: 0.2854 - mse: 0.1396 - val_loss: 0.1353 - val_mae: 0.2788 - val_mse: 0.1337 - learning_rate: 0.0100\n",
      "Epoch 2/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - loss: 0.1350 - mae: 0.2781 - mse: 0.1335 - val_loss: 0.1338 - val_mae: 0.2764 - val_mse: 0.1326 - learning_rate: 0.0100\n",
      "Epoch 3/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - loss: 0.1337 - mae: 0.2770 - mse: 0.1324 - val_loss: 0.1334 - val_mae: 0.2770 - val_mse: 0.1322 - learning_rate: 0.0100\n",
      "Epoch 4/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - loss: 0.1337 - mae: 0.2769 - mse: 0.1324 - val_loss: 0.1334 - val_mae: 0.2774 - val_mse: 0.1322 - learning_rate: 0.0100\n",
      "Epoch 5/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - loss: 0.1337 - mae: 0.2770 - mse: 0.1325 - val_loss: 0.1337 - val_mae: 0.2774 - val_mse: 0.1325 - learning_rate: 0.0100\n",
      "Epoch 6/50\n",
      "\u001b[1m3049/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1336 - mae: 0.2771 - mse: 0.1324\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - loss: 0.1336 - mae: 0.2771 - mse: 0.1324 - val_loss: 0.1336 - val_mae: 0.2763 - val_mse: 0.1325 - learning_rate: 0.0100\n",
      "Epoch 7/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - loss: 0.1318 - mae: 0.2749 - mse: 0.1310 - val_loss: 0.1312 - val_mae: 0.2749 - val_mse: 0.1305 - learning_rate: 0.0050\n",
      "Epoch 8/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - loss: 0.1305 - mae: 0.2736 - mse: 0.1299 - val_loss: 0.1311 - val_mae: 0.2751 - val_mse: 0.1304 - learning_rate: 0.0050\n",
      "Epoch 9/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - loss: 0.1305 - mae: 0.2734 - mse: 0.1298 - val_loss: 0.1308 - val_mae: 0.2738 - val_mse: 0.1301 - learning_rate: 0.0050\n",
      "Epoch 10/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - loss: 0.1304 - mae: 0.2735 - mse: 0.1298 - val_loss: 0.1307 - val_mae: 0.2740 - val_mse: 0.1299 - learning_rate: 0.0050\n",
      "Epoch 11/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - loss: 0.1300 - mae: 0.2731 - mse: 0.1293 - val_loss: 0.1304 - val_mae: 0.2737 - val_mse: 0.1298 - learning_rate: 0.0050\n",
      "Epoch 12/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - loss: 0.1302 - mae: 0.2731 - mse: 0.1296 - val_loss: 0.1304 - val_mae: 0.2733 - val_mse: 0.1297 - learning_rate: 0.0050\n",
      "Epoch 13/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - loss: 0.1298 - mae: 0.2727 - mse: 0.1291 - val_loss: 0.1307 - val_mae: 0.2739 - val_mse: 0.1301 - learning_rate: 0.0050\n",
      "Epoch 14/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - loss: 0.1299 - mae: 0.2729 - mse: 0.1292 - val_loss: 0.1300 - val_mae: 0.2735 - val_mse: 0.1294 - learning_rate: 0.0050\n",
      "Epoch 15/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - loss: 0.1300 - mae: 0.2730 - mse: 0.1293 - val_loss: 0.1302 - val_mae: 0.2738 - val_mse: 0.1294 - learning_rate: 0.0050\n",
      "Epoch 16/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - loss: 0.1294 - mae: 0.2721 - mse: 0.1287 - val_loss: 0.1299 - val_mae: 0.2720 - val_mse: 0.1293 - learning_rate: 0.0050\n",
      "Epoch 17/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - loss: 0.1291 - mae: 0.2721 - mse: 0.1285 - val_loss: 0.1299 - val_mae: 0.2738 - val_mse: 0.1292 - learning_rate: 0.0050\n",
      "Epoch 18/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - loss: 0.1293 - mae: 0.2721 - mse: 0.1287 - val_loss: 0.1294 - val_mae: 0.2721 - val_mse: 0.1288 - learning_rate: 0.0050\n",
      "Epoch 19/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - loss: 0.1292 - mae: 0.2721 - mse: 0.1286 - val_loss: 0.1295 - val_mae: 0.2735 - val_mse: 0.1289 - learning_rate: 0.0050\n",
      "Epoch 20/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - loss: 0.1290 - mae: 0.2719 - mse: 0.1284 - val_loss: 0.1297 - val_mae: 0.2724 - val_mse: 0.1289 - learning_rate: 0.0050\n",
      "Epoch 21/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1292 - mae: 0.2720 - mse: 0.1286\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 0.1292 - mae: 0.2720 - mse: 0.1286 - val_loss: 0.1294 - val_mae: 0.2718 - val_mse: 0.1287 - learning_rate: 0.0050\n",
      "Epoch 22/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 0.1278 - mae: 0.2704 - mse: 0.1273 - val_loss: 0.1283 - val_mae: 0.2711 - val_mse: 0.1279 - learning_rate: 0.0025\n",
      "Epoch 23/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 0.1273 - mae: 0.2698 - mse: 0.1268 - val_loss: 0.1280 - val_mae: 0.2707 - val_mse: 0.1276 - learning_rate: 0.0025\n",
      "Epoch 24/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 0.1275 - mae: 0.2701 - mse: 0.1271 - val_loss: 0.1281 - val_mae: 0.2712 - val_mse: 0.1277 - learning_rate: 0.0025\n",
      "Epoch 25/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - loss: 0.1271 - mae: 0.2697 - mse: 0.1267 - val_loss: 0.1281 - val_mae: 0.2712 - val_mse: 0.1277 - learning_rate: 0.0025\n",
      "Epoch 26/50\n",
      "\u001b[1m3053/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1267 - mae: 0.2692 - mse: 0.1263\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 0.1267 - mae: 0.2692 - mse: 0.1263 - val_loss: 0.1280 - val_mae: 0.2715 - val_mse: 0.1276 - learning_rate: 0.0025\n",
      "Epoch 27/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - loss: 0.1265 - mae: 0.2690 - mse: 0.1262 - val_loss: 0.1274 - val_mae: 0.2699 - val_mse: 0.1271 - learning_rate: 0.0012\n",
      "Epoch 28/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 0.1265 - mae: 0.2689 - mse: 0.1262 - val_loss: 0.1273 - val_mae: 0.2699 - val_mse: 0.1270 - learning_rate: 0.0012\n",
      "Epoch 29/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - loss: 0.1260 - mae: 0.2685 - mse: 0.1257 - val_loss: 0.1271 - val_mae: 0.2697 - val_mse: 0.1269 - learning_rate: 0.0012\n",
      "Epoch 30/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - loss: 0.1260 - mae: 0.2685 - mse: 0.1257 - val_loss: 0.1272 - val_mae: 0.2699 - val_mse: 0.1270 - learning_rate: 0.0012\n",
      "Epoch 31/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - loss: 0.1261 - mae: 0.2685 - mse: 0.1258 - val_loss: 0.1270 - val_mae: 0.2696 - val_mse: 0.1268 - learning_rate: 0.0012\n",
      "Epoch 32/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 0.1262 - mae: 0.2687 - mse: 0.1259 - val_loss: 0.1271 - val_mae: 0.2698 - val_mse: 0.1269 - learning_rate: 0.0012\n",
      "Epoch 33/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - loss: 0.1258 - mae: 0.2681 - mse: 0.1256 - val_loss: 0.1272 - val_mae: 0.2691 - val_mse: 0.1270 - learning_rate: 0.0012\n",
      "Epoch 34/50\n",
      "\u001b[1m3052/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1258 - mae: 0.2681 - mse: 0.1256\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - loss: 0.1258 - mae: 0.2681 - mse: 0.1256 - val_loss: 0.1270 - val_mae: 0.2695 - val_mse: 0.1268 - learning_rate: 0.0012\n",
      "Epoch 35/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 0.1254 - mae: 0.2676 - mse: 0.1251 - val_loss: 0.1268 - val_mae: 0.2693 - val_mse: 0.1266 - learning_rate: 6.2500e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 0.1251 - mae: 0.2675 - mse: 0.1249 - val_loss: 0.1268 - val_mae: 0.2696 - val_mse: 0.1266 - learning_rate: 6.2500e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 0.1256 - mae: 0.2679 - mse: 0.1254 - val_loss: 0.1268 - val_mae: 0.2692 - val_mse: 0.1266 - learning_rate: 6.2500e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m3054/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1252 - mae: 0.2676 - mse: 0.1250\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 0.1252 - mae: 0.2676 - mse: 0.1250 - val_loss: 0.1268 - val_mae: 0.2693 - val_mse: 0.1266 - learning_rate: 6.2500e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 0.1249 - mae: 0.2672 - mse: 0.1247 - val_loss: 0.1267 - val_mae: 0.2693 - val_mse: 0.1265 - learning_rate: 3.1250e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 0.1248 - mae: 0.2670 - mse: 0.1246 - val_loss: 0.1267 - val_mae: 0.2689 - val_mse: 0.1265 - learning_rate: 3.1250e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 0.1250 - mae: 0.2672 - mse: 0.1248 - val_loss: 0.1266 - val_mae: 0.2691 - val_mse: 0.1265 - learning_rate: 3.1250e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m3052/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1248 - mae: 0.2670 - mse: 0.1247\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - loss: 0.1248 - mae: 0.2670 - mse: 0.1247 - val_loss: 0.1266 - val_mae: 0.2689 - val_mse: 0.1265 - learning_rate: 3.1250e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 0.1246 - mae: 0.2670 - mse: 0.1245 - val_loss: 0.1266 - val_mae: 0.2692 - val_mse: 0.1264 - learning_rate: 1.5625e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 0.1249 - mae: 0.2672 - mse: 0.1247 - val_loss: 0.1266 - val_mae: 0.2691 - val_mse: 0.1264 - learning_rate: 1.5625e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m3050/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1250 - mae: 0.2673 - mse: 0.1249\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 0.1250 - mae: 0.2673 - mse: 0.1249 - val_loss: 0.1266 - val_mae: 0.2690 - val_mse: 0.1264 - learning_rate: 1.5625e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 0.1252 - mae: 0.2674 - mse: 0.1250 - val_loss: 0.1266 - val_mae: 0.2691 - val_mse: 0.1264 - learning_rate: 7.8125e-05\n",
      "Epoch 47/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 0.1247 - mae: 0.2669 - mse: 0.1245 - val_loss: 0.1266 - val_mae: 0.2690 - val_mse: 0.1264 - learning_rate: 7.8125e-05\n",
      "Epoch 48/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 0.1249 - mae: 0.2670 - mse: 0.1247 - val_loss: 0.1266 - val_mae: 0.2689 - val_mse: 0.1264 - learning_rate: 7.8125e-05\n",
      "Epoch 49/50\n",
      "\u001b[1m3055/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1247 - mae: 0.2669 - mse: 0.1245\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 0.1247 - mae: 0.2669 - mse: 0.1245 - val_loss: 0.1266 - val_mae: 0.2692 - val_mse: 0.1264 - learning_rate: 7.8125e-05\n",
      "Epoch 50/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - loss: 0.1247 - mae: 0.2669 - mse: 0.1246 - val_loss: 0.1265 - val_mae: 0.2690 - val_mse: 0.1264 - learning_rate: 3.9062e-05\n"
     ]
    }
   ],
   "source": [
    "history_tanh_l2 = model_tanh_l2.fit(x=[X_user_train, X_movie_train],y=y_train, callbacks=[early_stop, reduce_lr],\n",
    "    validation_data=([X_user_dev, X_movie_dev], y_dev),epochs=50, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35759e16-2dba-4751-a3c7-83e5e657919a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_user_features = X_user_numpy.shape[1]\n",
    "num_item_features = X_movie_numpy.shape[1]\n",
    "num_outputs = 64\n",
    "\n",
    "# ---------------- USER MODEL ----------------\n",
    "user_input = keras.Input(shape=(num_user_features,), name='user_input')\n",
    "x_user = layers.Dense(128, activation='tanh', kernel_initializer='glorot_uniform', kernel_regularizer= keras.regularizers.l2(0.001))(user_input)\n",
    "x_user = layers.Dense(num_outputs, activation='tanh', kernel_initializer='glorot_uniform')(x_user)\n",
    "user_embedding = layers.Lambda(lambda x: tf.nn.l2_normalize(x, axis=1))(x_user)\n",
    "\n",
    "# ---------------- ITEM MODEL ----------------\n",
    "item_input = keras.Input(shape=(num_item_features,), name='item_input')\n",
    "x_item = layers.Dense(128, activation='tanh', kernel_initializer='glorot_uniform')(item_input)\n",
    "x_item = layers.Dense(num_outputs, activation='tanh', kernel_initializer='glorot_uniform')(x_item)\n",
    "item_embedding = layers.Lambda(lambda x: tf.nn.l2_normalize(x, axis=1))(x_item)\n",
    "\n",
    "# ---------------- COSINE SIMILARITY ----------------\n",
    "cos_sim = layers.Dot(axes=1, name='cosine_similarity')([user_embedding, item_embedding])\n",
    "# rezultat je u [-1, 1]\n",
    "\n",
    "# ---------------- FINAL MODEL ----------------\n",
    "model_tanh_l2 = keras.Model(inputs=[user_input, item_input], outputs=cos_sim)\n",
    "\n",
    "# Kompajliraj model\n",
    "model_tanh_l2.compile(optimizer= keras.optimizers.Nadam(learning_rate= 0.005), loss='mse', metrics=['mae', 'mse'])\n",
    "\n",
    "# Prikaži arhitekturu\n",
    "model_tanh_l2.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "e57ee96a-12ae-4d0b-a850-e1d4f7e20fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 0.1435 - mae: 0.2845 - mse: 0.1391 - val_loss: 0.1325 - val_mae: 0.2754 - val_mse: 0.1313 - learning_rate: 0.0050\n",
      "Epoch 2/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - loss: 0.1324 - mae: 0.2755 - mse: 0.1313 - val_loss: 0.1319 - val_mae: 0.2766 - val_mse: 0.1309 - learning_rate: 0.0050\n",
      "Epoch 3/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - loss: 0.1308 - mae: 0.2737 - mse: 0.1298 - val_loss: 0.1302 - val_mae: 0.2741 - val_mse: 0.1292 - learning_rate: 0.0050\n",
      "Epoch 4/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - loss: 0.1301 - mae: 0.2730 - mse: 0.1292 - val_loss: 0.1294 - val_mae: 0.2719 - val_mse: 0.1285 - learning_rate: 0.0050\n",
      "Epoch 5/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6ms/step - loss: 0.1289 - mae: 0.2716 - mse: 0.1281 - val_loss: 0.1290 - val_mae: 0.2728 - val_mse: 0.1282 - learning_rate: 0.0050\n",
      "Epoch 6/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - loss: 0.1288 - mae: 0.2715 - mse: 0.1280 - val_loss: 0.1284 - val_mae: 0.2711 - val_mse: 0.1276 - learning_rate: 0.0050\n",
      "Epoch 7/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - loss: 0.1284 - mae: 0.2710 - mse: 0.1276 - val_loss: 0.1288 - val_mae: 0.2727 - val_mse: 0.1279 - learning_rate: 0.0050\n",
      "Epoch 8/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - loss: 0.1283 - mae: 0.2709 - mse: 0.1275 - val_loss: 0.1283 - val_mae: 0.2712 - val_mse: 0.1275 - learning_rate: 0.0050\n",
      "Epoch 9/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - loss: 0.1277 - mae: 0.2703 - mse: 0.1269 - val_loss: 0.1282 - val_mae: 0.2708 - val_mse: 0.1274 - learning_rate: 0.0050\n",
      "Epoch 10/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - loss: 0.1277 - mae: 0.2701 - mse: 0.1269 - val_loss: 0.1278 - val_mae: 0.2702 - val_mse: 0.1271 - learning_rate: 0.0050\n",
      "Epoch 11/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6ms/step - loss: 0.1273 - mae: 0.2698 - mse: 0.1266 - val_loss: 0.1278 - val_mae: 0.2703 - val_mse: 0.1271 - learning_rate: 0.0050\n",
      "Epoch 12/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6ms/step - loss: 0.1271 - mae: 0.2695 - mse: 0.1264 - val_loss: 0.1277 - val_mae: 0.2706 - val_mse: 0.1269 - learning_rate: 0.0050\n",
      "Epoch 13/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - loss: 0.1271 - mae: 0.2697 - mse: 0.1264 - val_loss: 0.1280 - val_mae: 0.2703 - val_mse: 0.1272 - learning_rate: 0.0050\n",
      "Epoch 14/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - loss: 0.1268 - mae: 0.2693 - mse: 0.1261 - val_loss: 0.1276 - val_mae: 0.2708 - val_mse: 0.1269 - learning_rate: 0.0050\n",
      "Epoch 15/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1271 - mae: 0.2695 - mse: 0.1264\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - loss: 0.1271 - mae: 0.2695 - mse: 0.1264 - val_loss: 0.1282 - val_mae: 0.2706 - val_mse: 0.1276 - learning_rate: 0.0050\n",
      "Epoch 16/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - loss: 0.1258 - mae: 0.2681 - mse: 0.1253 - val_loss: 0.1259 - val_mae: 0.2681 - val_mse: 0.1254 - learning_rate: 0.0025\n",
      "Epoch 17/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - loss: 0.1250 - mae: 0.2672 - mse: 0.1246 - val_loss: 0.1259 - val_mae: 0.2684 - val_mse: 0.1255 - learning_rate: 0.0025\n",
      "Epoch 18/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - loss: 0.1252 - mae: 0.2673 - mse: 0.1248 - val_loss: 0.1263 - val_mae: 0.2695 - val_mse: 0.1258 - learning_rate: 0.0025\n",
      "Epoch 19/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - loss: 0.1247 - mae: 0.2670 - mse: 0.1243 - val_loss: 0.1257 - val_mae: 0.2674 - val_mse: 0.1252 - learning_rate: 0.0025\n",
      "Epoch 20/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - loss: 0.1244 - mae: 0.2665 - mse: 0.1240 - val_loss: 0.1256 - val_mae: 0.2675 - val_mse: 0.1252 - learning_rate: 0.0025\n",
      "Epoch 21/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - loss: 0.1245 - mae: 0.2667 - mse: 0.1241 - val_loss: 0.1255 - val_mae: 0.2677 - val_mse: 0.1251 - learning_rate: 0.0025\n",
      "Epoch 22/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - loss: 0.1248 - mae: 0.2670 - mse: 0.1243 - val_loss: 0.1260 - val_mae: 0.2687 - val_mse: 0.1255 - learning_rate: 0.0025\n",
      "Epoch 23/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6ms/step - loss: 0.1244 - mae: 0.2666 - mse: 0.1240 - val_loss: 0.1255 - val_mae: 0.2678 - val_mse: 0.1250 - learning_rate: 0.0025\n",
      "Epoch 24/50\n",
      "\u001b[1m3053/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1241 - mae: 0.2663 - mse: 0.1236\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6ms/step - loss: 0.1241 - mae: 0.2663 - mse: 0.1237 - val_loss: 0.1257 - val_mae: 0.2682 - val_mse: 0.1253 - learning_rate: 0.0025\n",
      "Epoch 25/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6ms/step - loss: 0.1236 - mae: 0.2655 - mse: 0.1232 - val_loss: 0.1250 - val_mae: 0.2673 - val_mse: 0.1246 - learning_rate: 0.0012\n",
      "Epoch 26/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - loss: 0.1234 - mae: 0.2655 - mse: 0.1231 - val_loss: 0.1247 - val_mae: 0.2667 - val_mse: 0.1244 - learning_rate: 0.0012\n",
      "Epoch 27/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6ms/step - loss: 0.1230 - mae: 0.2650 - mse: 0.1227 - val_loss: 0.1247 - val_mae: 0.2666 - val_mse: 0.1244 - learning_rate: 0.0012\n",
      "Epoch 28/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6ms/step - loss: 0.1231 - mae: 0.2651 - mse: 0.1228 - val_loss: 0.1247 - val_mae: 0.2672 - val_mse: 0.1244 - learning_rate: 0.0012\n",
      "Epoch 29/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6ms/step - loss: 0.1233 - mae: 0.2652 - mse: 0.1230 - val_loss: 0.1246 - val_mae: 0.2668 - val_mse: 0.1243 - learning_rate: 0.0012\n",
      "Epoch 30/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6ms/step - loss: 0.1231 - mae: 0.2652 - mse: 0.1228 - val_loss: 0.1246 - val_mae: 0.2662 - val_mse: 0.1243 - learning_rate: 0.0012\n",
      "Epoch 31/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6ms/step - loss: 0.1235 - mae: 0.2655 - mse: 0.1233 - val_loss: 0.1245 - val_mae: 0.2662 - val_mse: 0.1242 - learning_rate: 0.0012\n",
      "Epoch 32/50\n",
      "\u001b[1m3052/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1226 - mae: 0.2646 - mse: 0.1223\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6ms/step - loss: 0.1226 - mae: 0.2646 - mse: 0.1223 - val_loss: 0.1246 - val_mae: 0.2662 - val_mse: 0.1243 - learning_rate: 0.0012\n",
      "Epoch 33/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - loss: 0.1225 - mae: 0.2643 - mse: 0.1222 - val_loss: 0.1243 - val_mae: 0.2664 - val_mse: 0.1240 - learning_rate: 6.2500e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - loss: 0.1227 - mae: 0.2644 - mse: 0.1225 - val_loss: 0.1243 - val_mae: 0.2661 - val_mse: 0.1240 - learning_rate: 6.2500e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6ms/step - loss: 0.1222 - mae: 0.2640 - mse: 0.1219 - val_loss: 0.1242 - val_mae: 0.2662 - val_mse: 0.1240 - learning_rate: 6.2500e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1228 - mae: 0.2646 - mse: 0.1225\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - loss: 0.1228 - mae: 0.2646 - mse: 0.1225 - val_loss: 0.1242 - val_mae: 0.2660 - val_mse: 0.1240 - learning_rate: 6.2500e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6ms/step - loss: 0.1220 - mae: 0.2640 - mse: 0.1218 - val_loss: 0.1241 - val_mae: 0.2658 - val_mse: 0.1239 - learning_rate: 3.1250e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - loss: 0.1224 - mae: 0.2642 - mse: 0.1222 - val_loss: 0.1241 - val_mae: 0.2658 - val_mse: 0.1239 - learning_rate: 3.1250e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6ms/step - loss: 0.1221 - mae: 0.2640 - mse: 0.1219 - val_loss: 0.1241 - val_mae: 0.2662 - val_mse: 0.1239 - learning_rate: 3.1250e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1222 - mae: 0.2639 - mse: 0.1220\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6ms/step - loss: 0.1222 - mae: 0.2639 - mse: 0.1220 - val_loss: 0.1241 - val_mae: 0.2660 - val_mse: 0.1239 - learning_rate: 3.1250e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - loss: 0.1219 - mae: 0.2638 - mse: 0.1217 - val_loss: 0.1240 - val_mae: 0.2659 - val_mse: 0.1238 - learning_rate: 1.5625e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6ms/step - loss: 0.1220 - mae: 0.2639 - mse: 0.1218 - val_loss: 0.1240 - val_mae: 0.2659 - val_mse: 0.1238 - learning_rate: 1.5625e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6ms/step - loss: 0.1220 - mae: 0.2638 - mse: 0.1218 - val_loss: 0.1240 - val_mae: 0.2659 - val_mse: 0.1238 - learning_rate: 1.5625e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m3047/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1221 - mae: 0.2639 - mse: 0.1219\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6ms/step - loss: 0.1221 - mae: 0.2639 - mse: 0.1219 - val_loss: 0.1240 - val_mae: 0.2660 - val_mse: 0.1238 - learning_rate: 1.5625e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - loss: 0.1219 - mae: 0.2636 - mse: 0.1217 - val_loss: 0.1240 - val_mae: 0.2659 - val_mse: 0.1238 - learning_rate: 7.8125e-05\n",
      "Epoch 46/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - loss: 0.1218 - mae: 0.2635 - mse: 0.1216 - val_loss: 0.1240 - val_mae: 0.2659 - val_mse: 0.1238 - learning_rate: 7.8125e-05\n",
      "Epoch 47/50\n",
      "\u001b[1m1953/3056\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.1221 - mae: 0.2639 - mse: 0.1219"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[371]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m history_tanh_l2 = \u001b[43mmodel_tanh_l2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_user_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_movie_train\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mearly_stop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_user_dev\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_movie_dev\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_dev\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m512\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:372\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    370\u001b[39m callbacks.on_train_batch_begin(step)\n\u001b[32m    371\u001b[39m logs = \u001b[38;5;28mself\u001b[39m.train_function(iterator)\n\u001b[32m--> \u001b[39m\u001b[32m372\u001b[39m \u001b[43mcallbacks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n\u001b[32m    374\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\keras\\src\\callbacks\\callback_list.py:172\u001b[39m, in \u001b[36mCallbackList.on_train_batch_end\u001b[39m\u001b[34m(self, batch, logs)\u001b[39m\n\u001b[32m    170\u001b[39m     \u001b[38;5;28mself\u001b[39m._async_dispatch(\u001b[38;5;28mself\u001b[39m._on_train_batch_end, batch, logs)\n\u001b[32m    171\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_on_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\keras\\src\\callbacks\\callback_list.py:194\u001b[39m, in \u001b[36mCallbackList._on_train_batch_end\u001b[39m\u001b[34m(self, batch, logs)\u001b[39m\n\u001b[32m    192\u001b[39m logs = python_utils.pythonify_logs(logs)\n\u001b[32m    193\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.callbacks:\n\u001b[32m--> \u001b[39m\u001b[32m194\u001b[39m     \u001b[43mcallback\u001b[49m\u001b[43m.\u001b[49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\keras\\src\\callbacks\\progbar_logger.py:58\u001b[39m, in \u001b[36mProgbarLogger.on_train_batch_end\u001b[39m\u001b[34m(self, batch, logs)\u001b[39m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mon_train_batch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, logs=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_update_progbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\keras\\src\\callbacks\\progbar_logger.py:95\u001b[39m, in \u001b[36mProgbarLogger._update_progbar\u001b[39m\u001b[34m(self, batch, logs)\u001b[39m\n\u001b[32m     92\u001b[39m \u001b[38;5;28mself\u001b[39m.seen = batch + \u001b[32m1\u001b[39m  \u001b[38;5;66;03m# One-indexed.\u001b[39;00m\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprogbar\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mseen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinalize\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\keras\\src\\utils\\progbar.py:182\u001b[39m, in \u001b[36mProgbar.update\u001b[39m\u001b[34m(self, current, values, finalize)\u001b[39m\n\u001b[32m    179\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m finalize:\n\u001b[32m    180\u001b[39m     message += \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m182\u001b[39m \u001b[43mio_utils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprint_msg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mline_break\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    183\u001b[39m \u001b[38;5;28mself\u001b[39m._prev_total_width = total_width\n\u001b[32m    184\u001b[39m message = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\keras\\src\\utils\\io_utils.py:107\u001b[39m, in \u001b[36mprint_msg\u001b[39m\u001b[34m(message, line_break)\u001b[39m\n\u001b[32m    105\u001b[39m         message = message_bytes.decode(sys.stdout.encoding)\n\u001b[32m    106\u001b[39m         sys.stdout.write(message)\n\u001b[32m--> \u001b[39m\u001b[32m107\u001b[39m     \u001b[43msys\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstdout\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflush\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    109\u001b[39m     logging.info(message)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\ipykernel\\iostream.py:609\u001b[39m, in \u001b[36mOutStream.flush\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    607\u001b[39m     \u001b[38;5;28mself\u001b[39m.pub_thread.schedule(evt.set)\n\u001b[32m    608\u001b[39m     \u001b[38;5;66;03m# and give a timeout to avoid\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m609\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mevt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mflush_timeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    610\u001b[39m         \u001b[38;5;66;03m# write directly to __stderr__ instead of warning because\u001b[39;00m\n\u001b[32m    611\u001b[39m         \u001b[38;5;66;03m# if this is happening sys.stderr may be the problem.\u001b[39;00m\n\u001b[32m    612\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mIOStream.flush timed out\u001b[39m\u001b[33m\"\u001b[39m, file=sys.__stderr__)\n\u001b[32m    613\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\threading.py:629\u001b[39m, in \u001b[36mEvent.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    627\u001b[39m signaled = \u001b[38;5;28mself\u001b[39m._flag\n\u001b[32m    628\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[32m--> \u001b[39m\u001b[32m629\u001b[39m     signaled = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cond\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    630\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\threading.py:331\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    329\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    330\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m         gotit = \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    333\u001b[39m         gotit = waiter.acquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "history_tanh_l2 = model_tanh_l2.fit(x=[X_user_train, X_movie_train],y=y_train, callbacks=[early_stop, reduce_lr],\n",
    "    validation_data=([X_user_dev, X_movie_dev], y_dev),epochs=50, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc908a9e-9850-4815-baa0-5b652765be0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "260ebbc6-3285-4cb8-b9f8-6a72bcecef62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_38\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_38\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ item_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_221 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,688</span> │ user_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_223 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,072</span> │ item_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_222 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dense_221[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_224 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dense_223[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lambda_60 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_222[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lambda_61 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_224[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ cosine_similarity (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lambda_60[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           │\n",
       "│                               │                           │                 │ lambda_61[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_input (\u001b[38;5;33mInputLayer\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ item_input (\u001b[38;5;33mInputLayer\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_221 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │           \u001b[38;5;34m2,688\u001b[0m │ user_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_223 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │           \u001b[38;5;34m3,072\u001b[0m │ item_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_222 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m8,256\u001b[0m │ dense_221[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_224 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m8,256\u001b[0m │ dense_223[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lambda_60 (\u001b[38;5;33mLambda\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_222[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lambda_61 (\u001b[38;5;33mLambda\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_224[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ cosine_similarity (\u001b[38;5;33mDot\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │ lambda_60[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           │\n",
       "│                               │                           │                 │ lambda_61[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,272</span> (87.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m22,272\u001b[0m (87.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,272</span> (87.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m22,272\u001b[0m (87.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_user_features = X_user_numpy.shape[1]\n",
    "num_item_features = X_movie_numpy.shape[1]\n",
    "num_outputs = 64\n",
    "\n",
    "# ---------------- USER MODEL ----------------\n",
    "user_input = keras.Input(shape=(num_user_features,), name='user_input')\n",
    "x_user = layers.Dense(128, activation='tanh', kernel_initializer='glorot_uniform', kernel_regularizer= keras.regularizers.l2(0.003))(user_input)\n",
    "x_user = layers.Dense(num_outputs, activation='tanh', kernel_initializer='glorot_uniform')(x_user)\n",
    "user_embedding = layers.Lambda(lambda x: tf.nn.l2_normalize(x, axis=1))(x_user)\n",
    "\n",
    "# ---------------- ITEM MODEL ----------------\n",
    "item_input = keras.Input(shape=(num_item_features,), name='item_input')\n",
    "x_item = layers.Dense(128, activation='tanh', kernel_initializer='glorot_uniform')(item_input)\n",
    "x_item = layers.Dense(num_outputs, activation='tanh', kernel_initializer='glorot_uniform')(x_item)\n",
    "item_embedding = layers.Lambda(lambda x: tf.nn.l2_normalize(x, axis=1))(x_item)\n",
    "\n",
    "# ---------------- COSINE SIMILARITY ----------------\n",
    "cos_sim = layers.Dot(axes=1, name='cosine_similarity')([user_embedding, item_embedding])\n",
    "# rezultat je u [-1, 1]\n",
    "\n",
    "# ---------------- FINAL MODEL ----------------\n",
    "model_tanh_l2 = keras.Model(inputs=[user_input, item_input], outputs=cos_sim)\n",
    "\n",
    "# Kompajliraj model\n",
    "model_tanh_l2.compile(optimizer= keras.optimizers.Nadam(learning_rate= 0.005), loss='mse', metrics=['mae', 'mse'])\n",
    "\n",
    "# Prikaži arhitekturu\n",
    "model_tanh_l2.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "74f2be04-8868-4d60-88ab-915a7b103855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - loss: 0.1466 - mae: 0.2852 - mse: 0.1395 - val_loss: 0.1331 - val_mae: 0.2757 - val_mse: 0.1318 - learning_rate: 0.0050\n",
      "Epoch 2/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - loss: 0.1327 - mae: 0.2758 - mse: 0.1315 - val_loss: 0.1314 - val_mae: 0.2742 - val_mse: 0.1302 - learning_rate: 0.0050\n",
      "Epoch 3/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - loss: 0.1313 - mae: 0.2742 - mse: 0.1302 - val_loss: 0.1313 - val_mae: 0.2766 - val_mse: 0.1303 - learning_rate: 0.0050\n",
      "Epoch 4/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6ms/step - loss: 0.1301 - mae: 0.2730 - mse: 0.1291 - val_loss: 0.1295 - val_mae: 0.2727 - val_mse: 0.1286 - learning_rate: 0.0050\n",
      "Epoch 5/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - loss: 0.1297 - mae: 0.2728 - mse: 0.1288 - val_loss: 0.1301 - val_mae: 0.2722 - val_mse: 0.1292 - learning_rate: 0.0050\n",
      "Epoch 6/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - loss: 0.1290 - mae: 0.2719 - mse: 0.1281 - val_loss: 0.1291 - val_mae: 0.2716 - val_mse: 0.1283 - learning_rate: 0.0050\n",
      "Epoch 7/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6ms/step - loss: 0.1287 - mae: 0.2714 - mse: 0.1278 - val_loss: 0.1287 - val_mae: 0.2723 - val_mse: 0.1279 - learning_rate: 0.0050\n",
      "Epoch 8/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - loss: 0.1280 - mae: 0.2707 - mse: 0.1272 - val_loss: 0.1285 - val_mae: 0.2713 - val_mse: 0.1277 - learning_rate: 0.0050\n",
      "Epoch 9/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - loss: 0.1282 - mae: 0.2708 - mse: 0.1273 - val_loss: 0.1287 - val_mae: 0.2719 - val_mse: 0.1278 - learning_rate: 0.0050\n",
      "Epoch 10/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - loss: 0.1281 - mae: 0.2708 - mse: 0.1273 - val_loss: 0.1283 - val_mae: 0.2714 - val_mse: 0.1275 - learning_rate: 0.0050\n",
      "Epoch 11/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - loss: 0.1276 - mae: 0.2701 - mse: 0.1268 - val_loss: 0.1279 - val_mae: 0.2707 - val_mse: 0.1271 - learning_rate: 0.0050\n",
      "Epoch 12/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6ms/step - loss: 0.1275 - mae: 0.2701 - mse: 0.1267 - val_loss: 0.1280 - val_mae: 0.2716 - val_mse: 0.1272 - learning_rate: 0.0050\n",
      "Epoch 13/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - loss: 0.1275 - mae: 0.2700 - mse: 0.1267 - val_loss: 0.1278 - val_mae: 0.2705 - val_mse: 0.1270 - learning_rate: 0.0050\n",
      "Epoch 14/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1276 - mae: 0.2702 - mse: 0.1268\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6ms/step - loss: 0.1276 - mae: 0.2702 - mse: 0.1268 - val_loss: 0.1282 - val_mae: 0.2709 - val_mse: 0.1274 - learning_rate: 0.0050\n",
      "Epoch 15/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6ms/step - loss: 0.1262 - mae: 0.2688 - mse: 0.1257 - val_loss: 0.1265 - val_mae: 0.2687 - val_mse: 0.1260 - learning_rate: 0.0025\n",
      "Epoch 16/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - loss: 0.1254 - mae: 0.2676 - mse: 0.1249 - val_loss: 0.1260 - val_mae: 0.2687 - val_mse: 0.1255 - learning_rate: 0.0025\n",
      "Epoch 17/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6ms/step - loss: 0.1254 - mae: 0.2676 - mse: 0.1249 - val_loss: 0.1261 - val_mae: 0.2685 - val_mse: 0.1256 - learning_rate: 0.0025\n",
      "Epoch 18/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6ms/step - loss: 0.1252 - mae: 0.2674 - mse: 0.1247 - val_loss: 0.1259 - val_mae: 0.2686 - val_mse: 0.1255 - learning_rate: 0.0025\n",
      "Epoch 19/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - loss: 0.1255 - mae: 0.2677 - mse: 0.1250 - val_loss: 0.1260 - val_mae: 0.2677 - val_mse: 0.1255 - learning_rate: 0.0025\n",
      "Epoch 20/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6ms/step - loss: 0.1250 - mae: 0.2670 - mse: 0.1245 - val_loss: 0.1256 - val_mae: 0.2682 - val_mse: 0.1251 - learning_rate: 0.0025\n",
      "Epoch 21/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6ms/step - loss: 0.1246 - mae: 0.2668 - mse: 0.1241 - val_loss: 0.1257 - val_mae: 0.2671 - val_mse: 0.1253 - learning_rate: 0.0025\n",
      "Epoch 22/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6ms/step - loss: 0.1245 - mae: 0.2666 - mse: 0.1240 - val_loss: 0.1262 - val_mae: 0.2692 - val_mse: 0.1258 - learning_rate: 0.0025\n",
      "Epoch 23/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1248 - mae: 0.2669 - mse: 0.1244\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - loss: 0.1248 - mae: 0.2669 - mse: 0.1244 - val_loss: 0.1258 - val_mae: 0.2672 - val_mse: 0.1253 - learning_rate: 0.0025\n",
      "Epoch 24/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6ms/step - loss: 0.1240 - mae: 0.2659 - mse: 0.1236 - val_loss: 0.1250 - val_mae: 0.2672 - val_mse: 0.1246 - learning_rate: 0.0012\n",
      "Epoch 25/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6ms/step - loss: 0.1235 - mae: 0.2655 - mse: 0.1232 - val_loss: 0.1247 - val_mae: 0.2663 - val_mse: 0.1244 - learning_rate: 0.0012\n",
      "Epoch 26/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - loss: 0.1236 - mae: 0.2656 - mse: 0.1233 - val_loss: 0.1249 - val_mae: 0.2667 - val_mse: 0.1245 - learning_rate: 0.0012\n",
      "Epoch 27/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1232 - mae: 0.2650 - mse: 0.1228 - val_loss: 0.1247 - val_mae: 0.2669 - val_mse: 0.1244 - learning_rate: 0.0012\n",
      "Epoch 28/50\n",
      "\u001b[1m3046/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1236 - mae: 0.2655 - mse: 0.1233\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - loss: 0.1236 - mae: 0.2655 - mse: 0.1233 - val_loss: 0.1248 - val_mae: 0.2667 - val_mse: 0.1245 - learning_rate: 0.0012\n",
      "Epoch 29/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - loss: 0.1230 - mae: 0.2648 - mse: 0.1228 - val_loss: 0.1245 - val_mae: 0.2662 - val_mse: 0.1242 - learning_rate: 6.2500e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - loss: 0.1229 - mae: 0.2648 - mse: 0.1226 - val_loss: 0.1244 - val_mae: 0.2666 - val_mse: 0.1242 - learning_rate: 6.2500e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1227 - mae: 0.2645 - mse: 0.1224 - val_loss: 0.1244 - val_mae: 0.2664 - val_mse: 0.1242 - learning_rate: 6.2500e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m3053/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1225 - mae: 0.2643 - mse: 0.1223\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - loss: 0.1225 - mae: 0.2643 - mse: 0.1223 - val_loss: 0.1245 - val_mae: 0.2666 - val_mse: 0.1242 - learning_rate: 6.2500e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1225 - mae: 0.2643 - mse: 0.1223 - val_loss: 0.1242 - val_mae: 0.2661 - val_mse: 0.1240 - learning_rate: 3.1250e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - loss: 0.1222 - mae: 0.2641 - mse: 0.1220 - val_loss: 0.1242 - val_mae: 0.2663 - val_mse: 0.1240 - learning_rate: 3.1250e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - loss: 0.1223 - mae: 0.2640 - mse: 0.1221 - val_loss: 0.1242 - val_mae: 0.2664 - val_mse: 0.1240 - learning_rate: 3.1250e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1224 - mae: 0.2643 - mse: 0.1222\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - loss: 0.1224 - mae: 0.2643 - mse: 0.1222 - val_loss: 0.1242 - val_mae: 0.2662 - val_mse: 0.1240 - learning_rate: 3.1250e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6ms/step - loss: 0.1225 - mae: 0.2644 - mse: 0.1223 - val_loss: 0.1241 - val_mae: 0.2662 - val_mse: 0.1240 - learning_rate: 1.5625e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m 581/3056\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - loss: 0.1229 - mae: 0.2648 - mse: 0.1227"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[377]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m history_tanh_l2 = \u001b[43mmodel_tanh_l2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_user_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_movie_train\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mearly_stop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_user_dev\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_movie_dev\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_dev\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m512\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:371\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    370\u001b[39m     callbacks.on_train_batch_begin(step)\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    372\u001b[39m     callbacks.on_train_batch_end(step, logs)\n\u001b[32m    373\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:219\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    217\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    218\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    220\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    221\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m    138\u001b[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bound_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1688\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1686\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1687\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1688\u001b[39m   outputs = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1689\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1690\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1691\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1696\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1697\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1698\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1702\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1703\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "history_tanh_l2 = model_tanh_l2.fit(x=[X_user_train, X_movie_train],y=y_train, callbacks=[early_stop, reduce_lr],\n",
    "    validation_data=([X_user_dev, X_movie_dev], y_dev),epochs=50, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "49bedbf4-6980-4cfc-871b-2ce262455583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_39\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_39\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ item_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_225 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,688</span> │ user_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_227 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,072</span> │ item_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_226 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dense_225[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_228 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dense_227[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lambda_62 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_226[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lambda_63 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_228[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ cosine_similarity (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lambda_62[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           │\n",
       "│                               │                           │                 │ lambda_63[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_input (\u001b[38;5;33mInputLayer\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ item_input (\u001b[38;5;33mInputLayer\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_225 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │           \u001b[38;5;34m2,688\u001b[0m │ user_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_227 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │           \u001b[38;5;34m3,072\u001b[0m │ item_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_226 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m8,256\u001b[0m │ dense_225[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_228 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m8,256\u001b[0m │ dense_227[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lambda_62 (\u001b[38;5;33mLambda\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_226[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lambda_63 (\u001b[38;5;33mLambda\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_228[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ cosine_similarity (\u001b[38;5;33mDot\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │ lambda_62[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           │\n",
       "│                               │                           │                 │ lambda_63[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,272</span> (87.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m22,272\u001b[0m (87.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,272</span> (87.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m22,272\u001b[0m (87.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_user_features = X_user_numpy.shape[1]\n",
    "num_item_features = X_movie_numpy.shape[1]\n",
    "num_outputs = 64\n",
    "\n",
    "# ---------------- USER MODEL ----------------\n",
    "user_input = keras.Input(shape=(num_user_features,), name='user_input')\n",
    "x_user = layers.Dense(128, activation='tanh', kernel_initializer='glorot_uniform', kernel_regularizer= keras.regularizers.l2(0.001))(user_input)\n",
    "x_user = layers.Dense(num_outputs, activation='tanh', kernel_initializer='glorot_uniform')(x_user)\n",
    "user_embedding = layers.Lambda(lambda x: tf.nn.l2_normalize(x, axis=1))(x_user)\n",
    "\n",
    "# ---------------- ITEM MODEL ----------------\n",
    "item_input = keras.Input(shape=(num_item_features,), name='item_input')\n",
    "x_item = layers.Dense(128, activation='tanh', kernel_initializer='glorot_uniform', kernel_regularizer= keras.regularizers.l2(0.0001))(item_input)\n",
    "x_item = layers.Dense(num_outputs, activation='tanh', kernel_initializer='glorot_uniform')(x_item)\n",
    "item_embedding = layers.Lambda(lambda x: tf.nn.l2_normalize(x, axis=1))(x_item)\n",
    "\n",
    "# ---------------- COSINE SIMILARITY ----------------\n",
    "cos_sim = layers.Dot(axes=1, name='cosine_similarity')([user_embedding, item_embedding])\n",
    "# rezultat je u [-1, 1]\n",
    "\n",
    "# ---------------- FINAL MODEL ----------------\n",
    "model_tanh_l2 = keras.Model(inputs=[user_input, item_input], outputs=cos_sim)\n",
    "\n",
    "# Kompajliraj model\n",
    "model_tanh_l2.compile(optimizer= keras.optimizers.Nadam(learning_rate= 0.005), loss='mse', metrics=['mae', 'mse'])\n",
    "\n",
    "# Prikaži arhitekturu\n",
    "model_tanh_l2.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "800a764c-1fb5-41d3-9f22-e5ffecafad8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - loss: 0.1457 - mae: 0.2847 - mse: 0.1392 - val_loss: 0.1355 - val_mae: 0.2767 - val_mse: 0.1329 - learning_rate: 0.0050\n",
      "Epoch 2/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - loss: 0.1356 - mae: 0.2773 - mse: 0.1330 - val_loss: 0.1344 - val_mae: 0.2766 - val_mse: 0.1320 - learning_rate: 0.0050\n",
      "Epoch 3/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - loss: 0.1348 - mae: 0.2762 - mse: 0.1323 - val_loss: 0.1348 - val_mae: 0.2768 - val_mse: 0.1324 - learning_rate: 0.0050\n",
      "Epoch 4/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6ms/step - loss: 0.1342 - mae: 0.2756 - mse: 0.1319 - val_loss: 0.1350 - val_mae: 0.2753 - val_mse: 0.1329 - learning_rate: 0.0050\n",
      "Epoch 5/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6ms/step - loss: 0.1341 - mae: 0.2755 - mse: 0.1318 - val_loss: 0.1336 - val_mae: 0.2747 - val_mse: 0.1314 - learning_rate: 0.0050\n",
      "Epoch 6/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6ms/step - loss: 0.1340 - mae: 0.2754 - mse: 0.1317 - val_loss: 0.1331 - val_mae: 0.2735 - val_mse: 0.1310 - learning_rate: 0.0050\n",
      "Epoch 7/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - loss: 0.1338 - mae: 0.2752 - mse: 0.1316 - val_loss: 0.1338 - val_mae: 0.2765 - val_mse: 0.1316 - learning_rate: 0.0050\n",
      "Epoch 8/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - loss: 0.1338 - mae: 0.2751 - mse: 0.1316 - val_loss: 0.1337 - val_mae: 0.2749 - val_mse: 0.1315 - learning_rate: 0.0050\n",
      "Epoch 9/50\n",
      "\u001b[1m3055/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1336 - mae: 0.2751 - mse: 0.1315\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - loss: 0.1336 - mae: 0.2751 - mse: 0.1315 - val_loss: 0.1334 - val_mae: 0.2742 - val_mse: 0.1312 - learning_rate: 0.0050\n",
      "Epoch 10/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6ms/step - loss: 0.1318 - mae: 0.2731 - mse: 0.1300 - val_loss: 0.1329 - val_mae: 0.2770 - val_mse: 0.1313 - learning_rate: 0.0025\n",
      "Epoch 11/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6ms/step - loss: 0.1319 - mae: 0.2734 - mse: 0.1303 - val_loss: 0.1318 - val_mae: 0.2746 - val_mse: 0.1303 - learning_rate: 0.0025\n",
      "Epoch 12/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6ms/step - loss: 0.1319 - mae: 0.2736 - mse: 0.1304 - val_loss: 0.1322 - val_mae: 0.2749 - val_mse: 0.1307 - learning_rate: 0.0025\n",
      "Epoch 13/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - loss: 0.1315 - mae: 0.2732 - mse: 0.1300 - val_loss: 0.1316 - val_mae: 0.2747 - val_mse: 0.1301 - learning_rate: 0.0025\n",
      "Epoch 14/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - loss: 0.1318 - mae: 0.2735 - mse: 0.1303 - val_loss: 0.1317 - val_mae: 0.2727 - val_mse: 0.1302 - learning_rate: 0.0025\n",
      "Epoch 15/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - loss: 0.1314 - mae: 0.2730 - mse: 0.1299 - val_loss: 0.1314 - val_mae: 0.2739 - val_mse: 0.1299 - learning_rate: 0.0025\n",
      "Epoch 16/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - loss: 0.1315 - mae: 0.2731 - mse: 0.1300 - val_loss: 0.1329 - val_mae: 0.2734 - val_mse: 0.1314 - learning_rate: 0.0025\n",
      "Epoch 17/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - loss: 0.1317 - mae: 0.2732 - mse: 0.1301 - val_loss: 0.1313 - val_mae: 0.2729 - val_mse: 0.1298 - learning_rate: 0.0025\n",
      "Epoch 18/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - loss: 0.1314 - mae: 0.2730 - mse: 0.1299 - val_loss: 0.1330 - val_mae: 0.2760 - val_mse: 0.1315 - learning_rate: 0.0025\n",
      "Epoch 19/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - loss: 0.1315 - mae: 0.2731 - mse: 0.1301 - val_loss: 0.1322 - val_mae: 0.2764 - val_mse: 0.1307 - learning_rate: 0.0025\n",
      "Epoch 20/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - loss: 0.1316 - mae: 0.2733 - mse: 0.1301 - val_loss: 0.1311 - val_mae: 0.2726 - val_mse: 0.1296 - learning_rate: 0.0025\n",
      "Epoch 21/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - loss: 0.1315 - mae: 0.2730 - mse: 0.1300 - val_loss: 0.1316 - val_mae: 0.2736 - val_mse: 0.1301 - learning_rate: 0.0025\n",
      "Epoch 22/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - loss: 0.1316 - mae: 0.2731 - mse: 0.1300 - val_loss: 0.1315 - val_mae: 0.2740 - val_mse: 0.1300 - learning_rate: 0.0025\n",
      "Epoch 23/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1314 - mae: 0.2729 - mse: 0.1299\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - loss: 0.1314 - mae: 0.2729 - mse: 0.1299 - val_loss: 0.1311 - val_mae: 0.2718 - val_mse: 0.1296 - learning_rate: 0.0025\n",
      "Epoch 24/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - loss: 0.1307 - mae: 0.2721 - mse: 0.1293 - val_loss: 0.1304 - val_mae: 0.2728 - val_mse: 0.1292 - learning_rate: 0.0012\n",
      "Epoch 25/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - loss: 0.1304 - mae: 0.2721 - mse: 0.1291 - val_loss: 0.1303 - val_mae: 0.2725 - val_mse: 0.1291 - learning_rate: 0.0012\n",
      "Epoch 26/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - loss: 0.1301 - mae: 0.2717 - mse: 0.1289 - val_loss: 0.1302 - val_mae: 0.2724 - val_mse: 0.1290 - learning_rate: 0.0012\n",
      "Epoch 27/50\n",
      "\u001b[1m1001/3056\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - loss: 0.1305 - mae: 0.2721 - mse: 0.1293"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[380]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m history_tanh_l2 = \u001b[43mmodel_tanh_l2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_user_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_movie_train\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mearly_stop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_user_dev\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_movie_dev\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_dev\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m512\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:371\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    370\u001b[39m     callbacks.on_train_batch_begin(step)\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    372\u001b[39m     callbacks.on_train_batch_end(step, logs)\n\u001b[32m    373\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:219\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    217\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    218\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    220\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    221\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m    138\u001b[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bound_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1688\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1686\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1687\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1688\u001b[39m   outputs = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1689\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1690\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1691\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1696\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1697\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1698\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1702\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1703\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "history_tanh_l2 = model_tanh_l2.fit(x=[X_user_train, X_movie_train],y=y_train, callbacks=[early_stop, reduce_lr],\n",
    "    validation_data=([X_user_dev, X_movie_dev], y_dev),epochs=50, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ff37f4-370e-4ec0-973f-3a457d15e191",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "4e9567a6-df42-4d1f-ad85-8874b8cbfe2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_49\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_49\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ item_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_265 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,688</span> │ user_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_267 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,072</span> │ item_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_36        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ dense_265[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_38        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ dense_267[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_266 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ batch_normalization_36[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_268 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ batch_normalization_38[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_37        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ dense_266[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_39        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ dense_268[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lambda_82 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_37[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lambda_83 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_39[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ cosine_similarity (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lambda_82[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           │\n",
       "│                               │                           │                 │ lambda_83[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_input (\u001b[38;5;33mInputLayer\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ item_input (\u001b[38;5;33mInputLayer\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_265 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │           \u001b[38;5;34m2,688\u001b[0m │ user_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_267 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │           \u001b[38;5;34m3,072\u001b[0m │ item_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_36        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │             \u001b[38;5;34m512\u001b[0m │ dense_265[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_38        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │             \u001b[38;5;34m512\u001b[0m │ dense_267[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_266 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m8,256\u001b[0m │ batch_normalization_36[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_268 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m8,256\u001b[0m │ batch_normalization_38[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_37        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │             \u001b[38;5;34m256\u001b[0m │ dense_266[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_39        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │             \u001b[38;5;34m256\u001b[0m │ dense_268[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lambda_82 (\u001b[38;5;33mLambda\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ batch_normalization_37[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lambda_83 (\u001b[38;5;33mLambda\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ batch_normalization_39[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ cosine_similarity (\u001b[38;5;33mDot\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │ lambda_82[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           │\n",
       "│                               │                           │                 │ lambda_83[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,808</span> (93.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m23,808\u001b[0m (93.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,040</span> (90.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m23,040\u001b[0m (90.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> (3.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m768\u001b[0m (3.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_user_features = X_user_numpy.shape[1]\n",
    "num_item_features = X_movie_numpy.shape[1]\n",
    "num_outputs = 64\n",
    "\n",
    "# ---------------- USER MODEL ----------------\n",
    "user_input = keras.Input(shape=(num_user_features,), name='user_input')\n",
    "x_user = layers.Dense(128, activation='tanh', kernel_initializer='glorot_uniform')(user_input)\n",
    "x_user = layers.BatchNormalization()(x_user)\n",
    "\n",
    "x_user = layers.Dense(num_outputs, activation='tanh', kernel_initializer='glorot_uniform')(x_user)\n",
    "x_user = layers.BatchNormalization()(x_user)\n",
    "user_embedding = layers.Lambda(lambda x: tf.nn.l2_normalize(x, axis=1))(x_user)\n",
    "\n",
    "# ---------------- ITEM MODEL ----------------\n",
    "item_input = keras.Input(shape=(num_item_features,), name='item_input')\n",
    "x_item = layers.Dense(128, activation='tanh', kernel_initializer='glorot_uniform')(item_input)\n",
    "x_item = layers.BatchNormalization()(x_item)\n",
    "\n",
    "x_item = layers.Dense(num_outputs, activation='tanh', kernel_initializer='glorot_uniform')(x_item)\n",
    "x_item = layers.BatchNormalization()(x_item)\n",
    "\n",
    "item_embedding = layers.Lambda(lambda x: tf.nn.l2_normalize(x, axis=1))(x_item)\n",
    "\n",
    "# ---------------- COSINE SIMILARITY ----------------\n",
    "cos_sim = layers.Dot(axes=1, name='cosine_similarity')([user_embedding, item_embedding])\n",
    "# rezultat je u [-1, 1]\n",
    "\n",
    "# ---------------- FINAL MODEL ----------------\n",
    "model_tanh_l2 = keras.Model(inputs=[user_input, item_input], outputs=cos_sim)\n",
    "\n",
    "# Kompajliraj model\n",
    "model_tanh_l2.compile(optimizer= keras.optimizers.Nadam(learning_rate= 0.001), loss='mse', metrics=['mae', 'mse'])\n",
    "\n",
    "# Prikaži arhitekturu\n",
    "model_tanh_l2.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "043f1ed2-db5e-4151-81b7-8e70f0dbe9ac",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 137. MiB for an array with shape (1564500, 23) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMemoryError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[430]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m history_tanh_l2 = \u001b[43mmodel_tanh_l2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_user_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_movie_train\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mearly_stop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_user_dev\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_movie_dev\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_dev\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m512\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\optree\\ops.py:766\u001b[39m, in \u001b[36mtree_map\u001b[39m\u001b[34m(func, tree, is_leaf, none_is_leaf, namespace, *rests)\u001b[39m\n\u001b[32m    764\u001b[39m leaves, treespec = _C.flatten(tree, is_leaf, none_is_leaf, namespace)\n\u001b[32m    765\u001b[39m flat_args = [leaves] + [treespec.flatten_up_to(r) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rests]\n\u001b[32m--> \u001b[39m\u001b[32m766\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtreespec\u001b[49m\u001b[43m.\u001b[49m\u001b[43munflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mflat_args\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mMemoryError\u001b[39m: Unable to allocate 137. MiB for an array with shape (1564500, 23) and data type float32"
     ]
    }
   ],
   "source": [
    "history_tanh_l2 = model_tanh_l2.fit(x=[X_user_train, X_movie_train],y=y_train, callbacks=[early_stop, reduce_lr],\n",
    "    validation_data=([X_user_dev, X_movie_dev], y_dev),epochs=50, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecaddc91-f4ac-4cc4-bd24-a18ee8a9bba2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10297ab7-e248-4e1d-8316-3d11ccf64eb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11401e2-296c-48f4-b8d7-8ef696d5dbed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "423bbbb2-7300-4cd5-a99b-f7a3f93708c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - loss: 0.1245 - mae: 0.2668 - mse: 0.1244 - val_loss: 0.1265 - val_mae: 0.2691 - val_mse: 0.1264 - learning_rate: 3.9062e-05\n",
      "Epoch 2/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 0.1245 - mae: 0.2667 - mse: 0.1244 - val_loss: 0.1265 - val_mae: 0.2690 - val_mse: 0.1264 - learning_rate: 3.9062e-05\n",
      "Epoch 3/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 0.1246 - mae: 0.2669 - mse: 0.1245 - val_loss: 0.1265 - val_mae: 0.2690 - val_mse: 0.1264 - learning_rate: 3.9062e-05\n",
      "Epoch 4/50\n",
      "\u001b[1m3055/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1247 - mae: 0.2670 - mse: 0.1246\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 1.9531249563442543e-05.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 0.1247 - mae: 0.2670 - mse: 0.1246 - val_loss: 0.1265 - val_mae: 0.2691 - val_mse: 0.1264 - learning_rate: 3.9062e-05\n",
      "Epoch 5/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 0.1244 - mae: 0.2668 - mse: 0.1243 - val_loss: 0.1265 - val_mae: 0.2691 - val_mse: 0.1264 - learning_rate: 1.9531e-05\n",
      "Epoch 6/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 0.1245 - mae: 0.2667 - mse: 0.1243 - val_loss: 0.1265 - val_mae: 0.2690 - val_mse: 0.1264 - learning_rate: 1.9531e-05\n",
      "Epoch 7/50\n",
      "\u001b[1m3047/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1249 - mae: 0.2670 - mse: 0.1248\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 9.765624781721272e-06.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 0.1249 - mae: 0.2670 - mse: 0.1248 - val_loss: 0.1265 - val_mae: 0.2691 - val_mse: 0.1264 - learning_rate: 1.9531e-05\n",
      "Epoch 8/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 0.1250 - mae: 0.2672 - mse: 0.1248 - val_loss: 0.1265 - val_mae: 0.2690 - val_mse: 0.1264 - learning_rate: 9.7656e-06\n",
      "Epoch 9/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 0.1252 - mae: 0.2675 - mse: 0.1250 - val_loss: 0.1265 - val_mae: 0.2690 - val_mse: 0.1264 - learning_rate: 9.7656e-06\n",
      "Epoch 10/50\n",
      "\u001b[1m3053/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1243 - mae: 0.2666 - mse: 0.1242\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 4.882812390860636e-06.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 0.1243 - mae: 0.2666 - mse: 0.1242 - val_loss: 0.1265 - val_mae: 0.2690 - val_mse: 0.1264 - learning_rate: 9.7656e-06\n",
      "Epoch 11/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 0.1246 - mae: 0.2669 - mse: 0.1245 - val_loss: 0.1265 - val_mae: 0.2691 - val_mse: 0.1264 - learning_rate: 4.8828e-06\n",
      "Epoch 12/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 0.1247 - mae: 0.2670 - mse: 0.1246 - val_loss: 0.1265 - val_mae: 0.2690 - val_mse: 0.1264 - learning_rate: 4.8828e-06\n",
      "Epoch 13/50\n",
      "\u001b[1m3048/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1249 - mae: 0.2671 - mse: 0.1248\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 2.441406195430318e-06.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 0.1249 - mae: 0.2671 - mse: 0.1248 - val_loss: 0.1265 - val_mae: 0.2690 - val_mse: 0.1264 - learning_rate: 4.8828e-06\n",
      "Epoch 14/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 0.1248 - mae: 0.2670 - mse: 0.1246 - val_loss: 0.1265 - val_mae: 0.2690 - val_mse: 0.1264 - learning_rate: 2.4414e-06\n",
      "Epoch 15/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 0.1246 - mae: 0.2668 - mse: 0.1244 - val_loss: 0.1265 - val_mae: 0.2690 - val_mse: 0.1264 - learning_rate: 2.4414e-06\n",
      "Epoch 16/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1248 - mae: 0.2672 - mse: 0.1247\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 1.220703097715159e-06.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 0.1248 - mae: 0.2672 - mse: 0.1247 - val_loss: 0.1265 - val_mae: 0.2690 - val_mse: 0.1264 - learning_rate: 2.4414e-06\n"
     ]
    }
   ],
   "source": [
    "history_tanh_l2 = model_tanh_l2.fit(x=[X_user_train, X_movie_train],y=y_train, callbacks=[early_stop, reduce_lr],\n",
    "    validation_data=([X_user_dev, X_movie_dev], y_dev),epochs=50, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60874906-337a-451d-8229-7643268b4e21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "6e0453a1-6730-4df9-91bc-fc3324ce5b26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_36\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_36\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ item_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_213 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,688</span> │ user_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_215 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,072</span> │ item_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_214 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dense_213[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_216 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dense_215[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lambda_56 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_214[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lambda_57 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_216[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ cosine_similarity (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lambda_56[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           │\n",
       "│                               │                           │                 │ lambda_57[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_input (\u001b[38;5;33mInputLayer\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ item_input (\u001b[38;5;33mInputLayer\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_213 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │           \u001b[38;5;34m2,688\u001b[0m │ user_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_215 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │           \u001b[38;5;34m3,072\u001b[0m │ item_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_214 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m8,256\u001b[0m │ dense_213[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_216 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m8,256\u001b[0m │ dense_215[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lambda_56 (\u001b[38;5;33mLambda\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_214[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lambda_57 (\u001b[38;5;33mLambda\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_216[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ cosine_similarity (\u001b[38;5;33mDot\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │ lambda_56[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           │\n",
       "│                               │                           │                 │ lambda_57[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,272</span> (87.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m22,272\u001b[0m (87.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,272</span> (87.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m22,272\u001b[0m (87.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_user_features = X_user_numpy.shape[1]\n",
    "num_item_features = X_movie_numpy.shape[1]\n",
    "num_outputs = 64\n",
    "\n",
    "# ---------------- USER MODEL ----------------\n",
    "user_input = keras.Input(shape=(num_user_features,), name='user_input')\n",
    "x_user = layers.Dense(128, activation='tanh', kernel_initializer='glorot_uniform', kernel_regularizer= keras.regularizers.l2(0.0001))(user_input)\n",
    "x_user = layers.Dense(num_outputs, activation='tanh', kernel_initializer='glorot_uniform')(x_user)\n",
    "user_embedding = layers.Lambda(lambda x: tf.nn.l2_normalize(x, axis=1))(x_user)\n",
    "\n",
    "# ---------------- ITEM MODEL ----------------\n",
    "item_input = keras.Input(shape=(num_item_features,), name='item_input')\n",
    "x_item = layers.Dense(128, activation='tanh', kernel_initializer='glorot_uniform', kernel_regularizer= keras.regularizers.l2(0.0001))(item_input)\n",
    "x_item = layers.Dense(num_outputs, activation='tanh', kernel_initializer='glorot_uniform')(x_item)\n",
    "item_embedding = layers.Lambda(lambda x: tf.nn.l2_normalize(x, axis=1))(x_item)\n",
    "\n",
    "# ---------------- COSINE SIMILARITY ----------------\n",
    "cos_sim = layers.Dot(axes=1, name='cosine_similarity')([user_embedding, item_embedding])\n",
    "# rezultat je u [-1, 1]\n",
    "\n",
    "# ---------------- FINAL MODEL ----------------\n",
    "model_tanh_l2 = keras.Model(inputs=[user_input, item_input], outputs=cos_sim)\n",
    "\n",
    "# Kompajliraj model\n",
    "model_tanh_l2.compile(optimizer= keras.optimizers.Nadam(learning_rate= 0.01), loss='mse', metrics=['mae', 'mse'])\n",
    "\n",
    "# Prikaži arhitekturu\n",
    "model_tanh_l2.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "00e40dcf-d976-4660-bbfd-5833c810c202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 0.1445 - mae: 0.2857 - mse: 0.1402 - val_loss: 0.1372 - val_mae: 0.2793 - val_mse: 0.1341 - learning_rate: 0.0100\n",
      "Epoch 2/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - loss: 0.1378 - mae: 0.2790 - mse: 0.1346 - val_loss: 0.1381 - val_mae: 0.2788 - val_mse: 0.1349 - learning_rate: 0.0100\n",
      "Epoch 3/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6ms/step - loss: 0.1385 - mae: 0.2799 - mse: 0.1351 - val_loss: 0.1382 - val_mae: 0.2781 - val_mse: 0.1349 - learning_rate: 0.0100\n",
      "Epoch 4/50\n",
      "\u001b[1m3051/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1381 - mae: 0.2795 - mse: 0.1348\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - loss: 0.1381 - mae: 0.2795 - mse: 0.1348 - val_loss: 0.1383 - val_mae: 0.2777 - val_mse: 0.1349 - learning_rate: 0.0100\n",
      "Epoch 5/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6ms/step - loss: 0.1357 - mae: 0.2771 - mse: 0.1331 - val_loss: 0.1352 - val_mae: 0.2753 - val_mse: 0.1330 - learning_rate: 0.0050\n",
      "Epoch 6/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - loss: 0.1345 - mae: 0.2761 - mse: 0.1324 - val_loss: 0.1349 - val_mae: 0.2768 - val_mse: 0.1328 - learning_rate: 0.0050\n",
      "Epoch 7/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - loss: 0.1345 - mae: 0.2762 - mse: 0.1324 - val_loss: 0.1349 - val_mae: 0.2753 - val_mse: 0.1328 - learning_rate: 0.0050\n",
      "Epoch 8/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - loss: 0.1345 - mae: 0.2761 - mse: 0.1324 - val_loss: 0.1351 - val_mae: 0.2787 - val_mse: 0.1329 - learning_rate: 0.0050\n",
      "Epoch 9/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - loss: 0.1343 - mae: 0.2760 - mse: 0.1322 - val_loss: 0.1339 - val_mae: 0.2760 - val_mse: 0.1318 - learning_rate: 0.0050\n",
      "Epoch 10/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - loss: 0.1345 - mae: 0.2758 - mse: 0.1324 - val_loss: 0.1354 - val_mae: 0.2754 - val_mse: 0.1334 - learning_rate: 0.0050\n",
      "Epoch 11/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - loss: 0.1342 - mae: 0.2758 - mse: 0.1322 - val_loss: 0.1345 - val_mae: 0.2773 - val_mse: 0.1325 - learning_rate: 0.0050\n",
      "Epoch 12/50\n",
      "\u001b[1m3047/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1342 - mae: 0.2758 - mse: 0.1322\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - loss: 0.1342 - mae: 0.2758 - mse: 0.1322 - val_loss: 0.1344 - val_mae: 0.2771 - val_mse: 0.1324 - learning_rate: 0.0050\n",
      "Epoch 13/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6ms/step - loss: 0.1324 - mae: 0.2738 - mse: 0.1307 - val_loss: 0.1325 - val_mae: 0.2758 - val_mse: 0.1310 - learning_rate: 0.0025\n",
      "Epoch 14/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6ms/step - loss: 0.1325 - mae: 0.2738 - mse: 0.1309 - val_loss: 0.1325 - val_mae: 0.2754 - val_mse: 0.1310 - learning_rate: 0.0025\n",
      "Epoch 15/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - loss: 0.1322 - mae: 0.2736 - mse: 0.1307 - val_loss: 0.1323 - val_mae: 0.2756 - val_mse: 0.1309 - learning_rate: 0.0025\n",
      "Epoch 16/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - loss: 0.1319 - mae: 0.2734 - mse: 0.1305 - val_loss: 0.1320 - val_mae: 0.2753 - val_mse: 0.1307 - learning_rate: 0.0025\n",
      "Epoch 17/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - loss: 0.1321 - mae: 0.2737 - mse: 0.1308 - val_loss: 0.1319 - val_mae: 0.2740 - val_mse: 0.1305 - learning_rate: 0.0025\n",
      "Epoch 18/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - loss: 0.1319 - mae: 0.2733 - mse: 0.1305 - val_loss: 0.1317 - val_mae: 0.2740 - val_mse: 0.1304 - learning_rate: 0.0025\n",
      "Epoch 19/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6ms/step - loss: 0.1318 - mae: 0.2732 - mse: 0.1304 - val_loss: 0.1316 - val_mae: 0.2727 - val_mse: 0.1302 - learning_rate: 0.0025\n",
      "Epoch 20/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - loss: 0.1317 - mae: 0.2732 - mse: 0.1304 - val_loss: 0.1317 - val_mae: 0.2730 - val_mse: 0.1304 - learning_rate: 0.0025\n",
      "Epoch 21/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - loss: 0.1313 - mae: 0.2729 - mse: 0.1299 - val_loss: 0.1315 - val_mae: 0.2730 - val_mse: 0.1301 - learning_rate: 0.0025\n",
      "Epoch 22/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - loss: 0.1315 - mae: 0.2730 - mse: 0.1302 - val_loss: 0.1316 - val_mae: 0.2738 - val_mse: 0.1303 - learning_rate: 0.0025\n",
      "Epoch 23/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - loss: 0.1318 - mae: 0.2734 - mse: 0.1305 - val_loss: 0.1319 - val_mae: 0.2746 - val_mse: 0.1306 - learning_rate: 0.0025\n",
      "Epoch 24/50\n",
      "\u001b[1m3047/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1316 - mae: 0.2730 - mse: 0.1302\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6ms/step - loss: 0.1316 - mae: 0.2730 - mse: 0.1302 - val_loss: 0.1320 - val_mae: 0.2745 - val_mse: 0.1307 - learning_rate: 0.0025\n",
      "Epoch 25/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6ms/step - loss: 0.1312 - mae: 0.2724 - mse: 0.1299 - val_loss: 0.1306 - val_mae: 0.2720 - val_mse: 0.1294 - learning_rate: 0.0012\n",
      "Epoch 26/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - loss: 0.1305 - mae: 0.2720 - mse: 0.1293 - val_loss: 0.1304 - val_mae: 0.2720 - val_mse: 0.1293 - learning_rate: 0.0012\n",
      "Epoch 27/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6ms/step - loss: 0.1306 - mae: 0.2721 - mse: 0.1295 - val_loss: 0.1308 - val_mae: 0.2735 - val_mse: 0.1297 - learning_rate: 0.0012\n",
      "Epoch 28/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6ms/step - loss: 0.1307 - mae: 0.2721 - mse: 0.1296 - val_loss: 0.1308 - val_mae: 0.2728 - val_mse: 0.1297 - learning_rate: 0.0012\n",
      "Epoch 29/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1307 - mae: 0.2722 - mse: 0.1297\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - loss: 0.1307 - mae: 0.2722 - mse: 0.1297 - val_loss: 0.1308 - val_mae: 0.2712 - val_mse: 0.1298 - learning_rate: 0.0012\n",
      "Epoch 30/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - loss: 0.1302 - mae: 0.2715 - mse: 0.1292 - val_loss: 0.1302 - val_mae: 0.2717 - val_mse: 0.1292 - learning_rate: 6.2500e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - loss: 0.1297 - mae: 0.2712 - mse: 0.1287 - val_loss: 0.1300 - val_mae: 0.2713 - val_mse: 0.1291 - learning_rate: 6.2500e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - loss: 0.1300 - mae: 0.2715 - mse: 0.1290 - val_loss: 0.1301 - val_mae: 0.2721 - val_mse: 0.1292 - learning_rate: 6.2500e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6ms/step - loss: 0.1301 - mae: 0.2715 - mse: 0.1291 - val_loss: 0.1300 - val_mae: 0.2722 - val_mse: 0.1290 - learning_rate: 6.2500e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m3052/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1300 - mae: 0.2715 - mse: 0.1291\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6ms/step - loss: 0.1300 - mae: 0.2715 - mse: 0.1291 - val_loss: 0.1302 - val_mae: 0.2717 - val_mse: 0.1293 - learning_rate: 6.2500e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6ms/step - loss: 0.1300 - mae: 0.2715 - mse: 0.1291 - val_loss: 0.1298 - val_mae: 0.2720 - val_mse: 0.1289 - learning_rate: 3.1250e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6ms/step - loss: 0.1294 - mae: 0.2710 - mse: 0.1285 - val_loss: 0.1298 - val_mae: 0.2721 - val_mse: 0.1289 - learning_rate: 3.1250e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - loss: 0.1296 - mae: 0.2711 - mse: 0.1287 - val_loss: 0.1297 - val_mae: 0.2713 - val_mse: 0.1288 - learning_rate: 3.1250e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6ms/step - loss: 0.1293 - mae: 0.2709 - mse: 0.1284 - val_loss: 0.1297 - val_mae: 0.2710 - val_mse: 0.1288 - learning_rate: 3.1250e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - loss: 0.1297 - mae: 0.2712 - mse: 0.1288 - val_loss: 0.1296 - val_mae: 0.2710 - val_mse: 0.1287 - learning_rate: 3.1250e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - loss: 0.1295 - mae: 0.2708 - mse: 0.1286 - val_loss: 0.1297 - val_mae: 0.2720 - val_mse: 0.1288 - learning_rate: 3.1250e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - loss: 0.1296 - mae: 0.2712 - mse: 0.1288 - val_loss: 0.1295 - val_mae: 0.2713 - val_mse: 0.1287 - learning_rate: 3.1250e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m3046/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1299 - mae: 0.2713 - mse: 0.1291\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6ms/step - loss: 0.1299 - mae: 0.2713 - mse: 0.1291 - val_loss: 0.1297 - val_mae: 0.2719 - val_mse: 0.1288 - learning_rate: 3.1250e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - loss: 0.1291 - mae: 0.2706 - mse: 0.1283 - val_loss: 0.1295 - val_mae: 0.2706 - val_mse: 0.1287 - learning_rate: 1.5625e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - loss: 0.1292 - mae: 0.2705 - mse: 0.1284 - val_loss: 0.1295 - val_mae: 0.2711 - val_mse: 0.1286 - learning_rate: 1.5625e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - loss: 0.1294 - mae: 0.2710 - mse: 0.1286 - val_loss: 0.1294 - val_mae: 0.2712 - val_mse: 0.1286 - learning_rate: 1.5625e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1291 - mae: 0.2705 - mse: 0.1283 - val_loss: 0.1294 - val_mae: 0.2714 - val_mse: 0.1286 - learning_rate: 1.5625e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m3047/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1293 - mae: 0.2707 - mse: 0.1284\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1293 - mae: 0.2707 - mse: 0.1284 - val_loss: 0.1294 - val_mae: 0.2716 - val_mse: 0.1286 - learning_rate: 1.5625e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1291 - mae: 0.2706 - mse: 0.1283 - val_loss: 0.1293 - val_mae: 0.2713 - val_mse: 0.1285 - learning_rate: 7.8125e-05\n",
      "Epoch 49/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1292 - mae: 0.2707 - mse: 0.1284 - val_loss: 0.1293 - val_mae: 0.2710 - val_mse: 0.1285 - learning_rate: 7.8125e-05\n",
      "Epoch 50/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1289 - mae: 0.2703 - mse: 0.1281 - val_loss: 0.1293 - val_mae: 0.2713 - val_mse: 0.1285 - learning_rate: 7.8125e-05\n"
     ]
    }
   ],
   "source": [
    "history_tanh_l2 = model_tanh_l2.fit(x=[X_user_train, X_movie_train],y=y_train, callbacks=[early_stop, reduce_lr],\n",
    "    validation_data=([X_user_dev, X_movie_dev], y_dev),epochs=50, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c2ba81-5959-4935-89ad-d270aa6cb9da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c810f3-5ba4-4f27-8f15-78f1933f4aeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d66019b-f108-4cf8-acb3-945ce594cebe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cae08e-e204-49fc-b349-2c91c45d79d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "1ffa9143-0b1f-4529-9e88-aac6309139d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_29\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_29\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ item_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_185 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,688</span> │ user_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_187 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,072</span> │ item_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_186 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dense_185[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_188 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dense_187[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lambda_42 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_186[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lambda_43 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_188[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ cosine_similarity (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lambda_42[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           │\n",
       "│                               │                           │                 │ lambda_43[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_input (\u001b[38;5;33mInputLayer\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ item_input (\u001b[38;5;33mInputLayer\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_185 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │           \u001b[38;5;34m2,688\u001b[0m │ user_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_187 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │           \u001b[38;5;34m3,072\u001b[0m │ item_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_186 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m8,256\u001b[0m │ dense_185[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_188 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m8,256\u001b[0m │ dense_187[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lambda_42 (\u001b[38;5;33mLambda\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_186[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lambda_43 (\u001b[38;5;33mLambda\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_188[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ cosine_similarity (\u001b[38;5;33mDot\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │ lambda_42[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           │\n",
       "│                               │                           │                 │ lambda_43[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,272</span> (87.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m22,272\u001b[0m (87.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,272</span> (87.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m22,272\u001b[0m (87.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_user_features = X_user_numpy.shape[1]\n",
    "num_item_features = X_movie_numpy.shape[1]\n",
    "num_outputs = 64\n",
    "\n",
    "# ---------------- USER MODEL ----------------\n",
    "user_input = keras.Input(shape=(num_user_features,), name='user_input')\n",
    "x_user = layers.Dense(128, activation='tanh', kernel_initializer='glorot_uniform', kernel_regularizer= keras.regularizers.l2(0.001))(user_input)\n",
    "x_user = layers.Dense(num_outputs, activation='tanh', kernel_initializer='glorot_uniform')(x_user)\n",
    "user_embedding = layers.Lambda(lambda x: tf.nn.l2_normalize(x, axis=1))(x_user)\n",
    "\n",
    "# ---------------- ITEM MODEL ----------------\n",
    "item_input = keras.Input(shape=(num_item_features,), name='item_input')\n",
    "x_item = layers.Dense(128, activation='tanh', kernel_initializer='glorot_uniform',kernel_regularizer= keras.regularizers.l2(0.001))(item_input)\n",
    "x_item = layers.Dense(num_outputs, activation='tanh', kernel_initializer='glorot_uniform')(x_item)\n",
    "item_embedding = layers.Lambda(lambda x: tf.nn.l2_normalize(x, axis=1))(x_item)\n",
    "\n",
    "# ---------------- COSINE SIMILARITY ----------------\n",
    "cos_sim = layers.Dot(axes=1, name='cosine_similarity')([user_embedding, item_embedding])\n",
    "# rezultat je u [-1, 1]\n",
    "\n",
    "# ---------------- FINAL MODEL ----------------\n",
    "model_tanh_l2 = keras.Model(inputs=[user_input, item_input], outputs=cos_sim)\n",
    "\n",
    "# Kompajliraj model\n",
    "model_tanh_l2.compile(optimizer= keras.optimizers.Nadam(learning_rate= 0.01), loss='mse', metrics=['mae', 'mse'])\n",
    "\n",
    "# Prikaži arhitekturu\n",
    "model_tanh_l2.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "a9624e1d-c025-4d32-8cdf-6f31b9b16a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - loss: 0.1525 - mae: 0.2886 - mse: 0.1426 - val_loss: 0.1401 - val_mae: 0.2811 - val_mse: 0.1362 - learning_rate: 0.0100\n",
      "Epoch 2/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - loss: 0.1398 - mae: 0.2802 - mse: 0.1357 - val_loss: 0.1408 - val_mae: 0.2849 - val_mse: 0.1368 - learning_rate: 0.0100\n",
      "Epoch 3/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6ms/step - loss: 0.1396 - mae: 0.2799 - mse: 0.1355 - val_loss: 0.1404 - val_mae: 0.2784 - val_mse: 0.1364 - learning_rate: 0.0100\n",
      "Epoch 4/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1394 - mae: 0.2796 - mse: 0.1352 - val_loss: 0.1397 - val_mae: 0.2799 - val_mse: 0.1351 - learning_rate: 0.0100\n",
      "Epoch 5/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - loss: 0.1398 - mae: 0.2799 - mse: 0.1355 - val_loss: 0.1435 - val_mae: 0.2875 - val_mse: 0.1390 - learning_rate: 0.0100\n",
      "Epoch 6/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1402 - mae: 0.2802 - mse: 0.1358 - val_loss: 0.1434 - val_mae: 0.2806 - val_mse: 0.1387 - learning_rate: 0.0100\n",
      "Epoch 7/50\n",
      "\u001b[1m3051/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1402 - mae: 0.2803 - mse: 0.1356\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - loss: 0.1402 - mae: 0.2803 - mse: 0.1356 - val_loss: 0.1405 - val_mae: 0.2823 - val_mse: 0.1360 - learning_rate: 0.0100\n",
      "Epoch 8/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1370 - mae: 0.2775 - mse: 0.1338 - val_loss: 0.1360 - val_mae: 0.2757 - val_mse: 0.1333 - learning_rate: 0.0050\n",
      "Epoch 9/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1362 - mae: 0.2772 - mse: 0.1335 - val_loss: 0.1370 - val_mae: 0.2783 - val_mse: 0.1343 - learning_rate: 0.0050\n",
      "Epoch 10/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1361 - mae: 0.2771 - mse: 0.1335 - val_loss: 0.1361 - val_mae: 0.2771 - val_mse: 0.1335 - learning_rate: 0.0050\n",
      "Epoch 11/50\n",
      "\u001b[1m3047/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1360 - mae: 0.2770 - mse: 0.1334\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1360 - mae: 0.2770 - mse: 0.1334 - val_loss: 0.1375 - val_mae: 0.2823 - val_mse: 0.1351 - learning_rate: 0.0050\n",
      "Epoch 12/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1344 - mae: 0.2757 - mse: 0.1324 - val_loss: 0.1338 - val_mae: 0.2748 - val_mse: 0.1320 - learning_rate: 0.0025\n",
      "Epoch 13/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1340 - mae: 0.2756 - mse: 0.1322 - val_loss: 0.1342 - val_mae: 0.2759 - val_mse: 0.1324 - learning_rate: 0.0025\n",
      "Epoch 14/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1337 - mae: 0.2754 - mse: 0.1320 - val_loss: 0.1341 - val_mae: 0.2753 - val_mse: 0.1324 - learning_rate: 0.0025\n",
      "Epoch 15/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1337 - mae: 0.2754 - mse: 0.1320\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1337 - mae: 0.2754 - mse: 0.1320 - val_loss: 0.1340 - val_mae: 0.2773 - val_mse: 0.1324 - learning_rate: 0.0025\n",
      "Epoch 16/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1326 - mae: 0.2744 - mse: 0.1311 - val_loss: 0.1327 - val_mae: 0.2749 - val_mse: 0.1314 - learning_rate: 0.0012\n",
      "Epoch 17/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1327 - mae: 0.2747 - mse: 0.1314 - val_loss: 0.1334 - val_mae: 0.2739 - val_mse: 0.1321 - learning_rate: 0.0012\n",
      "Epoch 18/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1328 - mae: 0.2748 - mse: 0.1315 - val_loss: 0.1326 - val_mae: 0.2753 - val_mse: 0.1314 - learning_rate: 0.0012\n",
      "Epoch 19/50\n",
      "\u001b[1m3052/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1328 - mae: 0.2748 - mse: 0.1316\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1328 - mae: 0.2748 - mse: 0.1316 - val_loss: 0.1330 - val_mae: 0.2757 - val_mse: 0.1318 - learning_rate: 0.0012\n",
      "Epoch 20/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1324 - mae: 0.2742 - mse: 0.1313 - val_loss: 0.1322 - val_mae: 0.2746 - val_mse: 0.1312 - learning_rate: 6.2500e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1322 - mae: 0.2743 - mse: 0.1312 - val_loss: 0.1320 - val_mae: 0.2745 - val_mse: 0.1310 - learning_rate: 6.2500e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1318 - mae: 0.2738 - mse: 0.1308 - val_loss: 0.1320 - val_mae: 0.2751 - val_mse: 0.1310 - learning_rate: 6.2500e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1321 - mae: 0.2742 - mse: 0.1311 - val_loss: 0.1321 - val_mae: 0.2753 - val_mse: 0.1311 - learning_rate: 6.2500e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m3054/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1318 - mae: 0.2740 - mse: 0.1309\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1318 - mae: 0.2740 - mse: 0.1309 - val_loss: 0.1320 - val_mae: 0.2749 - val_mse: 0.1310 - learning_rate: 6.2500e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - loss: 0.1315 - mae: 0.2736 - mse: 0.1305 - val_loss: 0.1317 - val_mae: 0.2741 - val_mse: 0.1308 - learning_rate: 3.1250e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1315 - mae: 0.2737 - mse: 0.1306 - val_loss: 0.1317 - val_mae: 0.2736 - val_mse: 0.1308 - learning_rate: 3.1250e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1318 - mae: 0.2740 - mse: 0.1310 - val_loss: 0.1316 - val_mae: 0.2742 - val_mse: 0.1307 - learning_rate: 3.1250e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m3045/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1314 - mae: 0.2737 - mse: 0.1305\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1314 - mae: 0.2737 - mse: 0.1305 - val_loss: 0.1316 - val_mae: 0.2742 - val_mse: 0.1308 - learning_rate: 3.1250e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1313 - mae: 0.2734 - mse: 0.1305 - val_loss: 0.1316 - val_mae: 0.2736 - val_mse: 0.1308 - learning_rate: 1.5625e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1312 - mae: 0.2735 - mse: 0.1304 - val_loss: 0.1314 - val_mae: 0.2739 - val_mse: 0.1306 - learning_rate: 1.5625e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1318 - mae: 0.2741 - mse: 0.1310 - val_loss: 0.1316 - val_mae: 0.2744 - val_mse: 0.1308 - learning_rate: 1.5625e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1313 - mae: 0.2734 - mse: 0.1305 - val_loss: 0.1314 - val_mae: 0.2740 - val_mse: 0.1306 - learning_rate: 1.5625e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1312 - mae: 0.2734 - mse: 0.1304\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1312 - mae: 0.2734 - mse: 0.1304 - val_loss: 0.1314 - val_mae: 0.2740 - val_mse: 0.1306 - learning_rate: 1.5625e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1315 - mae: 0.2737 - mse: 0.1307 - val_loss: 0.1314 - val_mae: 0.2744 - val_mse: 0.1307 - learning_rate: 7.8125e-05\n",
      "Epoch 35/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1313 - mae: 0.2736 - mse: 0.1306 - val_loss: 0.1314 - val_mae: 0.2739 - val_mse: 0.1306 - learning_rate: 7.8125e-05\n",
      "Epoch 36/50\n",
      "\u001b[1m3050/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1315 - mae: 0.2737 - mse: 0.1307\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1315 - mae: 0.2737 - mse: 0.1307 - val_loss: 0.1313 - val_mae: 0.2737 - val_mse: 0.1306 - learning_rate: 7.8125e-05\n",
      "Epoch 37/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1312 - mae: 0.2734 - mse: 0.1304 - val_loss: 0.1313 - val_mae: 0.2742 - val_mse: 0.1306 - learning_rate: 3.9062e-05\n",
      "Epoch 38/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1313 - mae: 0.2735 - mse: 0.1305 - val_loss: 0.1313 - val_mae: 0.2742 - val_mse: 0.1306 - learning_rate: 3.9062e-05\n",
      "Epoch 39/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1313 - mae: 0.2735 - mse: 0.1306 - val_loss: 0.1313 - val_mae: 0.2739 - val_mse: 0.1305 - learning_rate: 3.9062e-05\n",
      "Epoch 40/50\n",
      "\u001b[1m 987/3056\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - loss: 0.1309 - mae: 0.2730 - mse: 0.1301"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[338]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m history_tanh_l2 = \u001b[43mmodel_tanh_l2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_user_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_movie_train\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mearly_stop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_user_dev\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_movie_dev\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_dev\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m512\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:371\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    370\u001b[39m     callbacks.on_train_batch_begin(step)\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    372\u001b[39m     callbacks.on_train_batch_end(step, logs)\n\u001b[32m    373\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:219\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    217\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    218\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    220\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    221\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m    138\u001b[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bound_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1688\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1686\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1687\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1688\u001b[39m   outputs = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1689\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1690\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1691\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1696\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1697\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1698\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1702\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1703\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "history_tanh_l2 = model_tanh_l2.fit(x=[X_user_train, X_movie_train],y=y_train, callbacks=[early_stop, reduce_lr],\n",
    "    validation_data=([X_user_dev, X_movie_dev], y_dev),epochs=50, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f02978-8a3a-49ef-8028-53b240feabe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_tanh_l2 = model_tanh_l2.fit(x=[X_user_train, X_movie_train],y=y_train, callbacks=[early_stop, reduce_lr],\n",
    "    validation_data=([X_user_dev, X_movie_dev], y_dev),epochs=50, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ac8b17-bc61-4b3e-9099-6a8f49a9a9e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "1263a050-61b4-4ded-888d-3347846e252a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_30\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_30\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ item_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_189 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">258</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">5,418</span> │ user_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_191 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">258</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">6,192</span> │ item_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_190 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,576</span> │ dense_189[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_192 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,576</span> │ dense_191[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lambda_44 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_190[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lambda_45 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_192[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ cosine_similarity (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lambda_44[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           │\n",
       "│                               │                           │                 │ lambda_45[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_input (\u001b[38;5;33mInputLayer\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ item_input (\u001b[38;5;33mInputLayer\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_189 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m258\u001b[0m)               │           \u001b[38;5;34m5,418\u001b[0m │ user_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_191 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m258\u001b[0m)               │           \u001b[38;5;34m6,192\u001b[0m │ item_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_190 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │          \u001b[38;5;34m16,576\u001b[0m │ dense_189[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_192 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │          \u001b[38;5;34m16,576\u001b[0m │ dense_191[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lambda_44 (\u001b[38;5;33mLambda\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_190[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lambda_45 (\u001b[38;5;33mLambda\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_192[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ cosine_similarity (\u001b[38;5;33mDot\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │ lambda_44[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           │\n",
       "│                               │                           │                 │ lambda_45[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">44,762</span> (174.85 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m44,762\u001b[0m (174.85 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">44,762</span> (174.85 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m44,762\u001b[0m (174.85 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_user_features = X_user_numpy.shape[1]\n",
    "num_item_features = X_movie_numpy.shape[1]\n",
    "num_outputs = 64\n",
    "\n",
    "# ---------------- USER MODEL ----------------\n",
    "user_input = keras.Input(shape=(num_user_features,), name='user_input')\n",
    "x_user = layers.Dense(258, activation='tanh', kernel_initializer='glorot_uniform', kernel_regularizer= keras.regularizers.l2(0.0001))(user_input)\n",
    "x_user = layers.Dense(num_outputs, activation='tanh', kernel_initializer='glorot_uniform')(x_user)\n",
    "user_embedding = layers.Lambda(lambda x: tf.nn.l2_normalize(x, axis=1))(x_user)\n",
    "\n",
    "# ---------------- ITEM MODEL ----------------\n",
    "item_input = keras.Input(shape=(num_item_features,), name='item_input')\n",
    "x_item = layers.Dense(258, activation='tanh', kernel_initializer='glorot_uniform',kernel_regularizer= keras.regularizers.l2(0.0001))(item_input)\n",
    "x_item = layers.Dense(num_outputs, activation='tanh', kernel_initializer='glorot_uniform')(x_item)\n",
    "item_embedding = layers.Lambda(lambda x: tf.nn.l2_normalize(x, axis=1))(x_item)\n",
    "\n",
    "# ---------------- COSINE SIMILARITY ----------------\n",
    "cos_sim = layers.Dot(axes=1, name='cosine_similarity')([user_embedding, item_embedding])\n",
    "# rezultat je u [-1, 1]\n",
    "\n",
    "# ---------------- FINAL MODEL ----------------\n",
    "model_tanh_l2 = keras.Model(inputs=[user_input, item_input], outputs=cos_sim)\n",
    "\n",
    "# Kompajliraj model\n",
    "model_tanh_l2.compile(optimizer= keras.optimizers.Nadam(learning_rate= 0.01), loss='mse', metrics=['mae', 'mse'])\n",
    "\n",
    "# Prikaži arhitekturu\n",
    "model_tanh_l2.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "605c2f26-2362-4674-a3e8-52c1d89b2d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 5ms/step - loss: 0.1470 - mae: 0.2879 - mse: 0.1420 - val_loss: 0.1406 - val_mae: 0.2826 - val_mse: 0.1364 - learning_rate: 0.0100\n",
      "Epoch 2/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1411 - mae: 0.2823 - mse: 0.1369 - val_loss: 0.1419 - val_mae: 0.2826 - val_mse: 0.1371 - learning_rate: 0.0100\n",
      "Epoch 3/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1419 - mae: 0.2829 - mse: 0.1374 - val_loss: 0.1416 - val_mae: 0.2823 - val_mse: 0.1371 - learning_rate: 0.0100\n",
      "Epoch 4/50\n",
      "\u001b[1m3045/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1420 - mae: 0.2827 - mse: 0.1373\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1420 - mae: 0.2827 - mse: 0.1373 - val_loss: 0.1416 - val_mae: 0.2831 - val_mse: 0.1369 - learning_rate: 0.0100\n",
      "Epoch 5/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1386 - mae: 0.2797 - mse: 0.1350 - val_loss: 0.1381 - val_mae: 0.2797 - val_mse: 0.1351 - learning_rate: 0.0050\n",
      "Epoch 6/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1375 - mae: 0.2789 - mse: 0.1345 - val_loss: 0.1377 - val_mae: 0.2814 - val_mse: 0.1346 - learning_rate: 0.0050\n",
      "Epoch 7/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1374 - mae: 0.2791 - mse: 0.1344 - val_loss: 0.1366 - val_mae: 0.2793 - val_mse: 0.1337 - learning_rate: 0.0050\n",
      "Epoch 8/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1368 - mae: 0.2784 - mse: 0.1338 - val_loss: 0.1380 - val_mae: 0.2775 - val_mse: 0.1349 - learning_rate: 0.0050\n",
      "Epoch 9/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1371 - mae: 0.2788 - mse: 0.1341 - val_loss: 0.1379 - val_mae: 0.2774 - val_mse: 0.1350 - learning_rate: 0.0050\n",
      "Epoch 10/50\n",
      "\u001b[1m3052/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1369 - mae: 0.2785 - mse: 0.1339\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1369 - mae: 0.2785 - mse: 0.1339 - val_loss: 0.1375 - val_mae: 0.2789 - val_mse: 0.1347 - learning_rate: 0.0050\n",
      "Epoch 11/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1354 - mae: 0.2770 - mse: 0.1330 - val_loss: 0.1341 - val_mae: 0.2765 - val_mse: 0.1321 - learning_rate: 0.0025\n",
      "Epoch 12/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6ms/step - loss: 0.1345 - mae: 0.2764 - mse: 0.1324 - val_loss: 0.1342 - val_mae: 0.2760 - val_mse: 0.1321 - learning_rate: 0.0025\n",
      "Epoch 13/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1345 - mae: 0.2764 - mse: 0.1324 - val_loss: 0.1347 - val_mae: 0.2764 - val_mse: 0.1326 - learning_rate: 0.0025\n",
      "Epoch 14/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1339 - mae: 0.2758 - mse: 0.1320 - val_loss: 0.1337 - val_mae: 0.2757 - val_mse: 0.1318 - learning_rate: 0.0025\n",
      "Epoch 15/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1338 - mae: 0.2757 - mse: 0.1318 - val_loss: 0.1339 - val_mae: 0.2764 - val_mse: 0.1319 - learning_rate: 0.0025\n",
      "Epoch 16/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1335 - mae: 0.2754 - mse: 0.1316 - val_loss: 0.1338 - val_mae: 0.2766 - val_mse: 0.1318 - learning_rate: 0.0025\n",
      "Epoch 17/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1341 - mae: 0.2760 - mse: 0.1321\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1341 - mae: 0.2760 - mse: 0.1321 - val_loss: 0.1337 - val_mae: 0.2759 - val_mse: 0.1317 - learning_rate: 0.0025\n",
      "Epoch 18/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1332 - mae: 0.2748 - mse: 0.1314 - val_loss: 0.1326 - val_mae: 0.2755 - val_mse: 0.1310 - learning_rate: 0.0012\n",
      "Epoch 19/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1328 - mae: 0.2747 - mse: 0.1312 - val_loss: 0.1328 - val_mae: 0.2761 - val_mse: 0.1312 - learning_rate: 0.0012\n",
      "Epoch 20/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1325 - mae: 0.2743 - mse: 0.1309 - val_loss: 0.1328 - val_mae: 0.2738 - val_mse: 0.1313 - learning_rate: 0.0012\n",
      "Epoch 21/50\n",
      "\u001b[1m3054/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1324 - mae: 0.2742 - mse: 0.1309\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1324 - mae: 0.2742 - mse: 0.1309 - val_loss: 0.1327 - val_mae: 0.2743 - val_mse: 0.1313 - learning_rate: 0.0012\n",
      "Epoch 22/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1318 - mae: 0.2737 - mse: 0.1305 - val_loss: 0.1317 - val_mae: 0.2735 - val_mse: 0.1304 - learning_rate: 6.2500e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1317 - mae: 0.2735 - mse: 0.1303 - val_loss: 0.1316 - val_mae: 0.2747 - val_mse: 0.1303 - learning_rate: 6.2500e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1314 - mae: 0.2732 - mse: 0.1301 - val_loss: 0.1317 - val_mae: 0.2731 - val_mse: 0.1304 - learning_rate: 6.2500e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1313 - mae: 0.2732 - mse: 0.1300 - val_loss: 0.1316 - val_mae: 0.2746 - val_mse: 0.1303 - learning_rate: 6.2500e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1315 - mae: 0.2734 - mse: 0.1303 - val_loss: 0.1316 - val_mae: 0.2746 - val_mse: 0.1304 - learning_rate: 6.2500e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1310 - mae: 0.2730 - mse: 0.1298 - val_loss: 0.1312 - val_mae: 0.2734 - val_mse: 0.1300 - learning_rate: 6.2500e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1311 - mae: 0.2730 - mse: 0.1299 - val_loss: 0.1314 - val_mae: 0.2745 - val_mse: 0.1302 - learning_rate: 6.2500e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1311 - mae: 0.2731 - mse: 0.1299 - val_loss: 0.1313 - val_mae: 0.2738 - val_mse: 0.1301 - learning_rate: 6.2500e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1311 - mae: 0.2732 - mse: 0.1300 - val_loss: 0.1311 - val_mae: 0.2727 - val_mse: 0.1299 - learning_rate: 6.2500e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1313 - mae: 0.2732 - mse: 0.1301 - val_loss: 0.1311 - val_mae: 0.2729 - val_mse: 0.1300 - learning_rate: 6.2500e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1311 - mae: 0.2731 - mse: 0.1299 - val_loss: 0.1312 - val_mae: 0.2741 - val_mse: 0.1300 - learning_rate: 6.2500e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m3054/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1313 - mae: 0.2733 - mse: 0.1301\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1313 - mae: 0.2733 - mse: 0.1301 - val_loss: 0.1314 - val_mae: 0.2750 - val_mse: 0.1302 - learning_rate: 6.2500e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1306 - mae: 0.2725 - mse: 0.1295 - val_loss: 0.1306 - val_mae: 0.2725 - val_mse: 0.1295 - learning_rate: 3.1250e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1305 - mae: 0.2724 - mse: 0.1294 - val_loss: 0.1307 - val_mae: 0.2734 - val_mse: 0.1296 - learning_rate: 3.1250e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1308 - mae: 0.2727 - mse: 0.1297 - val_loss: 0.1307 - val_mae: 0.2734 - val_mse: 0.1297 - learning_rate: 3.1250e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1301 - mae: 0.2719 - mse: 0.1290 - val_loss: 0.1305 - val_mae: 0.2733 - val_mse: 0.1294 - learning_rate: 3.1250e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1302 - mae: 0.2720 - mse: 0.1292 - val_loss: 0.1305 - val_mae: 0.2725 - val_mse: 0.1294 - learning_rate: 3.1250e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1305 - mae: 0.2723 - mse: 0.1295 - val_loss: 0.1303 - val_mae: 0.2726 - val_mse: 0.1293 - learning_rate: 3.1250e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1304 - mae: 0.2723 - mse: 0.1294 - val_loss: 0.1305 - val_mae: 0.2731 - val_mse: 0.1295 - learning_rate: 3.1250e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1305 - mae: 0.2724 - mse: 0.1294 - val_loss: 0.1305 - val_mae: 0.2733 - val_mse: 0.1294 - learning_rate: 3.1250e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m3048/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1302 - mae: 0.2721 - mse: 0.1292\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1302 - mae: 0.2721 - mse: 0.1292 - val_loss: 0.1305 - val_mae: 0.2732 - val_mse: 0.1295 - learning_rate: 3.1250e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1302 - mae: 0.2721 - mse: 0.1292 - val_loss: 0.1302 - val_mae: 0.2716 - val_mse: 0.1292 - learning_rate: 1.5625e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1300 - mae: 0.2717 - mse: 0.1290 - val_loss: 0.1301 - val_mae: 0.2721 - val_mse: 0.1291 - learning_rate: 1.5625e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1301 - mae: 0.2719 - mse: 0.1291 - val_loss: 0.1301 - val_mae: 0.2719 - val_mse: 0.1291 - learning_rate: 1.5625e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1298 - mae: 0.2715 - mse: 0.1288 - val_loss: 0.1300 - val_mae: 0.2720 - val_mse: 0.1290 - learning_rate: 1.5625e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1300 - mae: 0.2720 - mse: 0.1290\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1300 - mae: 0.2720 - mse: 0.1290 - val_loss: 0.1301 - val_mae: 0.2728 - val_mse: 0.1291 - learning_rate: 1.5625e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1298 - mae: 0.2716 - mse: 0.1289 - val_loss: 0.1300 - val_mae: 0.2729 - val_mse: 0.1291 - learning_rate: 7.8125e-05\n",
      "Epoch 49/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1293 - mae: 0.2713 - mse: 0.1284 - val_loss: 0.1300 - val_mae: 0.2724 - val_mse: 0.1290 - learning_rate: 7.8125e-05\n",
      "Epoch 50/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.1294 - mae: 0.2713 - mse: 0.1285 - val_loss: 0.1300 - val_mae: 0.2714 - val_mse: 0.1291 - learning_rate: 7.8125e-05\n"
     ]
    }
   ],
   "source": [
    "history_tanh_l2 = model_tanh_l2.fit(x=[X_user_train, X_movie_train],y=y_train, callbacks=[early_stop, reduce_lr],\n",
    "    validation_data=([X_user_dev, X_movie_dev], y_dev),epochs=50, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec8c7c9-b436-447d-bef8-d83ab7d2d166",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e943224f-e7b3-468e-855f-b2d54a7c0999",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "47ea4303-7019-40d8-9348-f77a58a60233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_34\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_34\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ item_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_205 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">258</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">5,418</span> │ user_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_207 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">258</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">6,192</span> │ item_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_206 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">33,152</span> │ dense_205[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_208 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">33,152</span> │ dense_207[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lambda_52 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_206[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lambda_53 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_208[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ cosine_similarity (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lambda_52[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           │\n",
       "│                               │                           │                 │ lambda_53[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_input (\u001b[38;5;33mInputLayer\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ item_input (\u001b[38;5;33mInputLayer\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_205 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m258\u001b[0m)               │           \u001b[38;5;34m5,418\u001b[0m │ user_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_207 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m258\u001b[0m)               │           \u001b[38;5;34m6,192\u001b[0m │ item_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_206 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │          \u001b[38;5;34m33,152\u001b[0m │ dense_205[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_208 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │          \u001b[38;5;34m33,152\u001b[0m │ dense_207[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lambda_52 (\u001b[38;5;33mLambda\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ dense_206[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lambda_53 (\u001b[38;5;33mLambda\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ dense_208[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ cosine_similarity (\u001b[38;5;33mDot\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │ lambda_52[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           │\n",
       "│                               │                           │                 │ lambda_53[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">77,914</span> (304.35 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m77,914\u001b[0m (304.35 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">77,914</span> (304.35 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m77,914\u001b[0m (304.35 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_user_features = X_user_numpy.shape[1]\n",
    "num_item_features = X_movie_numpy.shape[1]\n",
    "num_outputs = 128\n",
    "\n",
    "# ---------------- USER MODEL ----------------\n",
    "user_input = keras.Input(shape=(num_user_features,), name='user_input')\n",
    "x_user = layers.Dense(258, activation='tanh', kernel_initializer='glorot_uniform')(user_input)\n",
    "x_user = layers.Dense(num_outputs, activation='tanh', kernel_initializer='glorot_uniform')(x_user)\n",
    "user_embedding = layers.Lambda(lambda x: tf.nn.l2_normalize(x, axis=1))(x_user)\n",
    "\n",
    "# ---------------- ITEM MODEL ----------------\n",
    "item_input = keras.Input(shape=(num_item_features,), name='item_input')\n",
    "x_item = layers.Dense(258, activation='tanh', kernel_initializer='glorot_uniform')(item_input)\n",
    "x_item = layers.Dense(num_outputs, activation='tanh', kernel_initializer='glorot_uniform')(x_item)\n",
    "item_embedding = layers.Lambda(lambda x: tf.nn.l2_normalize(x, axis=1))(x_item)\n",
    "\n",
    "# ---------------- COSINE SIMILARITY ----------------\n",
    "cos_sim = layers.Dot(axes=1, name='cosine_similarity')([user_embedding, item_embedding])\n",
    "# rezultat je u [-1, 1]\n",
    "\n",
    "# ---------------- FINAL MODEL ----------------\n",
    "model_tanh_l2 = keras.Model(inputs=[user_input, item_input], outputs=cos_sim)\n",
    "\n",
    "# Kompajliraj model\n",
    "model_tanh_l2.compile(optimizer= keras.optimizers.Nadam(learning_rate= 0.01), loss='mse', metrics=['mae', 'mse'])\n",
    "\n",
    "# Prikaži arhitekturu\n",
    "model_tanh_l2.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "f7840403-3d16-406c-95fe-c80c62aa46ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - loss: 0.1397 - mae: 0.2853 - mse: 0.1397 - val_loss: 0.1340 - val_mae: 0.2801 - val_mse: 0.1340 - learning_rate: 0.0100\n",
      "Epoch 2/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - loss: 0.1338 - mae: 0.2790 - mse: 0.1338 - val_loss: 0.1329 - val_mae: 0.2777 - val_mse: 0.1329 - learning_rate: 0.0100\n",
      "Epoch 3/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - loss: 0.1334 - mae: 0.2786 - mse: 0.1334 - val_loss: 0.1330 - val_mae: 0.2785 - val_mse: 0.1330 - learning_rate: 0.0100\n",
      "Epoch 4/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - loss: 0.1331 - mae: 0.2782 - mse: 0.1331 - val_loss: 0.1333 - val_mae: 0.2789 - val_mse: 0.1333 - learning_rate: 0.0100\n",
      "Epoch 5/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - loss: 0.1329 - mae: 0.2780 - mse: 0.1329 - val_loss: 0.1325 - val_mae: 0.2772 - val_mse: 0.1325 - learning_rate: 0.0100\n",
      "Epoch 6/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - loss: 0.1326 - mae: 0.2772 - mse: 0.1326 - val_loss: 0.1329 - val_mae: 0.2783 - val_mse: 0.1329 - learning_rate: 0.0100\n",
      "Epoch 7/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - loss: 0.1323 - mae: 0.2771 - mse: 0.1323 - val_loss: 0.1325 - val_mae: 0.2776 - val_mse: 0.1325 - learning_rate: 0.0100\n",
      "Epoch 8/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - loss: 0.1323 - mae: 0.2771 - mse: 0.1323 - val_loss: 0.1322 - val_mae: 0.2776 - val_mse: 0.1322 - learning_rate: 0.0100\n",
      "Epoch 9/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - loss: 0.1321 - mae: 0.2767 - mse: 0.1321 - val_loss: 0.1323 - val_mae: 0.2773 - val_mse: 0.1323 - learning_rate: 0.0100\n",
      "Epoch 10/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 0.1320 - mae: 0.2766 - mse: 0.1320 - val_loss: 0.1321 - val_mae: 0.2775 - val_mse: 0.1321 - learning_rate: 0.0100\n",
      "Epoch 11/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - loss: 0.1320 - mae: 0.2767 - mse: 0.1320 - val_loss: 0.1322 - val_mae: 0.2770 - val_mse: 0.1322 - learning_rate: 0.0100\n",
      "Epoch 12/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - loss: 0.1321 - mae: 0.2767 - mse: 0.1321 - val_loss: 0.1323 - val_mae: 0.2775 - val_mse: 0.1323 - learning_rate: 0.0100\n",
      "Epoch 13/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - loss: 0.1317 - mae: 0.2763 - mse: 0.1317 - val_loss: 0.1319 - val_mae: 0.2774 - val_mse: 0.1319 - learning_rate: 0.0100\n",
      "Epoch 14/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - loss: 0.1317 - mae: 0.2764 - mse: 0.1317 - val_loss: 0.1319 - val_mae: 0.2764 - val_mse: 0.1319 - learning_rate: 0.0100\n",
      "Epoch 15/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6ms/step - loss: 0.1319 - mae: 0.2765 - mse: 0.1319 - val_loss: 0.1320 - val_mae: 0.2768 - val_mse: 0.1320 - learning_rate: 0.0100\n",
      "Epoch 16/50\n",
      "\u001b[1m3049/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1318 - mae: 0.2763 - mse: 0.1318\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - loss: 0.1318 - mae: 0.2763 - mse: 0.1318 - val_loss: 0.1324 - val_mae: 0.2781 - val_mse: 0.1324 - learning_rate: 0.0100\n",
      "Epoch 17/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - loss: 0.1311 - mae: 0.2755 - mse: 0.1311 - val_loss: 0.1310 - val_mae: 0.2753 - val_mse: 0.1310 - learning_rate: 0.0050\n",
      "Epoch 18/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6ms/step - loss: 0.1305 - mae: 0.2745 - mse: 0.1305 - val_loss: 0.1309 - val_mae: 0.2752 - val_mse: 0.1309 - learning_rate: 0.0050\n",
      "Epoch 19/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - loss: 0.1304 - mae: 0.2745 - mse: 0.1304 - val_loss: 0.1306 - val_mae: 0.2746 - val_mse: 0.1306 - learning_rate: 0.0050\n",
      "Epoch 20/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - loss: 0.1303 - mae: 0.2742 - mse: 0.1303 - val_loss: 0.1305 - val_mae: 0.2751 - val_mse: 0.1305 - learning_rate: 0.0050\n",
      "Epoch 21/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6ms/step - loss: 0.1299 - mae: 0.2739 - mse: 0.1299 - val_loss: 0.1304 - val_mae: 0.2742 - val_mse: 0.1304 - learning_rate: 0.0050\n",
      "Epoch 22/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - loss: 0.1300 - mae: 0.2739 - mse: 0.1300 - val_loss: 0.1304 - val_mae: 0.2742 - val_mse: 0.1304 - learning_rate: 0.0050\n",
      "Epoch 23/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - loss: 0.1298 - mae: 0.2736 - mse: 0.1298 - val_loss: 0.1304 - val_mae: 0.2748 - val_mse: 0.1304 - learning_rate: 0.0050\n",
      "Epoch 24/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - loss: 0.1299 - mae: 0.2737 - mse: 0.1299 - val_loss: 0.1303 - val_mae: 0.2741 - val_mse: 0.1303 - learning_rate: 0.0050\n",
      "Epoch 25/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6ms/step - loss: 0.1295 - mae: 0.2732 - mse: 0.1295 - val_loss: 0.1300 - val_mae: 0.2737 - val_mse: 0.1300 - learning_rate: 0.0050\n",
      "Epoch 26/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - loss: 0.1295 - mae: 0.2729 - mse: 0.1295 - val_loss: 0.1301 - val_mae: 0.2742 - val_mse: 0.1301 - learning_rate: 0.0050\n",
      "Epoch 27/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - loss: 0.1296 - mae: 0.2732 - mse: 0.1296 - val_loss: 0.1301 - val_mae: 0.2740 - val_mse: 0.1301 - learning_rate: 0.0050\n",
      "Epoch 28/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1289 - mae: 0.2724 - mse: 0.1289\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 0.1289 - mae: 0.2724 - mse: 0.1289 - val_loss: 0.1299 - val_mae: 0.2739 - val_mse: 0.1299 - learning_rate: 0.0050\n",
      "Epoch 29/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - loss: 0.1290 - mae: 0.2726 - mse: 0.1290 - val_loss: 0.1296 - val_mae: 0.2732 - val_mse: 0.1296 - learning_rate: 0.0025\n",
      "Epoch 30/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - loss: 0.1281 - mae: 0.2714 - mse: 0.1281 - val_loss: 0.1292 - val_mae: 0.2726 - val_mse: 0.1292 - learning_rate: 0.0025\n",
      "Epoch 31/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - loss: 0.1280 - mae: 0.2713 - mse: 0.1280 - val_loss: 0.1293 - val_mae: 0.2726 - val_mse: 0.1293 - learning_rate: 0.0025\n",
      "Epoch 32/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - loss: 0.1282 - mae: 0.2715 - mse: 0.1282 - val_loss: 0.1292 - val_mae: 0.2727 - val_mse: 0.1292 - learning_rate: 0.0025\n",
      "Epoch 33/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - loss: 0.1279 - mae: 0.2709 - mse: 0.1279 - val_loss: 0.1291 - val_mae: 0.2728 - val_mse: 0.1291 - learning_rate: 0.0025\n",
      "Epoch 34/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - loss: 0.1281 - mae: 0.2712 - mse: 0.1281 - val_loss: 0.1291 - val_mae: 0.2723 - val_mse: 0.1291 - learning_rate: 0.0025\n",
      "Epoch 35/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6ms/step - loss: 0.1278 - mae: 0.2709 - mse: 0.1278 - val_loss: 0.1291 - val_mae: 0.2721 - val_mse: 0.1291 - learning_rate: 0.0025\n",
      "Epoch 36/50\n",
      "\u001b[1m3054/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1274 - mae: 0.2704 - mse: 0.1274\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6ms/step - loss: 0.1274 - mae: 0.2704 - mse: 0.1274 - val_loss: 0.1291 - val_mae: 0.2725 - val_mse: 0.1291 - learning_rate: 0.0025\n",
      "Epoch 37/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - loss: 0.1273 - mae: 0.2704 - mse: 0.1273 - val_loss: 0.1289 - val_mae: 0.2720 - val_mse: 0.1289 - learning_rate: 0.0012\n",
      "Epoch 38/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - loss: 0.1272 - mae: 0.2702 - mse: 0.1272 - val_loss: 0.1288 - val_mae: 0.2718 - val_mse: 0.1288 - learning_rate: 0.0012\n",
      "Epoch 39/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - loss: 0.1270 - mae: 0.2699 - mse: 0.1270 - val_loss: 0.1287 - val_mae: 0.2718 - val_mse: 0.1287 - learning_rate: 0.0012\n",
      "Epoch 40/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - loss: 0.1268 - mae: 0.2698 - mse: 0.1268 - val_loss: 0.1287 - val_mae: 0.2716 - val_mse: 0.1287 - learning_rate: 0.0012\n",
      "Epoch 41/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - loss: 0.1266 - mae: 0.2695 - mse: 0.1266 - val_loss: 0.1287 - val_mae: 0.2720 - val_mse: 0.1287 - learning_rate: 0.0012\n",
      "Epoch 42/50\n",
      "\u001b[1m3049/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1265 - mae: 0.2694 - mse: 0.1265\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - loss: 0.1266 - mae: 0.2695 - mse: 0.1266 - val_loss: 0.1288 - val_mae: 0.2719 - val_mse: 0.1288 - learning_rate: 0.0012\n",
      "Epoch 43/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 0.1263 - mae: 0.2692 - mse: 0.1263 - val_loss: 0.1287 - val_mae: 0.2717 - val_mse: 0.1287 - learning_rate: 6.2500e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - loss: 0.1267 - mae: 0.2694 - mse: 0.1267 - val_loss: 0.1287 - val_mae: 0.2717 - val_mse: 0.1287 - learning_rate: 6.2500e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m3049/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1261 - mae: 0.2687 - mse: 0.1261\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 0.1261 - mae: 0.2687 - mse: 0.1261 - val_loss: 0.1287 - val_mae: 0.2717 - val_mse: 0.1287 - learning_rate: 6.2500e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - loss: 0.1259 - mae: 0.2687 - mse: 0.1259 - val_loss: 0.1286 - val_mae: 0.2718 - val_mse: 0.1286 - learning_rate: 3.1250e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 0.1256 - mae: 0.2683 - mse: 0.1256 - val_loss: 0.1286 - val_mae: 0.2717 - val_mse: 0.1286 - learning_rate: 3.1250e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m3050/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1257 - mae: 0.2683 - mse: 0.1257\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 0.1257 - mae: 0.2683 - mse: 0.1257 - val_loss: 0.1286 - val_mae: 0.2716 - val_mse: 0.1286 - learning_rate: 3.1250e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 0.1256 - mae: 0.2684 - mse: 0.1256 - val_loss: 0.1286 - val_mae: 0.2717 - val_mse: 0.1286 - learning_rate: 1.5625e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 0.1258 - mae: 0.2684 - mse: 0.1258 - val_loss: 0.1286 - val_mae: 0.2717 - val_mse: 0.1286 - learning_rate: 1.5625e-04\n"
     ]
    }
   ],
   "source": [
    "history_tanh_l2 = model_tanh_l2.fit(x=[X_user_train, X_movie_train],y=y_train, callbacks=[early_stop, reduce_lr],\n",
    "    validation_data=([X_user_dev, X_movie_dev], y_dev),epochs=50, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808c4f4b-ee65-40c1-9307-b7b6dbb2acb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e251ef84-e808-48e9-ad6b-536fbb2f22be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08df7793-13d6-4c57-a4e7-c1e09a2c24e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57d360d-70df-45d1-bec4-94e72d50ef46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e068fb13-6ef3-43dc-b1c7-66fcfacea45f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78aca51c-c685-4e29-abb8-6baef87eae43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e76dc89-33db-4e2a-b1b3-7eff65df18b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a754b5c-9e7c-4870-b364-a2b349eb59e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77247d6d-2c4c-44ed-a843-c619c1d36d70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef4ae85-1df5-4275-9fa0-e8a8fc0127dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e3cd7a-eddc-40ae-aa2c-cf675afe6be8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4588d0a4-f2a5-4025-9793-bd4ef433f586",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "14610501-09ca-48e9-b7fa-2715e22548db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_22\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_22\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ item_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_151 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,200</span> │ user_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_154 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,800</span> │ item_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_152 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">25,728</span> │ dense_151[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_155 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">25,728</span> │ dense_154[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_153 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dense_152[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_156 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dense_155[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lambda_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_153[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lambda_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_156[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ cosine_similarity (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lambda_28[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           │\n",
       "│                               │                           │                 │ lambda_29[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_input (\u001b[38;5;33mInputLayer\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ item_input (\u001b[38;5;33mInputLayer\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_151 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)               │           \u001b[38;5;34m4,200\u001b[0m │ user_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_154 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)               │           \u001b[38;5;34m4,800\u001b[0m │ item_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_152 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │          \u001b[38;5;34m25,728\u001b[0m │ dense_151[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_155 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │          \u001b[38;5;34m25,728\u001b[0m │ dense_154[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_153 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m8,256\u001b[0m │ dense_152[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_156 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m8,256\u001b[0m │ dense_155[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lambda_28 (\u001b[38;5;33mLambda\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_153[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lambda_29 (\u001b[38;5;33mLambda\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_156[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ cosine_similarity (\u001b[38;5;33mDot\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │ lambda_28[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           │\n",
       "│                               │                           │                 │ lambda_29[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">76,968</span> (300.66 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m76,968\u001b[0m (300.66 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">76,968</span> (300.66 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m76,968\u001b[0m (300.66 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_user_features = X_user_numpy.shape[1]\n",
    "num_item_features = X_movie_numpy.shape[1]\n",
    "num_outputs = 64\n",
    "\n",
    "# ---------------- USER MODEL ----------------\n",
    "user_input = keras.Input(shape=(num_user_features,), name='user_input')\n",
    "x_user = layers.Dense(200, activation='tanh', kernel_initializer='glorot_uniform')(user_input)\n",
    "x_user = layers.Dense(128, activation='tanh', kernel_initializer='glorot_uniform')(x_user)\n",
    "x_user = layers.Dense(num_outputs, activation='tanh', kernel_initializer='glorot_uniform')(x_user)\n",
    "user_embedding = layers.Lambda(lambda x: tf.nn.l2_normalize(x, axis=1))(x_user)\n",
    "\n",
    "# ---------------- ITEM MODEL ----------------\n",
    "item_input = keras.Input(shape=(num_item_features,), name='item_input')\n",
    "x_item = layers.Dense(200, activation='tanh', kernel_initializer='glorot_uniform')(item_input)\n",
    "x_item = layers.Dense(128, activation='tanh', kernel_initializer='glorot_uniform')(x_item)\n",
    "x_item = layers.Dense(num_outputs, activation='tanh', kernel_initializer='glorot_uniform')(x_item)\n",
    "item_embedding = layers.Lambda(lambda x: tf.nn.l2_normalize(x, axis=1))(x_item)\n",
    "\n",
    "# ---------------- COSINE SIMILARITY ----------------\n",
    "cos_sim = layers.Dot(axes=1, name='cosine_similarity')([user_embedding, item_embedding])\n",
    "# rezultat je u [-1, 1]\n",
    "\n",
    "# ---------------- FINAL MODEL ----------------\n",
    "model_tanh2 = keras.Model(inputs=[user_input, item_input], outputs=cos_sim)\n",
    "\n",
    "# Kompajliraj model\n",
    "model_tanh2.compile(optimizer= keras.optimizers.Nadam(learning_rate= 0.01), loss='mse', metrics=['mae', 'mse'])\n",
    "\n",
    "# Prikaži arhitekturu\n",
    "model_tanh2.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "fd81f6fa-1534-4720-9350-d131cdb66b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - loss: 0.1417 - mae: 0.2872 - mse: 0.1417 - val_loss: 0.1358 - val_mae: 0.2817 - val_mse: 0.1358 - learning_rate: 0.0100\n",
      "Epoch 2/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 0.1354 - mae: 0.2803 - mse: 0.1354 - val_loss: 0.1364 - val_mae: 0.2825 - val_mse: 0.1364 - learning_rate: 0.0100\n",
      "Epoch 3/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 0.1356 - mae: 0.2807 - mse: 0.1356 - val_loss: 0.1364 - val_mae: 0.2819 - val_mse: 0.1364 - learning_rate: 0.0100\n",
      "Epoch 4/50\n",
      "\u001b[1m3051/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1356 - mae: 0.2809 - mse: 0.1356\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 0.1356 - mae: 0.2809 - mse: 0.1356 - val_loss: 0.1364 - val_mae: 0.2818 - val_mse: 0.1364 - learning_rate: 0.0100\n",
      "Epoch 5/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 0.1349 - mae: 0.2797 - mse: 0.1349 - val_loss: 0.1340 - val_mae: 0.2782 - val_mse: 0.1340 - learning_rate: 0.0050\n",
      "Epoch 6/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 0.1339 - mae: 0.2784 - mse: 0.1339 - val_loss: 0.1337 - val_mae: 0.2787 - val_mse: 0.1337 - learning_rate: 0.0050\n",
      "Epoch 7/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 0.1334 - mae: 0.2776 - mse: 0.1334 - val_loss: 0.1339 - val_mae: 0.2783 - val_mse: 0.1339 - learning_rate: 0.0050\n",
      "Epoch 8/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 0.1332 - mae: 0.2775 - mse: 0.1332 - val_loss: 0.1335 - val_mae: 0.2770 - val_mse: 0.1335 - learning_rate: 0.0050\n",
      "Epoch 9/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 0.1335 - mae: 0.2776 - mse: 0.1335 - val_loss: 0.1333 - val_mae: 0.2777 - val_mse: 0.1333 - learning_rate: 0.0050\n",
      "Epoch 10/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 0.1330 - mae: 0.2770 - mse: 0.1330 - val_loss: 0.1331 - val_mae: 0.2771 - val_mse: 0.1331 - learning_rate: 0.0050\n",
      "Epoch 11/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 0.1328 - mae: 0.2768 - mse: 0.1328 - val_loss: 0.1334 - val_mae: 0.2788 - val_mse: 0.1334 - learning_rate: 0.0050\n",
      "Epoch 12/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 0.1327 - mae: 0.2769 - mse: 0.1327 - val_loss: 0.1334 - val_mae: 0.2778 - val_mse: 0.1334 - learning_rate: 0.0050\n",
      "Epoch 13/50\n",
      "\u001b[1m3054/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1329 - mae: 0.2770 - mse: 0.1329\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 0.1329 - mae: 0.2770 - mse: 0.1329 - val_loss: 0.1336 - val_mae: 0.2796 - val_mse: 0.1336 - learning_rate: 0.0050\n",
      "Epoch 14/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 0.1318 - mae: 0.2755 - mse: 0.1318 - val_loss: 0.1318 - val_mae: 0.2758 - val_mse: 0.1318 - learning_rate: 0.0025\n",
      "Epoch 15/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 0.1313 - mae: 0.2749 - mse: 0.1313 - val_loss: 0.1318 - val_mae: 0.2751 - val_mse: 0.1318 - learning_rate: 0.0025\n",
      "Epoch 16/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 0.1309 - mae: 0.2745 - mse: 0.1309 - val_loss: 0.1317 - val_mae: 0.2750 - val_mse: 0.1317 - learning_rate: 0.0025\n",
      "Epoch 17/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 0.1310 - mae: 0.2744 - mse: 0.1310 - val_loss: 0.1315 - val_mae: 0.2754 - val_mse: 0.1315 - learning_rate: 0.0025\n",
      "Epoch 18/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 0.1309 - mae: 0.2743 - mse: 0.1309 - val_loss: 0.1315 - val_mae: 0.2761 - val_mse: 0.1315 - learning_rate: 0.0025\n",
      "Epoch 19/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 0.1307 - mae: 0.2740 - mse: 0.1307 - val_loss: 0.1315 - val_mae: 0.2761 - val_mse: 0.1315 - learning_rate: 0.0025\n",
      "Epoch 20/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 0.1309 - mae: 0.2744 - mse: 0.1309 - val_loss: 0.1312 - val_mae: 0.2748 - val_mse: 0.1312 - learning_rate: 0.0025\n",
      "Epoch 21/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 0.1301 - mae: 0.2735 - mse: 0.1301 - val_loss: 0.1311 - val_mae: 0.2752 - val_mse: 0.1311 - learning_rate: 0.0025\n",
      "Epoch 22/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 0.1304 - mae: 0.2738 - mse: 0.1304 - val_loss: 0.1311 - val_mae: 0.2744 - val_mse: 0.1311 - learning_rate: 0.0025\n",
      "Epoch 23/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 0.1305 - mae: 0.2738 - mse: 0.1305 - val_loss: 0.1309 - val_mae: 0.2744 - val_mse: 0.1309 - learning_rate: 0.0025\n",
      "Epoch 24/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 0.1301 - mae: 0.2734 - mse: 0.1301 - val_loss: 0.1310 - val_mae: 0.2747 - val_mse: 0.1310 - learning_rate: 0.0025\n",
      "Epoch 25/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 0.1302 - mae: 0.2733 - mse: 0.1302 - val_loss: 0.1312 - val_mae: 0.2754 - val_mse: 0.1312 - learning_rate: 0.0025\n",
      "Epoch 26/50\n",
      "\u001b[1m3055/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1300 - mae: 0.2732 - mse: 0.1300\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 0.1300 - mae: 0.2732 - mse: 0.1300 - val_loss: 0.1310 - val_mae: 0.2744 - val_mse: 0.1310 - learning_rate: 0.0025\n",
      "Epoch 27/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 0.1299 - mae: 0.2732 - mse: 0.1299 - val_loss: 0.1303 - val_mae: 0.2735 - val_mse: 0.1303 - learning_rate: 0.0012\n",
      "Epoch 28/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 0.1292 - mae: 0.2721 - mse: 0.1292 - val_loss: 0.1303 - val_mae: 0.2736 - val_mse: 0.1303 - learning_rate: 0.0012\n",
      "Epoch 29/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 0.1290 - mae: 0.2718 - mse: 0.1290 - val_loss: 0.1302 - val_mae: 0.2731 - val_mse: 0.1302 - learning_rate: 0.0012\n",
      "Epoch 30/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 0.1289 - mae: 0.2716 - mse: 0.1289 - val_loss: 0.1301 - val_mae: 0.2732 - val_mse: 0.1301 - learning_rate: 0.0012\n",
      "Epoch 31/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 0.1288 - mae: 0.2714 - mse: 0.1288 - val_loss: 0.1301 - val_mae: 0.2733 - val_mse: 0.1301 - learning_rate: 0.0012\n",
      "Epoch 32/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 0.1284 - mae: 0.2714 - mse: 0.1284 - val_loss: 0.1299 - val_mae: 0.2732 - val_mse: 0.1299 - learning_rate: 0.0012\n",
      "Epoch 33/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 0.1285 - mae: 0.2712 - mse: 0.1285 - val_loss: 0.1299 - val_mae: 0.2731 - val_mse: 0.1299 - learning_rate: 0.0012\n",
      "Epoch 34/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 0.1284 - mae: 0.2710 - mse: 0.1284 - val_loss: 0.1300 - val_mae: 0.2726 - val_mse: 0.1300 - learning_rate: 0.0012\n",
      "Epoch 35/50\n",
      "\u001b[1m3055/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1286 - mae: 0.2714 - mse: 0.1286\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 0.1286 - mae: 0.2714 - mse: 0.1286 - val_loss: 0.1300 - val_mae: 0.2728 - val_mse: 0.1300 - learning_rate: 0.0012\n",
      "Epoch 36/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 0.1283 - mae: 0.2710 - mse: 0.1283 - val_loss: 0.1297 - val_mae: 0.2727 - val_mse: 0.1297 - learning_rate: 6.2500e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 0.1281 - mae: 0.2707 - mse: 0.1281 - val_loss: 0.1296 - val_mae: 0.2726 - val_mse: 0.1296 - learning_rate: 6.2500e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 0.1274 - mae: 0.2701 - mse: 0.1274 - val_loss: 0.1295 - val_mae: 0.2724 - val_mse: 0.1295 - learning_rate: 6.2500e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 0.1275 - mae: 0.2700 - mse: 0.1275 - val_loss: 0.1295 - val_mae: 0.2723 - val_mse: 0.1295 - learning_rate: 6.2500e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 0.1275 - mae: 0.2700 - mse: 0.1275 - val_loss: 0.1295 - val_mae: 0.2725 - val_mse: 0.1295 - learning_rate: 6.2500e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m3050/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1273 - mae: 0.2699 - mse: 0.1273\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 0.1273 - mae: 0.2699 - mse: 0.1273 - val_loss: 0.1295 - val_mae: 0.2723 - val_mse: 0.1295 - learning_rate: 6.2500e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 0.1269 - mae: 0.2692 - mse: 0.1269 - val_loss: 0.1294 - val_mae: 0.2723 - val_mse: 0.1294 - learning_rate: 3.1250e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 0.1268 - mae: 0.2693 - mse: 0.1268 - val_loss: 0.1294 - val_mae: 0.2722 - val_mse: 0.1294 - learning_rate: 3.1250e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 0.1267 - mae: 0.2691 - mse: 0.1267 - val_loss: 0.1294 - val_mae: 0.2722 - val_mse: 0.1294 - learning_rate: 3.1250e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1268 - mae: 0.2692 - mse: 0.1268\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 0.1268 - mae: 0.2692 - mse: 0.1268 - val_loss: 0.1294 - val_mae: 0.2724 - val_mse: 0.1294 - learning_rate: 3.1250e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 0.1265 - mae: 0.2689 - mse: 0.1265 - val_loss: 0.1294 - val_mae: 0.2720 - val_mse: 0.1294 - learning_rate: 1.5625e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 0.1261 - mae: 0.2686 - mse: 0.1261 - val_loss: 0.1294 - val_mae: 0.2722 - val_mse: 0.1294 - learning_rate: 1.5625e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m3051/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1262 - mae: 0.2684 - mse: 0.1262\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 0.1262 - mae: 0.2684 - mse: 0.1262 - val_loss: 0.1294 - val_mae: 0.2721 - val_mse: 0.1294 - learning_rate: 1.5625e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 0.1262 - mae: 0.2684 - mse: 0.1262 - val_loss: 0.1294 - val_mae: 0.2722 - val_mse: 0.1294 - learning_rate: 7.8125e-05\n",
      "Epoch 50/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 0.1262 - mae: 0.2686 - mse: 0.1262 - val_loss: 0.1294 - val_mae: 0.2721 - val_mse: 0.1294 - learning_rate: 7.8125e-05\n"
     ]
    }
   ],
   "source": [
    "history_tanh2 = model_tanh2.fit(x=[X_user_train, X_movie_train],y=y_train, callbacks=[early_stop, reduce_lr],\n",
    "    validation_data=([X_user_dev, X_movie_dev], y_dev),epochs=50, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "b6bf5a3b-b535-42a2-b19d-b12c1b5df3be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 0.1262 - mae: 0.2685 - mse: 0.1262 - val_loss: 0.1294 - val_mae: 0.2721 - val_mse: 0.1294 - learning_rate: 7.8125e-05\n",
      "Epoch 2/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 0.1259 - mae: 0.2682 - mse: 0.1259 - val_loss: 0.1294 - val_mae: 0.2721 - val_mse: 0.1294 - learning_rate: 7.8125e-05\n",
      "Epoch 3/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 0.1262 - mae: 0.2684 - mse: 0.1262 - val_loss: 0.1294 - val_mae: 0.2721 - val_mse: 0.1294 - learning_rate: 7.8125e-05\n",
      "Epoch 4/50\n",
      "\u001b[1m3054/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1264 - mae: 0.2686 - mse: 0.1264\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 0.1264 - mae: 0.2686 - mse: 0.1264 - val_loss: 0.1294 - val_mae: 0.2721 - val_mse: 0.1294 - learning_rate: 7.8125e-05\n",
      "Epoch 5/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 0.1263 - mae: 0.2686 - mse: 0.1263 - val_loss: 0.1294 - val_mae: 0.2721 - val_mse: 0.1294 - learning_rate: 3.9062e-05\n"
     ]
    }
   ],
   "source": [
    "history_tanh2 = model_tanh2.fit(x=[X_user_train, X_movie_train],y=y_train, callbacks=[early_stop, reduce_lr],\n",
    "    validation_data=([X_user_dev, X_movie_dev], y_dev),epochs=50, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "2ea40dcd-263b-4b8b-a8dd-91e76491dedc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_23\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_23\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ item_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_157 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,200</span> │ user_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_161 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,800</span> │ item_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_158 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">25,728</span> │ dense_157[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_162 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">25,728</span> │ dense_161[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_159 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │ dense_158[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_163 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │ dense_162[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_160 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dense_159[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_164 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dense_163[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lambda_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_160[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lambda_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_164[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ cosine_similarity (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lambda_30[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           │\n",
       "│                               │                           │                 │ lambda_31[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_input (\u001b[38;5;33mInputLayer\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ item_input (\u001b[38;5;33mInputLayer\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_157 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)               │           \u001b[38;5;34m4,200\u001b[0m │ user_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_161 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)               │           \u001b[38;5;34m4,800\u001b[0m │ item_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_158 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │          \u001b[38;5;34m25,728\u001b[0m │ dense_157[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_162 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │          \u001b[38;5;34m25,728\u001b[0m │ dense_161[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_159 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │          \u001b[38;5;34m16,512\u001b[0m │ dense_158[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_163 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │          \u001b[38;5;34m16,512\u001b[0m │ dense_162[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_160 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m8,256\u001b[0m │ dense_159[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_164 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m8,256\u001b[0m │ dense_163[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lambda_30 (\u001b[38;5;33mLambda\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_160[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lambda_31 (\u001b[38;5;33mLambda\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_164[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ cosine_similarity (\u001b[38;5;33mDot\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │ lambda_30[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           │\n",
       "│                               │                           │                 │ lambda_31[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">109,992</span> (429.66 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m109,992\u001b[0m (429.66 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">109,992</span> (429.66 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m109,992\u001b[0m (429.66 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_user_features = X_user_numpy.shape[1]\n",
    "num_item_features = X_movie_numpy.shape[1]\n",
    "num_outputs = 64\n",
    "\n",
    "# ---------------- USER MODEL ----------------\n",
    "user_input = keras.Input(shape=(num_user_features,), name='user_input')\n",
    "x_user = layers.Dense(200, activation='tanh', kernel_initializer='glorot_uniform')(user_input)\n",
    "x_user = layers.Dense(128, activation='tanh', kernel_initializer='glorot_uniform')(x_user)\n",
    "x_user = layers.Dense(128, activation='tanh', kernel_initializer='glorot_uniform')(x_user)\n",
    "x_user = layers.Dense(num_outputs, activation='tanh', kernel_initializer='glorot_uniform')(x_user)\n",
    "user_embedding = layers.Lambda(lambda x: tf.nn.l2_normalize(x, axis=1))(x_user)\n",
    "\n",
    "# ---------------- ITEM MODEL ----------------\n",
    "item_input = keras.Input(shape=(num_item_features,), name='item_input')\n",
    "x_item = layers.Dense(200, activation='tanh', kernel_initializer='glorot_uniform')(item_input)\n",
    "x_item = layers.Dense(128, activation='tanh', kernel_initializer='glorot_uniform')(x_item)\n",
    "x_item = layers.Dense(128, activation='tanh', kernel_initializer='glorot_uniform')(x_item)\n",
    "x_item = layers.Dense(num_outputs, activation='tanh', kernel_initializer='glorot_uniform')(x_item)\n",
    "item_embedding = layers.Lambda(lambda x: tf.nn.l2_normalize(x, axis=1))(x_item)\n",
    "\n",
    "# ---------------- COSINE SIMILARITY ----------------\n",
    "cos_sim = layers.Dot(axes=1, name='cosine_similarity')([user_embedding, item_embedding])\n",
    "# rezultat je u [-1, 1]\n",
    "\n",
    "# ---------------- FINAL MODEL ----------------\n",
    "model_tanh3 = keras.Model(inputs=[user_input, item_input], outputs=cos_sim)\n",
    "\n",
    "# Kompajliraj model\n",
    "model_tanh3.compile(optimizer= keras.optimizers.Nadam(learning_rate= 0.01), loss='mse', metrics=['mae', 'mse'])\n",
    "\n",
    "# Prikaži arhitekturu\n",
    "model_tanh3.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "48fe17ae-7876-4ee0-b5a4-a4f63bba1fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 8ms/step - loss: 0.1442 - mae: 0.2900 - mse: 0.1442 - val_loss: 0.1368 - val_mae: 0.2830 - val_mse: 0.1368 - learning_rate: 0.0100\n",
      "Epoch 2/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - loss: 0.1375 - mae: 0.2827 - mse: 0.1375 - val_loss: 0.1382 - val_mae: 0.2827 - val_mse: 0.1382 - learning_rate: 0.0100\n",
      "Epoch 3/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - loss: 0.1381 - mae: 0.2838 - mse: 0.1381 - val_loss: 0.1386 - val_mae: 0.2850 - val_mse: 0.1386 - learning_rate: 0.0100\n",
      "Epoch 4/50\n",
      "\u001b[1m3055/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1380 - mae: 0.2840 - mse: 0.1380\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - loss: 0.1380 - mae: 0.2840 - mse: 0.1380 - val_loss: 0.1386 - val_mae: 0.2857 - val_mse: 0.1386 - learning_rate: 0.0100\n",
      "Epoch 5/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - loss: 0.1371 - mae: 0.2822 - mse: 0.1371 - val_loss: 0.1363 - val_mae: 0.2802 - val_mse: 0.1363 - learning_rate: 0.0050\n",
      "Epoch 6/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - loss: 0.1352 - mae: 0.2799 - mse: 0.1352 - val_loss: 0.1360 - val_mae: 0.2816 - val_mse: 0.1360 - learning_rate: 0.0050\n",
      "Epoch 7/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - loss: 0.1358 - mae: 0.2804 - mse: 0.1358 - val_loss: 0.1358 - val_mae: 0.2810 - val_mse: 0.1358 - learning_rate: 0.0050\n",
      "Epoch 8/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - loss: 0.1351 - mae: 0.2795 - mse: 0.1351 - val_loss: 0.1357 - val_mae: 0.2801 - val_mse: 0.1357 - learning_rate: 0.0050\n",
      "Epoch 9/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - loss: 0.1351 - mae: 0.2794 - mse: 0.1351 - val_loss: 0.1353 - val_mae: 0.2803 - val_mse: 0.1353 - learning_rate: 0.0050\n",
      "Epoch 10/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - loss: 0.1353 - mae: 0.2797 - mse: 0.1353 - val_loss: 0.1358 - val_mae: 0.2796 - val_mse: 0.1358 - learning_rate: 0.0050\n",
      "Epoch 11/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - loss: 0.1349 - mae: 0.2794 - mse: 0.1349 - val_loss: 0.1351 - val_mae: 0.2804 - val_mse: 0.1351 - learning_rate: 0.0050\n",
      "Epoch 12/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - loss: 0.1348 - mae: 0.2791 - mse: 0.1348 - val_loss: 0.1350 - val_mae: 0.2800 - val_mse: 0.1350 - learning_rate: 0.0050\n",
      "Epoch 13/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - loss: 0.1347 - mae: 0.2790 - mse: 0.1347 - val_loss: 0.1350 - val_mae: 0.2793 - val_mse: 0.1350 - learning_rate: 0.0050\n",
      "Epoch 14/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - loss: 0.1350 - mae: 0.2794 - mse: 0.1350 - val_loss: 0.1354 - val_mae: 0.2805 - val_mse: 0.1354 - learning_rate: 0.0050\n",
      "Epoch 15/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - loss: 0.1351 - mae: 0.2796 - mse: 0.1351 - val_loss: 0.1349 - val_mae: 0.2801 - val_mse: 0.1349 - learning_rate: 0.0050\n",
      "Epoch 16/50\n",
      "\u001b[1m3053/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1346 - mae: 0.2789 - mse: 0.1346\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - loss: 0.1346 - mae: 0.2789 - mse: 0.1346 - val_loss: 0.1351 - val_mae: 0.2801 - val_mse: 0.1351 - learning_rate: 0.0050\n",
      "Epoch 17/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - loss: 0.1340 - mae: 0.2781 - mse: 0.1340 - val_loss: 0.1340 - val_mae: 0.2784 - val_mse: 0.1340 - learning_rate: 0.0025\n",
      "Epoch 18/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - loss: 0.1337 - mae: 0.2776 - mse: 0.1337 - val_loss: 0.1340 - val_mae: 0.2784 - val_mse: 0.1340 - learning_rate: 0.0025\n",
      "Epoch 19/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - loss: 0.1331 - mae: 0.2769 - mse: 0.1331 - val_loss: 0.1338 - val_mae: 0.2782 - val_mse: 0.1338 - learning_rate: 0.0025\n",
      "Epoch 20/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - loss: 0.1332 - mae: 0.2772 - mse: 0.1332 - val_loss: 0.1336 - val_mae: 0.2777 - val_mse: 0.1336 - learning_rate: 0.0025\n",
      "Epoch 21/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - loss: 0.1327 - mae: 0.2764 - mse: 0.1327 - val_loss: 0.1335 - val_mae: 0.2769 - val_mse: 0.1335 - learning_rate: 0.0025\n",
      "Epoch 22/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - loss: 0.1330 - mae: 0.2766 - mse: 0.1330 - val_loss: 0.1333 - val_mae: 0.2770 - val_mse: 0.1333 - learning_rate: 0.0025\n",
      "Epoch 23/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - loss: 0.1331 - mae: 0.2768 - mse: 0.1331 - val_loss: 0.1332 - val_mae: 0.2771 - val_mse: 0.1332 - learning_rate: 0.0025\n",
      "Epoch 24/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - loss: 0.1328 - mae: 0.2765 - mse: 0.1328 - val_loss: 0.1333 - val_mae: 0.2774 - val_mse: 0.1333 - learning_rate: 0.0025\n",
      "Epoch 25/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - loss: 0.1326 - mae: 0.2764 - mse: 0.1326 - val_loss: 0.1333 - val_mae: 0.2769 - val_mse: 0.1333 - learning_rate: 0.0025\n",
      "Epoch 26/50\n",
      "\u001b[1m3053/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1330 - mae: 0.2767 - mse: 0.1330\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - loss: 0.1330 - mae: 0.2767 - mse: 0.1330 - val_loss: 0.1334 - val_mae: 0.2767 - val_mse: 0.1334 - learning_rate: 0.0025\n",
      "Epoch 27/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - loss: 0.1327 - mae: 0.2761 - mse: 0.1327 - val_loss: 0.1328 - val_mae: 0.2769 - val_mse: 0.1328 - learning_rate: 0.0012\n",
      "Epoch 28/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - loss: 0.1320 - mae: 0.2754 - mse: 0.1320 - val_loss: 0.1326 - val_mae: 0.2763 - val_mse: 0.1326 - learning_rate: 0.0012\n",
      "Epoch 29/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - loss: 0.1314 - mae: 0.2749 - mse: 0.1314 - val_loss: 0.1324 - val_mae: 0.2760 - val_mse: 0.1324 - learning_rate: 0.0012\n",
      "Epoch 30/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - loss: 0.1317 - mae: 0.2752 - mse: 0.1317 - val_loss: 0.1325 - val_mae: 0.2762 - val_mse: 0.1325 - learning_rate: 0.0012\n",
      "Epoch 31/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 7ms/step - loss: 0.1314 - mae: 0.2748 - mse: 0.1314 - val_loss: 0.1324 - val_mae: 0.2761 - val_mse: 0.1324 - learning_rate: 0.0012\n",
      "Epoch 32/50\n",
      "\u001b[1m3050/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1313 - mae: 0.2748 - mse: 0.1313\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - loss: 0.1313 - mae: 0.2748 - mse: 0.1313 - val_loss: 0.1324 - val_mae: 0.2760 - val_mse: 0.1324 - learning_rate: 0.0012\n",
      "Epoch 33/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - loss: 0.1313 - mae: 0.2745 - mse: 0.1313 - val_loss: 0.1320 - val_mae: 0.2754 - val_mse: 0.1320 - learning_rate: 6.2500e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - loss: 0.1305 - mae: 0.2737 - mse: 0.1305 - val_loss: 0.1321 - val_mae: 0.2757 - val_mse: 0.1321 - learning_rate: 6.2500e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - loss: 0.1307 - mae: 0.2739 - mse: 0.1307 - val_loss: 0.1319 - val_mae: 0.2754 - val_mse: 0.1319 - learning_rate: 6.2500e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - loss: 0.1304 - mae: 0.2736 - mse: 0.1304 - val_loss: 0.1318 - val_mae: 0.2752 - val_mse: 0.1318 - learning_rate: 6.2500e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - loss: 0.1304 - mae: 0.2735 - mse: 0.1304 - val_loss: 0.1319 - val_mae: 0.2756 - val_mse: 0.1319 - learning_rate: 6.2500e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - loss: 0.1304 - mae: 0.2737 - mse: 0.1304 - val_loss: 0.1318 - val_mae: 0.2751 - val_mse: 0.1318 - learning_rate: 6.2500e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - loss: 0.1302 - mae: 0.2733 - mse: 0.1302 - val_loss: 0.1317 - val_mae: 0.2749 - val_mse: 0.1317 - learning_rate: 6.2500e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - loss: 0.1303 - mae: 0.2735 - mse: 0.1303 - val_loss: 0.1317 - val_mae: 0.2750 - val_mse: 0.1317 - learning_rate: 6.2500e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 8ms/step - loss: 0.1303 - mae: 0.2733 - mse: 0.1303 - val_loss: 0.1317 - val_mae: 0.2752 - val_mse: 0.1317 - learning_rate: 6.2500e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - loss: 0.1302 - mae: 0.2732 - mse: 0.1302 - val_loss: 0.1316 - val_mae: 0.2748 - val_mse: 0.1316 - learning_rate: 6.2500e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1299 - mae: 0.2727 - mse: 0.1299\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - loss: 0.1299 - mae: 0.2727 - mse: 0.1299 - val_loss: 0.1316 - val_mae: 0.2747 - val_mse: 0.1316 - learning_rate: 6.2500e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - loss: 0.1301 - mae: 0.2730 - mse: 0.1301 - val_loss: 0.1316 - val_mae: 0.2746 - val_mse: 0.1316 - learning_rate: 3.1250e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - loss: 0.1294 - mae: 0.2722 - mse: 0.1294 - val_loss: 0.1315 - val_mae: 0.2745 - val_mse: 0.1315 - learning_rate: 3.1250e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - loss: 0.1294 - mae: 0.2723 - mse: 0.1294 - val_loss: 0.1314 - val_mae: 0.2745 - val_mse: 0.1314 - learning_rate: 3.1250e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 7ms/step - loss: 0.1294 - mae: 0.2721 - mse: 0.1294 - val_loss: 0.1314 - val_mae: 0.2745 - val_mse: 0.1314 - learning_rate: 3.1250e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m3052/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1295 - mae: 0.2720 - mse: 0.1295\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - loss: 0.1295 - mae: 0.2720 - mse: 0.1295 - val_loss: 0.1314 - val_mae: 0.2744 - val_mse: 0.1314 - learning_rate: 3.1250e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - loss: 0.1291 - mae: 0.2719 - mse: 0.1291 - val_loss: 0.1314 - val_mae: 0.2745 - val_mse: 0.1314 - learning_rate: 1.5625e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - loss: 0.1291 - mae: 0.2718 - mse: 0.1291 - val_loss: 0.1314 - val_mae: 0.2744 - val_mse: 0.1314 - learning_rate: 1.5625e-04\n"
     ]
    }
   ],
   "source": [
    "history_tanh3 = model_tanh3.fit(x=[X_user_train, X_movie_train],y=y_train, callbacks=[early_stop, reduce_lr],\n",
    "    validation_data=([X_user_dev, X_movie_dev], y_dev),epochs=50, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "74c792bf-d68d-4a67-9a79-da620d86bd62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 7ms/step - loss: 0.1289 - mae: 0.2716 - mse: 0.1289 - val_loss: 0.1314 - val_mae: 0.2745 - val_mse: 0.1314 - learning_rate: 1.5625e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - loss: 0.1289 - mae: 0.2716 - mse: 0.1289 - val_loss: 0.1314 - val_mae: 0.2743 - val_mse: 0.1314 - learning_rate: 1.5625e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - loss: 0.1286 - mae: 0.2713 - mse: 0.1286 - val_loss: 0.1314 - val_mae: 0.2745 - val_mse: 0.1314 - learning_rate: 1.5625e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m3049/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1287 - mae: 0.2713 - mse: 0.1287\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - loss: 0.1287 - mae: 0.2713 - mse: 0.1287 - val_loss: 0.1314 - val_mae: 0.2744 - val_mse: 0.1314 - learning_rate: 1.5625e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - loss: 0.1286 - mae: 0.2712 - mse: 0.1286 - val_loss: 0.1314 - val_mae: 0.2743 - val_mse: 0.1314 - learning_rate: 7.8125e-05\n",
      "Epoch 6/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - loss: 0.1286 - mae: 0.2712 - mse: 0.1286 - val_loss: 0.1314 - val_mae: 0.2744 - val_mse: 0.1314 - learning_rate: 7.8125e-05\n",
      "Epoch 7/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1283 - mae: 0.2710 - mse: 0.1283\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 8ms/step - loss: 0.1283 - mae: 0.2710 - mse: 0.1283 - val_loss: 0.1314 - val_mae: 0.2744 - val_mse: 0.1314 - learning_rate: 7.8125e-05\n",
      "Epoch 8/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 8ms/step - loss: 0.1283 - mae: 0.2709 - mse: 0.1283 - val_loss: 0.1314 - val_mae: 0.2744 - val_mse: 0.1314 - learning_rate: 3.9062e-05\n",
      "Epoch 9/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 7ms/step - loss: 0.1283 - mae: 0.2709 - mse: 0.1283 - val_loss: 0.1313 - val_mae: 0.2743 - val_mse: 0.1313 - learning_rate: 3.9062e-05\n",
      "Epoch 10/50\n",
      "\u001b[1m3054/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1286 - mae: 0.2711 - mse: 0.1286\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 1.9531249563442543e-05.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - loss: 0.1286 - mae: 0.2711 - mse: 0.1286 - val_loss: 0.1314 - val_mae: 0.2743 - val_mse: 0.1314 - learning_rate: 3.9062e-05\n",
      "Epoch 11/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - loss: 0.1284 - mae: 0.2709 - mse: 0.1284 - val_loss: 0.1314 - val_mae: 0.2743 - val_mse: 0.1314 - learning_rate: 1.9531e-05\n",
      "Epoch 12/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - loss: 0.1281 - mae: 0.2706 - mse: 0.1281 - val_loss: 0.1314 - val_mae: 0.2743 - val_mse: 0.1314 - learning_rate: 1.9531e-05\n",
      "Epoch 13/50\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1285 - mae: 0.2711 - mse: 0.1285\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 9.765624781721272e-06.\n",
      "\u001b[1m3056/3056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - loss: 0.1285 - mae: 0.2711 - mse: 0.1285 - val_loss: 0.1314 - val_mae: 0.2743 - val_mse: 0.1314 - learning_rate: 1.9531e-05\n"
     ]
    }
   ],
   "source": [
    "history_tanh3 = model_tanh3.fit(x=[X_user_train, X_movie_train],y=y_train, callbacks=[early_stop, reduce_lr],\n",
    "    validation_data=([X_user_dev, X_movie_dev], y_dev),epochs=50, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097810ed-c60c-40ed-8b17-a80c94b8c3b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205e62d0-5f35-42ab-844c-7ccd06917fb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec59136-fd43-49ea-8862-c60d84e8d5e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86ea3a7-89bd-4d57-a315-5a1267856b1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd46ef43-7993-4a23-857a-a76c25d5e117",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df170d9-f88f-4c69-b513-5aba12e7799c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d0f30941-f917-4700-acd4-8cfc7e3c7730",
   "metadata": {},
   "source": [
    "### SKIDAM REGULARIZACIJU SA POSLEDNJA 2 SLOJA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "794205cc-5bab-42fd-bbbc-a4f6b0b41ddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_19\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_19\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ movie_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_121 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,688</span> │ user_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_127 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,072</span> │ movie_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_72 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_121[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_78 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_127[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_122 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │ dropout_72[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_128 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │ dropout_78[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_73 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_122[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_79 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_128[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_123 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │ dropout_73[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_129 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │ dropout_79[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_74 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_123[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_80 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_129[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_124 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │ dropout_74[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_130 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │ dropout_80[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_75 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_124[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_81 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_130[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_125 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_75[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_131 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_81[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_76 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_125[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_82 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_131[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_126 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ dropout_76[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_132 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ dropout_82[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_77 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_126[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_83 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_132[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ user_embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ dropout_77[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ movie_embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ dropout_83[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dot_product (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ user_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
       "│                               │                           │                 │ movie_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_input (\u001b[38;5;33mInputLayer\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ movie_input (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_121 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │           \u001b[38;5;34m2,688\u001b[0m │ user_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_127 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │           \u001b[38;5;34m3,072\u001b[0m │ movie_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_72 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ dense_121[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_78 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ dense_127[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_122 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │          \u001b[38;5;34m16,512\u001b[0m │ dropout_72[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_128 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │          \u001b[38;5;34m16,512\u001b[0m │ dropout_78[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_73 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ dense_122[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_79 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ dense_128[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_123 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │          \u001b[38;5;34m16,512\u001b[0m │ dropout_73[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_129 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │          \u001b[38;5;34m16,512\u001b[0m │ dropout_79[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_74 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ dense_123[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_80 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ dense_129[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_124 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │          \u001b[38;5;34m16,512\u001b[0m │ dropout_74[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_130 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │          \u001b[38;5;34m16,512\u001b[0m │ dropout_80[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_75 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ dense_124[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_81 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ dense_130[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_125 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m8,256\u001b[0m │ dropout_75[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_131 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m8,256\u001b[0m │ dropout_81[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_76 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_125[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_82 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_131[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_126 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m4,160\u001b[0m │ dropout_76[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_132 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m4,160\u001b[0m │ dropout_82[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_77 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_126[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_83 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_132[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ user_embedding (\u001b[38;5;33mDense\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m4,160\u001b[0m │ dropout_77[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ movie_embedding (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m4,160\u001b[0m │ dropout_83[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dot_product (\u001b[38;5;33mDot\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │ user_embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
       "│                               │                           │                 │ movie_embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">137,984</span> (539.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m137,984\u001b[0m (539.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">137,984</span> (539.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m137,984\u001b[0m (539.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_user_features = X_user_numpy.shape[1]   \n",
    "num_movie_features = X_movie_numpy.shape[1]\n",
    "drop = 0.3\n",
    "# ---------------- USER TOWER ----------------\n",
    "user_input = layers.Input(shape=(num_user_features,), name='user_input')\n",
    "x = layers.Dense(128, activation='relu')(user_input)\n",
    "x = layers.Dropout(drop)(x)\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "x = layers.Dropout(drop)(x)\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "x = layers.Dropout(drop)(x)\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "x = layers.Dropout(drop)(x)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "x = layers.Dropout(drop)(x)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "x = layers.Dropout(drop)(x)\n",
    "\n",
    "user_embedding = layers.Dense(64, activation='linear', name='user_embedding')(x)\n",
    "\n",
    "# ---------------- MOVIE TOWER ----------------\n",
    "movie_input = layers.Input(shape=(num_movie_features,), name='movie_input')\n",
    "\n",
    "x2= layers.Dense(128, activation='relu')(movie_input)\n",
    "x2 = layers.Dropout(drop)(x2)\n",
    "x2 = layers.Dense(128, activation='relu')(x2)\n",
    "x2 = layers.Dropout(drop)(x2)\n",
    "x2 = layers.Dense(128, activation='relu')(x2)\n",
    "x2 = layers.Dropout(drop)(x2)\n",
    "x2 = layers.Dense(128, activation='relu')(x2)\n",
    "x2 = layers.Dropout(drop)(x2)\n",
    "x2 = layers.Dense(64, activation='relu')(x2)\n",
    "x2 = layers.Dropout(drop)(x2)\n",
    "x2 = layers.Dense(64, activation='relu')(x2)\n",
    "x2 = layers.Dropout(drop)(x2)\n",
    "\n",
    "movie_embedding = layers.Dense(64, activation='linear', name='movie_embedding')(x2)\n",
    "\n",
    "# ---------------- FINAL MODEL ----------------\n",
    "dot_product = layers.Dot(axes=1, name='dot_product')([user_embedding, movie_embedding])\n",
    "\n",
    "model4 = models.Model(inputs=[user_input, movie_input], outputs=dot_product)\n",
    "\n",
    "# Compile model\n",
    "model4.compile( loss='mse', metrics=['mae', 'mse'])\n",
    "\n",
    "# Pregled modela\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "edeab81b-ff84-4f6a-913b-0ac6a948d42b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m1377/3056\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - loss: 0.1754 - mae: 0.3184 - mse: 0.1704"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[316]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     10\u001b[39m reduce_lr = ReduceLROnPlateau(\n\u001b[32m     11\u001b[39m     monitor=\u001b[33m'\u001b[39m\u001b[33mval_loss\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     12\u001b[39m     factor=\u001b[32m0.5\u001b[39m,\n\u001b[32m     13\u001b[39m     patience=\u001b[32m3\u001b[39m,\n\u001b[32m     14\u001b[39m     verbose=\u001b[32m1\u001b[39m\n\u001b[32m     15\u001b[39m )\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# --- Treniraj model ---\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m history4 = \u001b[43mmodel4\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_user_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_movie_train\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mearly_stop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_user_dev\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_movie_dev\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_dev\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m512\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:371\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    370\u001b[39m     callbacks.on_train_batch_begin(step)\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    372\u001b[39m     callbacks.on_train_batch_end(step, logs)\n\u001b[32m    373\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:219\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    217\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    218\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    220\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    221\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m    138\u001b[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bound_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1688\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1686\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1687\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1688\u001b[39m   outputs = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1689\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1690\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1691\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1696\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1697\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1698\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1702\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1703\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# --- EarlyStopping ---\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# --- ReduceLROnPlateau ---\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# --- Treniraj model ---\n",
    "history4 = model4.fit(x=[X_user_train, X_movie_train],y=y_train, callbacks=[early_stop, reduce_lr],\n",
    "    validation_data=([X_user_dev, X_movie_dev], y_dev),epochs=30, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "7f8fab76-2bfa-4420-8c17-3115d9eb2d9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_20\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_20\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ movie_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_133 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,688</span> │ user_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_139 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,072</span> │ movie_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_84 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_133[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_90 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_139[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_134 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │ dropout_84[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_140 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │ dropout_90[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_85 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_134[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_91 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_140[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_135 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │ dropout_85[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_141 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │ dropout_91[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_86 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_135[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_92 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_141[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_136 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │ dropout_86[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_142 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │ dropout_92[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_87 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_136[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_93 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_142[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_137 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_87[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_143 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_93[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_88 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_137[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_94 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_143[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_138 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dropout_88[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_144 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dropout_94[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_89 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_138[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_95 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_144[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ user_embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │ dropout_89[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ movie_embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │ dropout_95[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dot_product (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ user_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
       "│                               │                           │                 │ movie_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_input (\u001b[38;5;33mInputLayer\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ movie_input (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_133 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │           \u001b[38;5;34m2,688\u001b[0m │ user_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_139 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │           \u001b[38;5;34m3,072\u001b[0m │ movie_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_84 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ dense_133[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_90 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ dense_139[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_134 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │          \u001b[38;5;34m16,512\u001b[0m │ dropout_84[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_140 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │          \u001b[38;5;34m16,512\u001b[0m │ dropout_90[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_85 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ dense_134[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_91 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ dense_140[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_135 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │          \u001b[38;5;34m16,512\u001b[0m │ dropout_85[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_141 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │          \u001b[38;5;34m16,512\u001b[0m │ dropout_91[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_86 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ dense_135[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_92 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ dense_141[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_136 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │          \u001b[38;5;34m16,512\u001b[0m │ dropout_86[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_142 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │          \u001b[38;5;34m16,512\u001b[0m │ dropout_92[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_87 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ dense_136[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_93 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ dense_142[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_137 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m8,256\u001b[0m │ dropout_87[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_143 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m8,256\u001b[0m │ dropout_93[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_88 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_137[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_94 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_143[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_138 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │           \u001b[38;5;34m2,080\u001b[0m │ dropout_88[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_144 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │           \u001b[38;5;34m2,080\u001b[0m │ dropout_94[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_89 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_138[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_95 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_144[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ user_embedding (\u001b[38;5;33mDense\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │           \u001b[38;5;34m1,056\u001b[0m │ dropout_89[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ movie_embedding (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │           \u001b[38;5;34m1,056\u001b[0m │ dropout_95[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dot_product (\u001b[38;5;33mDot\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │ user_embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
       "│                               │                           │                 │ movie_embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">127,616</span> (498.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m127,616\u001b[0m (498.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">127,616</span> (498.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m127,616\u001b[0m (498.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_user_features = X_user_numpy.shape[1]   \n",
    "num_movie_features = X_movie_numpy.shape[1]\n",
    "drop = 0.2\n",
    "# ---------------- USER TOWER ----------------\n",
    "user_input = layers.Input(shape=(num_user_features,), name='user_input')\n",
    "x = layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001))(user_input)\n",
    "x = layers.Dropout(drop)(x)\n",
    "x = layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "x = layers.Dropout(drop)(x)\n",
    "x = layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "x = layers.Dropout(drop)(x)\n",
    "x = layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "x = layers.Dropout(drop)(x)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "x = layers.Dropout(drop)(x)\n",
    "x = layers.Dense(32, activation='relu')(x)\n",
    "x = layers.Dropout(drop)(x)\n",
    "\n",
    "user_embedding = layers.Dense(32, activation='linear', name='user_embedding')(x)\n",
    "\n",
    "# ---------------- MOVIE TOWER ----------------\n",
    "movie_input = layers.Input(shape=(num_movie_features,), name='movie_input')\n",
    "\n",
    "x2= layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01))(movie_input)\n",
    "x2 = layers.Dropout(drop)(x2)\n",
    "x2 = layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01))(x2)\n",
    "x2 = layers.Dropout(drop)(x2)\n",
    "x2 = layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01))(x2)\n",
    "x2 = layers.Dropout(drop)(x2)\n",
    "x2 = layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01))(x2)\n",
    "x2 = layers.Dropout(drop)(x2)\n",
    "x2 = layers.Dense(64, activation='relu')(x2)\n",
    "x2 = layers.Dropout(drop)(x2)\n",
    "x2 = layers.Dense(32, activation='relu')(x2)\n",
    "x2 = layers.Dropout(drop)(x2)\n",
    "\n",
    "movie_embedding = layers.Dense(32, activation='linear', name='movie_embedding')(x2)\n",
    "\n",
    "# ---------------- FINAL MODEL ----------------\n",
    "dot_product = layers.Dot(axes=1, name='dot_product')([user_embedding, movie_embedding])\n",
    "\n",
    "model4 = models.Model(inputs=[user_input, movie_input], outputs=dot_product)\n",
    "\n",
    "# Compile model\n",
    "model4.compile( loss='mse', metrics=['mae', 'mse'])\n",
    "\n",
    "# Pregled modela\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "725009fe-6242-44da-ac52-1e6817e68171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m 2800/12223\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m42s\u001b[0m 4ms/step - loss: 0.6265 - mae: 0.3383 - mse: 0.1880"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[298]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     10\u001b[39m reduce_lr = ReduceLROnPlateau(\n\u001b[32m     11\u001b[39m     monitor=\u001b[33m'\u001b[39m\u001b[33mval_loss\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     12\u001b[39m     factor=\u001b[32m0.5\u001b[39m,\n\u001b[32m     13\u001b[39m     patience=\u001b[32m3\u001b[39m,\n\u001b[32m     14\u001b[39m     verbose=\u001b[32m1\u001b[39m\n\u001b[32m     15\u001b[39m )\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# --- Treniraj model ---\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m history4 = \u001b[43mmodel4\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_user_numpy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_movie_numpy\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m128\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.15\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:371\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    370\u001b[39m     callbacks.on_train_batch_begin(step)\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    372\u001b[39m     callbacks.on_train_batch_end(step, logs)\n\u001b[32m    373\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:219\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    217\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    218\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    220\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    221\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m    138\u001b[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bound_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1688\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1686\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1687\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1688\u001b[39m   outputs = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1689\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1690\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1691\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1696\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1697\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1698\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1702\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1703\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# --- EarlyStopping ---\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# --- ReduceLROnPlateau ---\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# --- Treniraj model ---\n",
    "history4 = model4.fit(\n",
    "    [X_user_numpy, X_movie_numpy],\n",
    "    y,\n",
    "    epochs=50,\n",
    "    batch_size=128,\n",
    "    validation_split=0.15,\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "95733edf-4beb-4e42-8a6c-b0facc70ea1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ movie_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,688</span> │ user_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,072</span> │ movie_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_30[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │ dropout_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │ dropout_30[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_31[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │ dropout_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │ dropout_31[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_32[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │ dropout_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │ dropout_32[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_33[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_33[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_28[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_34[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,040</span> │ dropout_28[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,040</span> │ dropout_34[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_29[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_35[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ user_embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │ dropout_29[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ movie_embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │ dropout_35[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dot_product (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ user_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
       "│                               │                           │                 │ movie_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_input (\u001b[38;5;33mInputLayer\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ movie_input (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_24 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │           \u001b[38;5;34m2,688\u001b[0m │ user_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_30 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │           \u001b[38;5;34m3,072\u001b[0m │ movie_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_24 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ dense_24[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_30 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ dense_30[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_25 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │          \u001b[38;5;34m16,512\u001b[0m │ dropout_24[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_31 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │          \u001b[38;5;34m16,512\u001b[0m │ dropout_30[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_25 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ dense_25[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_31 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ dense_31[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_26 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │          \u001b[38;5;34m16,512\u001b[0m │ dropout_25[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_32 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │          \u001b[38;5;34m16,512\u001b[0m │ dropout_31[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_26 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ dense_26[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_32 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ dense_32[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_27 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │          \u001b[38;5;34m16,512\u001b[0m │ dropout_26[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_33 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │          \u001b[38;5;34m16,512\u001b[0m │ dropout_32[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_27 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ dense_27[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_33 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ dense_33[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_28 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m8,256\u001b[0m │ dropout_27[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_34 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m8,256\u001b[0m │ dropout_33[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_28 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_28[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_34 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_34[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_29 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                │           \u001b[38;5;34m1,040\u001b[0m │ dropout_28[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_35 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                │           \u001b[38;5;34m1,040\u001b[0m │ dropout_34[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_29 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_29[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_35 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_35[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ user_embedding (\u001b[38;5;33mDense\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                │             \u001b[38;5;34m272\u001b[0m │ dropout_29[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ movie_embedding (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                │             \u001b[38;5;34m272\u001b[0m │ dropout_35[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dot_product (\u001b[38;5;33mDot\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │ user_embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
       "│                               │                           │                 │ movie_embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">123,968</span> (484.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m123,968\u001b[0m (484.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">123,968</span> (484.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m123,968\u001b[0m (484.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_user_features = X_user_numpy.shape[1]   \n",
    "num_movie_features = X_movie_numpy.shape[1]\n",
    "drop = 0.2\n",
    "# ---------------- USER TOWER ----------------\n",
    "user_input = layers.Input(shape=(num_user_features,), name='user_input')\n",
    "x = layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001))(user_input)\n",
    "x = layers.Dropout(drop)(x)\n",
    "x = layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "x = layers.Dropout(drop)(x)\n",
    "x = layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "x = layers.Dropout(drop)(x)\n",
    "x = layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "x = layers.Dropout(drop)(x)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "x = layers.Dropout(drop)(x)\n",
    "x = layers.Dense(16, activation='relu')(x)\n",
    "x = layers.Dropout(drop)(x)\n",
    "\n",
    "user_embedding = layers.Dense(16, activation='linear', name='user_embedding')(x)\n",
    "\n",
    "# ---------------- MOVIE TOWER ----------------\n",
    "movie_input = layers.Input(shape=(num_movie_features,), name='movie_input')\n",
    "\n",
    "x2= layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01))(movie_input)\n",
    "x2 = layers.Dropout(drop)(x2)\n",
    "x2 = layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01))(x2)\n",
    "x2 = layers.Dropout(drop)(x2)\n",
    "x2 = layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01))(x2)\n",
    "x2 = layers.Dropout(drop)(x2)\n",
    "x2 = layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01))(x2)\n",
    "x2 = layers.Dropout(drop)(x2)\n",
    "x2 = layers.Dense(64, activation='relu')(x2)\n",
    "x2 = layers.Dropout(drop)(x2)\n",
    "x2 = layers.Dense(16, activation='relu')(x2)\n",
    "x2 = layers.Dropout(drop)(x2)\n",
    "\n",
    "movie_embedding = layers.Dense(16, activation='linear', name='movie_embedding')(x2)\n",
    "\n",
    "# ---------------- FINAL MODEL ----------------\n",
    "dot_product = layers.Dot(axes=1, name='dot_product')([user_embedding, movie_embedding])\n",
    "\n",
    "model4 = models.Model(inputs=[user_input, movie_input], outputs=dot_product)\n",
    "\n",
    "# Compile model\n",
    "model4.compile( loss='mse', metrics=['mae', 'mse'])\n",
    "\n",
    "# Pregled modela\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "316f7faa-fef3-4401-8aef-7ef3ff8b2600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m12223/12223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 5ms/step - loss: 0.3124 - mae: 0.3149 - mse: 0.1657 - val_loss: 0.1528 - val_mae: 0.2812 - val_mse: 0.1409 - learning_rate: 0.0010\n",
      "Epoch 2/30\n",
      "\u001b[1m12223/12223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 5ms/step - loss: 0.1675 - mae: 0.3041 - mse: 0.1556 - val_loss: 0.1518 - val_mae: 0.2863 - val_mse: 0.1403 - learning_rate: 0.0010\n",
      "Epoch 3/30\n",
      "\u001b[1m12223/12223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 5ms/step - loss: 0.1664 - mae: 0.3035 - mse: 0.1549 - val_loss: 0.1554 - val_mae: 0.2799 - val_mse: 0.1441 - learning_rate: 0.0010\n",
      "Epoch 4/30\n",
      "\u001b[1m12223/12223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 5ms/step - loss: 0.1666 - mae: 0.3035 - mse: 0.1552 - val_loss: 0.1633 - val_mae: 0.3094 - val_mse: 0.1524 - learning_rate: 0.0010\n",
      "Epoch 5/30\n",
      "\u001b[1m12222/12223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1663 - mae: 0.3033 - mse: 0.1550\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m12223/12223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 5ms/step - loss: 0.1663 - mae: 0.3033 - mse: 0.1550 - val_loss: 0.1584 - val_mae: 0.2829 - val_mse: 0.1469 - learning_rate: 0.0010\n",
      "Epoch 6/30\n",
      "\u001b[1m12223/12223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 5ms/step - loss: 0.1606 - mae: 0.2990 - mse: 0.1512 - val_loss: 0.1477 - val_mae: 0.2782 - val_mse: 0.1386 - learning_rate: 5.0000e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m12223/12223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 5ms/step - loss: 0.1600 - mae: 0.2988 - mse: 0.1511 - val_loss: 0.1471 - val_mae: 0.2836 - val_mse: 0.1384 - learning_rate: 5.0000e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m12223/12223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 5ms/step - loss: 0.1600 - mae: 0.2988 - mse: 0.1511 - val_loss: 0.1469 - val_mae: 0.2770 - val_mse: 0.1383 - learning_rate: 5.0000e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m12223/12223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 6ms/step - loss: 0.1599 - mae: 0.2987 - mse: 0.1510 - val_loss: 0.1571 - val_mae: 0.2843 - val_mse: 0.1482 - learning_rate: 5.0000e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m12223/12223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 6ms/step - loss: 0.1600 - mae: 0.2988 - mse: 0.1510 - val_loss: 0.1460 - val_mae: 0.2771 - val_mse: 0.1371 - learning_rate: 5.0000e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m12223/12223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 6ms/step - loss: 0.1594 - mae: 0.2982 - mse: 0.1505 - val_loss: 0.1452 - val_mae: 0.2769 - val_mse: 0.1363 - learning_rate: 5.0000e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m12223/12223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 6ms/step - loss: 0.1599 - mae: 0.2987 - mse: 0.1510 - val_loss: 0.1502 - val_mae: 0.2768 - val_mse: 0.1411 - learning_rate: 5.0000e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m12223/12223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 6ms/step - loss: 0.1596 - mae: 0.2985 - mse: 0.1507 - val_loss: 0.1453 - val_mae: 0.2785 - val_mse: 0.1366 - learning_rate: 5.0000e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m12223/12223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 6ms/step - loss: 0.1595 - mae: 0.2984 - mse: 0.1507 - val_loss: 0.1445 - val_mae: 0.2771 - val_mse: 0.1355 - learning_rate: 5.0000e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m12223/12223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 6ms/step - loss: 0.1592 - mae: 0.2981 - mse: 0.1504 - val_loss: 0.1484 - val_mae: 0.2787 - val_mse: 0.1394 - learning_rate: 5.0000e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m12223/12223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 6ms/step - loss: 0.1598 - mae: 0.2986 - mse: 0.1510 - val_loss: 0.1460 - val_mae: 0.2825 - val_mse: 0.1372 - learning_rate: 5.0000e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m 1344/12223\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:05\u001b[0m 6ms/step - loss: 0.1599 - mae: 0.2987 - mse: 0.1511"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_17032\\1963603183.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     14\u001b[39m     verbose=\u001b[32m1\u001b[39m\n\u001b[32m     15\u001b[39m )\n\u001b[32m     16\u001b[39m \n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# --- Treniraj model ---\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m history4 = model4.fit(\n\u001b[32m     19\u001b[39m     [X_user_numpy, X_movie_numpy],\n\u001b[32m     20\u001b[39m     y,\n\u001b[32m     21\u001b[39m     epochs=\u001b[32m30\u001b[39m,\n",
      "\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    120\u001b[39m             \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m             \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m    122\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m         \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m             \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    368\u001b[39m             \u001b[38;5;28;01mwith\u001b[39;00m epoch_iterator.catch_stop_iteration():\n\u001b[32m    369\u001b[39m                 \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;28;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    370\u001b[39m                     callbacks.on_train_batch_begin(step)\n\u001b[32m    371\u001b[39m                     logs = self.train_function(iterator)\n\u001b[32m--> \u001b[39m\u001b[32m372\u001b[39m                     callbacks.on_train_batch_end(step, logs)\n\u001b[32m    373\u001b[39m                     \u001b[38;5;28;01mif\u001b[39;00m self.stop_training:\n\u001b[32m    374\u001b[39m                         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    375\u001b[39m \n",
      "\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\keras\\src\\callbacks\\callback_list.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, batch, logs)\u001b[39m\n\u001b[32m    168\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m on_train_batch_end(self, batch, logs=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    169\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m self._async_train:\n\u001b[32m    170\u001b[39m             self._async_dispatch(self._on_train_batch_end, batch, logs)\n\u001b[32m    171\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m             self._on_train_batch_end(batch, logs)\n",
      "\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\keras\\src\\callbacks\\callback_list.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, batch, logs)\u001b[39m\n\u001b[32m    191\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m _on_train_batch_end(self, batch, logs=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    192\u001b[39m         logs = python_utils.pythonify_logs(logs)\n\u001b[32m    193\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;28;01min\u001b[39;00m self.callbacks:\n\u001b[32m--> \u001b[39m\u001b[32m194\u001b[39m             callback.on_train_batch_end(batch, logs=logs)\n",
      "\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\keras\\src\\callbacks\\progbar_logger.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, batch, logs)\u001b[39m\n\u001b[32m     57\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m on_train_batch_end(self, batch, logs=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m         self._update_progbar(batch, logs)\n",
      "\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\keras\\src\\callbacks\\progbar_logger.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, batch, logs)\u001b[39m\n\u001b[32m     91\u001b[39m         self._maybe_init_progbar()\n\u001b[32m     92\u001b[39m         self.seen = batch + \u001b[32m1\u001b[39m  \u001b[38;5;66;03m# One-indexed.\u001b[39;00m\n\u001b[32m     93\u001b[39m \n\u001b[32m     94\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m self.verbose == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m             self.progbar.update(self.seen, list(logs.items()), finalize=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\keras\\src\\utils\\progbar.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, current, values, finalize)\u001b[39m\n\u001b[32m    159\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;28;01min\u001b[39;00m self._values_order:\n\u001b[32m    160\u001b[39m                 info += \u001b[33mf\" - {k}:\"\u001b[39m\n\u001b[32m    161\u001b[39m                 \u001b[38;5;28;01mif\u001b[39;00m isinstance(self._values[k], list):\n\u001b[32m    162\u001b[39m                     avg = backend.convert_to_numpy(\n\u001b[32m--> \u001b[39m\u001b[32m163\u001b[39m                         backend.numpy.mean(\n\u001b[32m    164\u001b[39m                             self._values[k][\u001b[32m0\u001b[39m] / max(\u001b[32m1\u001b[39m, self._values[k][\u001b[32m1\u001b[39m])\n\u001b[32m    165\u001b[39m                         )\n\u001b[32m    166\u001b[39m                     )\n",
      "\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\numpy.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(x, axis, keepdims)\u001b[39m\n\u001b[32m    662\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"int\"\u001b[39m \u001b[38;5;28;01min\u001b[39;00m ori_dtype \u001b[38;5;28;01mor\u001b[39;00m ori_dtype == \u001b[33m\"bool\"\u001b[39m:\n\u001b[32m    663\u001b[39m         result_dtype = compute_dtype\n\u001b[32m    664\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    665\u001b[39m         result_dtype = ori_dtype\n\u001b[32m--> \u001b[39m\u001b[32m666\u001b[39m     output = tf.reduce_mean(\n\u001b[32m    667\u001b[39m         tf.cast(x, compute_dtype), axis=axis, keepdims=keepdims\n\u001b[32m    668\u001b[39m     )\n\u001b[32m    669\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m tf.cast(output, result_dtype)\n",
      "\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\tensorflow\\python\\ops\\weak_tensor_ops.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     86\u001b[39m   \u001b[38;5;28;01mdef\u001b[39;00m wrapper(*args, **kwargs):\n\u001b[32m     87\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m ops.is_auto_dtype_conversion_enabled():\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m       \u001b[38;5;28;01mreturn\u001b[39;00m op(*args, **kwargs)\n\u001b[32m     89\u001b[39m     bound_arguments = signature.bind(*args, **kwargs)\n\u001b[32m     90\u001b[39m     bound_arguments.apply_defaults()\n\u001b[32m     91\u001b[39m     bound_kwargs = bound_arguments.arguments\n",
      "\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    151\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m Exception \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m       filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    153\u001b[39m       \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    154\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m       \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1257\u001b[39m \n\u001b[32m   1258\u001b[39m       \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[32m   1259\u001b[39m       \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1260\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m dispatch_target(*args, **kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m1261\u001b[39m       \u001b[38;5;28;01mexcept\u001b[39;00m (TypeError, ValueError):\n\u001b[32m   1262\u001b[39m         \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[32m   1263\u001b[39m         \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[32m   1264\u001b[39m         result = dispatch(op_dispatch_handler, args, kwargs)\n",
      "\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(input_tensor, axis, keepdims, name)\u001b[39m\n\u001b[32m   2590\u001b[39m   keepdims = \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m keepdims \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m bool(keepdims)\n\u001b[32m   2591\u001b[39m   return _may_reduce_to_scalar(\n\u001b[32m   2592\u001b[39m       keepdims, axis,\n\u001b[32m   2593\u001b[39m       gen_math_ops.mean(\n\u001b[32m-> \u001b[39m\u001b[32m2594\u001b[39m           input_tensor, _ReductionDims(input_tensor, axis), keepdims,\n\u001b[32m   2595\u001b[39m           name=name))\n",
      "\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(x, axis)\u001b[39m\n\u001b[32m   2094\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m x_rank:\n\u001b[32m   2095\u001b[39m       \u001b[38;5;28;01mreturn\u001b[39;00m constant_op.constant(np.arange(x_rank, dtype=np.int32))\n\u001b[32m   2096\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2097\u001b[39m       \u001b[38;5;66;03m# Otherwise, we rely on Range and Rank to do the right thing at run-time.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2098\u001b[39m       \u001b[38;5;28;01mreturn\u001b[39;00m range(\u001b[32m0\u001b[39m, array_ops.rank(x))\n",
      "\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    151\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m Exception \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m       filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    153\u001b[39m       \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    154\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m       \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1257\u001b[39m \n\u001b[32m   1258\u001b[39m       \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[32m   1259\u001b[39m       \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1260\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m dispatch_target(*args, **kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m1261\u001b[39m       \u001b[38;5;28;01mexcept\u001b[39;00m (TypeError, ValueError):\n\u001b[32m   1262\u001b[39m         \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[32m   1263\u001b[39m         \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[32m   1264\u001b[39m         result = dispatch(op_dispatch_handler, args, kwargs)\n",
      "\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(start, limit, delta, dtype, name)\u001b[39m\n\u001b[32m   2065\u001b[39m     start = cast(start, inferred_dtype)\n\u001b[32m   2066\u001b[39m     limit = cast(limit, inferred_dtype)\n\u001b[32m   2067\u001b[39m     delta = cast(delta, inferred_dtype)\n\u001b[32m   2068\u001b[39m \n\u001b[32m-> \u001b[39m\u001b[32m2069\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m gen_math_ops._range(start, limit, delta, name=name)\n",
      "\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(start, limit, delta, name)\u001b[39m\n\u001b[32m   8020\u001b[39m         _ctx, \"Range\", name, start, limit, delta)\n\u001b[32m   8021\u001b[39m       \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[32m   8022\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m _core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   8023\u001b[39m       _ops.raise_from_not_ok_status(e, name)\n\u001b[32m-> \u001b[39m\u001b[32m8024\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m _core._FallbackException:\n\u001b[32m   8025\u001b[39m       \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m   8026\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   8027\u001b[39m       return _range_eager_fallback(\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# --- EarlyStopping ---\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# --- ReduceLROnPlateau ---\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# --- Treniraj model ---\n",
    "history4 = model4.fit(\n",
    "    [X_user_numpy, X_movie_numpy],\n",
    "    y,\n",
    "    epochs=30,\n",
    "    batch_size=128,\n",
    "    validation_split=0.15,\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "b2888531-2488-4cf3-a27b-8bfee8717bf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ movie_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,688</span> │ user_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_42 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,072</span> │ movie_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_36[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_42 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_42[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │ dropout_36[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_43 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │ dropout_42[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_37[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_43 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_43[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_37[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_44 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_43[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_38[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_44 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_44[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ dropout_38[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_45 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ dropout_44[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_39[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_45 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_45[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dropout_39[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_46 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dropout_45[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_40[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_46 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_46[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │ dropout_40[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_47 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │ dropout_46[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_41[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_47 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_47[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ user_embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │ dropout_41[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ movie_embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │ dropout_47[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dot_product (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ user_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
       "│                               │                           │                 │ movie_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_input (\u001b[38;5;33mInputLayer\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ movie_input (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_36 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │           \u001b[38;5;34m2,688\u001b[0m │ user_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_42 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │           \u001b[38;5;34m3,072\u001b[0m │ movie_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_36 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ dense_36[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_42 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ dense_42[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_37 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │          \u001b[38;5;34m16,512\u001b[0m │ dropout_36[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_43 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │          \u001b[38;5;34m16,512\u001b[0m │ dropout_42[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_37 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ dense_37[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_43 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ dense_43[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_38 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m8,256\u001b[0m │ dropout_37[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_44 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m8,256\u001b[0m │ dropout_43[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_38 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_38[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_44 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_44[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_39 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m4,160\u001b[0m │ dropout_38[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_45 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m4,160\u001b[0m │ dropout_44[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_39 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_39[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_45 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_45[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_40 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │           \u001b[38;5;34m2,080\u001b[0m │ dropout_39[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_46 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │           \u001b[38;5;34m2,080\u001b[0m │ dropout_45[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_40 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_40[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_46 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_46[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_41 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                │             \u001b[38;5;34m528\u001b[0m │ dropout_40[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_47 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                │             \u001b[38;5;34m528\u001b[0m │ dropout_46[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_41 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_41[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_47 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_47[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ user_embedding (\u001b[38;5;33mDense\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                │             \u001b[38;5;34m272\u001b[0m │ dropout_41[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ movie_embedding (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                │             \u001b[38;5;34m272\u001b[0m │ dropout_47[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dot_product (\u001b[38;5;33mDot\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │ user_embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
       "│                               │                           │                 │ movie_embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">69,376</span> (271.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m69,376\u001b[0m (271.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">69,376</span> (271.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m69,376\u001b[0m (271.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_user_features = X_user_numpy.shape[1]   \n",
    "num_movie_features = X_movie_numpy.shape[1]\n",
    "drop = 0.15\n",
    "# ---------------- USER TOWER ----------------\n",
    "user_input = layers.Input(shape=(num_user_features,), name='user_input')\n",
    "x = layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001))(user_input)\n",
    "x = layers.Dropout(drop)(x)\n",
    "x = layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "x = layers.Dropout(drop)(x)\n",
    "x = layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "x = layers.Dropout(drop)(x)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "x = layers.Dropout(drop)(x)\n",
    "x = layers.Dense(32, activation='relu')(x)\n",
    "x = layers.Dropout(drop)(x)\n",
    "x = layers.Dense(16, activation='relu')(x)\n",
    "x = layers.Dropout(drop)(x)\n",
    "\n",
    "user_embedding = layers.Dense(16, activation='linear', name='user_embedding')(x)\n",
    "\n",
    "# ---------------- MOVIE TOWER ----------------\n",
    "movie_input = layers.Input(shape=(num_movie_features,), name='movie_input')\n",
    "\n",
    "x2= layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01))(movie_input)\n",
    "x2 = layers.Dropout(drop)(x2)\n",
    "x2 = layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01))(x2)\n",
    "x2 = layers.Dropout(drop)(x2)\n",
    "x2 = layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.01))(x2)\n",
    "x2 = layers.Dropout(drop)(x2)\n",
    "x2 = layers.Dense(64, activation='relu')(x2)\n",
    "x2 = layers.Dropout(drop)(x2)\n",
    "x2 = layers.Dense(32, activation='relu')(x2)\n",
    "x2 = layers.Dropout(drop)(x2)\n",
    "x2 = layers.Dense(16, activation='relu')(x2)\n",
    "x2 = layers.Dropout(drop)(x2)\n",
    "\n",
    "movie_embedding = layers.Dense(16, activation='linear', name='movie_embedding')(x2)\n",
    "\n",
    "# ---------------- FINAL MODEL ----------------\n",
    "dot_product = layers.Dot(axes=1, name='dot_product')([user_embedding, movie_embedding])\n",
    "\n",
    "model4 = models.Model(inputs=[user_input, movie_input], outputs=dot_product)\n",
    "\n",
    "# Compile model\n",
    "model4.compile( loss='mse', metrics=['mae', 'mse'])\n",
    "\n",
    "# Pregled modela\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "70a877b5-5081-42ac-84f6-ca264b4ba749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m12223/12223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 5ms/step - loss: 0.2537 - mae: 0.3085 - mse: 0.1599 - val_loss: 0.1461 - val_mae: 0.2794 - val_mse: 0.1379 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m12223/12223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 5ms/step - loss: 0.1589 - mae: 0.2984 - mse: 0.1508 - val_loss: 0.1454 - val_mae: 0.2784 - val_mse: 0.1374 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m12223/12223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 5ms/step - loss: 0.1581 - mae: 0.2981 - mse: 0.1503 - val_loss: 0.1481 - val_mae: 0.2884 - val_mse: 0.1405 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m12223/12223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 5ms/step - loss: 0.1574 - mae: 0.2973 - mse: 0.1497 - val_loss: 0.1578 - val_mae: 0.3043 - val_mse: 0.1504 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m12223/12223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1580 - mae: 0.2979 - mse: 0.1504\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m12223/12223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 5ms/step - loss: 0.1580 - mae: 0.2979 - mse: 0.1504 - val_loss: 0.1573 - val_mae: 0.2843 - val_mse: 0.1492 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m 1072/12223\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:00\u001b[0m 5ms/step - loss: 0.1527 - mae: 0.2923 - mse: 0.1455"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[128]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     10\u001b[39m reduce_lr = ReduceLROnPlateau(\n\u001b[32m     11\u001b[39m     monitor=\u001b[33m'\u001b[39m\u001b[33mval_loss\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     12\u001b[39m     factor=\u001b[32m0.5\u001b[39m,\n\u001b[32m     13\u001b[39m     patience=\u001b[32m3\u001b[39m,\n\u001b[32m     14\u001b[39m     verbose=\u001b[32m1\u001b[39m\n\u001b[32m     15\u001b[39m )\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# --- Treniraj model ---\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m history4 = \u001b[43mmodel4\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_user_numpy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_movie_numpy\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m128\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.15\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:371\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    370\u001b[39m     callbacks.on_train_batch_begin(step)\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    372\u001b[39m     callbacks.on_train_batch_end(step, logs)\n\u001b[32m    373\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:219\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    217\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    218\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    220\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    221\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m    138\u001b[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bound_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1688\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1686\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1687\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1688\u001b[39m   outputs = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1689\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1690\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1691\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1696\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1697\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1698\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1702\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1703\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# --- EarlyStopping ---\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# --- ReduceLROnPlateau ---\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# --- Treniraj model ---\n",
    "history4 = model4.fit(\n",
    "    [X_user_numpy, X_movie_numpy],\n",
    "    y,\n",
    "    epochs=20,\n",
    "    batch_size=128,\n",
    "    validation_split=0.15,\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7266c93e-cc12-4028-ae1b-ce154700c82e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "4114e4e9-b963-43c2-90f2-8b0fd044cb76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ movie_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,688</span> │ user_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_54 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,072</span> │ movie_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_48[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_54 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_54[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │ dropout_48[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_55 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │ dropout_54[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_49[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_55 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_55[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │ dropout_49[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_56 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │ dropout_55[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_50[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_56 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_56[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_51 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │ dropout_50[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_57 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │ dropout_56[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_51 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_51[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_57 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_57[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_52 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_51[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_58 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_57[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_52 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_52[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_58 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_58[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_53 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,040</span> │ dropout_52[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_59 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,040</span> │ dropout_58[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_53 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_53[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_59 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_59[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ user_embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │ dropout_53[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ movie_embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │ dropout_59[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dot_product (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ user_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
       "│                               │                           │                 │ movie_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_input (\u001b[38;5;33mInputLayer\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ movie_input (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_48 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │           \u001b[38;5;34m2,688\u001b[0m │ user_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_54 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │           \u001b[38;5;34m3,072\u001b[0m │ movie_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_48 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ dense_48[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_54 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ dense_54[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_49 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │          \u001b[38;5;34m16,512\u001b[0m │ dropout_48[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_55 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │          \u001b[38;5;34m16,512\u001b[0m │ dropout_54[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_49 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ dense_49[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_55 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ dense_55[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_50 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │          \u001b[38;5;34m16,512\u001b[0m │ dropout_49[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_56 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │          \u001b[38;5;34m16,512\u001b[0m │ dropout_55[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_50 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ dense_50[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_56 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ dense_56[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_51 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │          \u001b[38;5;34m16,512\u001b[0m │ dropout_50[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_57 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │          \u001b[38;5;34m16,512\u001b[0m │ dropout_56[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_51 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ dense_51[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_57 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ dense_57[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_52 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m8,256\u001b[0m │ dropout_51[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_58 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m8,256\u001b[0m │ dropout_57[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_52 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_52[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_58 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_58[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_53 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                │           \u001b[38;5;34m1,040\u001b[0m │ dropout_52[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_59 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                │           \u001b[38;5;34m1,040\u001b[0m │ dropout_58[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_53 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_53[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_59 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_59[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ user_embedding (\u001b[38;5;33mDense\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                │             \u001b[38;5;34m272\u001b[0m │ dropout_53[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ movie_embedding (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                │             \u001b[38;5;34m272\u001b[0m │ dropout_59[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dot_product (\u001b[38;5;33mDot\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │ user_embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
       "│                               │                           │                 │ movie_embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">123,968</span> (484.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m123,968\u001b[0m (484.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">123,968</span> (484.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m123,968\u001b[0m (484.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_user_features = X_user_numpy.shape[1]   \n",
    "num_movie_features = X_movie_numpy.shape[1]\n",
    "drop = 0.2\n",
    "# ---------------- USER TOWER ----------------\n",
    "user_input = layers.Input(shape=(num_user_features,), name='user_input')\n",
    "x = layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001))(user_input)\n",
    "x = layers.Dropout(drop)(x)\n",
    "x = layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "x = layers.Dropout(drop)(x)\n",
    "x = layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "x = layers.Dropout(drop)(x)\n",
    "x = layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "x = layers.Dropout(drop)(x)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "x = layers.Dropout(drop)(x)\n",
    "x = layers.Dense(16, activation='relu')(x)\n",
    "x = layers.Dropout(drop)(x)\n",
    "\n",
    "user_embedding = layers.Dense(16, activation='linear', name='user_embedding')(x)\n",
    "\n",
    "# ---------------- MOVIE TOWER ----------------\n",
    "movie_input = layers.Input(shape=(num_movie_features,), name='movie_input')\n",
    "\n",
    "x2= layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001))(movie_input)\n",
    "x2 = layers.Dropout(drop)(x2)\n",
    "x2 = layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001))(x2)\n",
    "x2 = layers.Dropout(drop)(x2)\n",
    "x2 = layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001))(x2)\n",
    "x2 = layers.Dropout(drop)(x2)\n",
    "x2 = layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001))(x2)\n",
    "x2 = layers.Dropout(drop)(x2)\n",
    "x2 = layers.Dense(64, activation='relu')(x2)\n",
    "x2 = layers.Dropout(drop)(x2)\n",
    "x2 = layers.Dense(16, activation='relu')(x2)\n",
    "x2 = layers.Dropout(drop)(x2)\n",
    "\n",
    "movie_embedding = layers.Dense(16, activation='linear', name='movie_embedding')(x2)\n",
    "\n",
    "# ---------------- FINAL MODEL ----------------\n",
    "dot_product = layers.Dot(axes=1, name='dot_product')([user_embedding, movie_embedding])\n",
    "\n",
    "model4 = models.Model(inputs=[user_input, movie_input], outputs=dot_product)\n",
    "\n",
    "# Compile model\n",
    "model4.compile( loss='mse', metrics=['mae', 'mse'])\n",
    "\n",
    "# Pregled modela\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "6d6ec948-49a0-4db4-9e05-e3ebc36fbb5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m12223/12223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 6ms/step - loss: 0.2291 - mae: 0.3100 - mse: 0.1611 - val_loss: 0.1473 - val_mae: 0.2756 - val_mse: 0.1396 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m12223/12223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 6ms/step - loss: 0.1564 - mae: 0.2967 - mse: 0.1489 - val_loss: 0.1505 - val_mae: 0.2796 - val_mse: 0.1431 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m12223/12223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 6ms/step - loss: 0.1556 - mae: 0.2957 - mse: 0.1482 - val_loss: 0.1459 - val_mae: 0.2846 - val_mse: 0.1388 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m12223/12223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 6ms/step - loss: 0.1553 - mae: 0.2957 - mse: 0.1482 - val_loss: 0.1459 - val_mae: 0.2756 - val_mse: 0.1385 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m12223/12223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 6ms/step - loss: 0.1551 - mae: 0.2955 - mse: 0.1479 - val_loss: 0.1498 - val_mae: 0.2774 - val_mse: 0.1424 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m12223/12223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 6ms/step - loss: 0.1547 - mae: 0.2951 - mse: 0.1475 - val_loss: 0.1444 - val_mae: 0.2786 - val_mse: 0.1374 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m12223/12223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 6ms/step - loss: 0.1541 - mae: 0.2947 - mse: 0.1471 - val_loss: 0.1569 - val_mae: 0.3072 - val_mse: 0.1500 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m12223/12223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 9ms/step - loss: 0.1544 - mae: 0.2949 - mse: 0.1474 - val_loss: 0.1452 - val_mae: 0.2789 - val_mse: 0.1384 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m12222/12223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1542 - mae: 0.2947 - mse: 0.1473\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m12223/12223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 9ms/step - loss: 0.1542 - mae: 0.2947 - mse: 0.1473 - val_loss: 0.1458 - val_mae: 0.2777 - val_mse: 0.1388 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\u001b[1m12223/12223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 8ms/step - loss: 0.1506 - mae: 0.2913 - mse: 0.1445 - val_loss: 0.1426 - val_mae: 0.2794 - val_mse: 0.1369 - learning_rate: 5.0000e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m12223/12223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 6ms/step - loss: 0.1500 - mae: 0.2913 - mse: 0.1445 - val_loss: 0.1423 - val_mae: 0.2745 - val_mse: 0.1368 - learning_rate: 5.0000e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m12223/12223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 6ms/step - loss: 0.1503 - mae: 0.2916 - mse: 0.1448 - val_loss: 0.1451 - val_mae: 0.2749 - val_mse: 0.1395 - learning_rate: 5.0000e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m12223/12223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 5ms/step - loss: 0.1497 - mae: 0.2911 - mse: 0.1442 - val_loss: 0.1438 - val_mae: 0.2826 - val_mse: 0.1383 - learning_rate: 5.0000e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m 1098/12223\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m52s\u001b[0m 5ms/step - loss: 0.1490 - mae: 0.2902 - mse: 0.1435"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[132]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     10\u001b[39m reduce_lr = ReduceLROnPlateau(\n\u001b[32m     11\u001b[39m     monitor=\u001b[33m'\u001b[39m\u001b[33mval_loss\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     12\u001b[39m     factor=\u001b[32m0.5\u001b[39m,\n\u001b[32m     13\u001b[39m     patience=\u001b[32m3\u001b[39m,\n\u001b[32m     14\u001b[39m     verbose=\u001b[32m1\u001b[39m\n\u001b[32m     15\u001b[39m )\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# --- Treniraj model ---\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m history4 = \u001b[43mmodel4\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_user_numpy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_movie_numpy\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m128\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.15\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:371\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    370\u001b[39m     callbacks.on_train_batch_begin(step)\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    372\u001b[39m     callbacks.on_train_batch_end(step, logs)\n\u001b[32m    373\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:219\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    217\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    218\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    220\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    221\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m    138\u001b[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bound_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1688\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1686\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1687\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1688\u001b[39m   outputs = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1689\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1690\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1691\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1696\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1697\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1698\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1702\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1703\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Freestyle\\GitHub\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# --- EarlyStopping ---\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# --- ReduceLROnPlateau ---\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# --- Treniraj model ---\n",
    "history4 = model4.fit(\n",
    "    [X_user_numpy, X_movie_numpy],\n",
    "    y,\n",
    "    epochs=20,\n",
    "    batch_size=128,\n",
    "    validation_split=0.15,\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03528abd-7757-4180-b581-d6b6ed912211",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "540cd070-e0f2-4419-b4f6-f737ebcc92b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ movie_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_60 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">5,376</span> │ user_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_66 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">6,144</span> │ movie_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_60 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_60[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_66 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_66[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_61 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ dropout_60[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_67 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ dropout_66[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_61 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_61[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_67 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_67[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_62 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │ dropout_61[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_68 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │ dropout_67[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_62 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_62[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_68 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_68[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_63 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_62[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_69 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_68[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_63 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_63[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_69 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_69[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_64 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ dropout_63[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_70 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ dropout_69[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_64 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_64[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_70 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_70[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_65 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,040</span> │ dropout_64[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_71 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,040</span> │ dropout_70[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_65 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_65[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_71 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_71[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ user_embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │ dropout_65[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ movie_embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │ dropout_71[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dot_product (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ user_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
       "│                               │                           │                 │ movie_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_input (\u001b[38;5;33mInputLayer\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ movie_input (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_60 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)               │           \u001b[38;5;34m5,376\u001b[0m │ user_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_66 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)               │           \u001b[38;5;34m6,144\u001b[0m │ movie_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_60 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ dense_60[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_66 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ dense_66[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_61 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │          \u001b[38;5;34m32,896\u001b[0m │ dropout_60[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_67 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │          \u001b[38;5;34m32,896\u001b[0m │ dropout_66[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_61 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ dense_61[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_67 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ dense_67[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_62 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │          \u001b[38;5;34m16,512\u001b[0m │ dropout_61[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_68 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │          \u001b[38;5;34m16,512\u001b[0m │ dropout_67[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_62 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ dense_62[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_68 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ dense_68[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_63 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m8,256\u001b[0m │ dropout_62[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_69 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m8,256\u001b[0m │ dropout_68[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_63 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_63[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_69 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_69[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_64 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m4,160\u001b[0m │ dropout_63[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_70 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m4,160\u001b[0m │ dropout_69[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_64 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_64[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_70 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_70[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_65 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                │           \u001b[38;5;34m1,040\u001b[0m │ dropout_64[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_71 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                │           \u001b[38;5;34m1,040\u001b[0m │ dropout_70[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_65 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_65[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_71 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_71[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ user_embedding (\u001b[38;5;33mDense\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                │             \u001b[38;5;34m272\u001b[0m │ dropout_65[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ movie_embedding (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                │             \u001b[38;5;34m272\u001b[0m │ dropout_71[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dot_product (\u001b[38;5;33mDot\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │ user_embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
       "│                               │                           │                 │ movie_embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">137,792</span> (538.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m137,792\u001b[0m (538.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">137,792</span> (538.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m137,792\u001b[0m (538.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_user_features = X_user_numpy.shape[1]   \n",
    "num_movie_features = X_movie_numpy.shape[1]\n",
    "drop = 0.2\n",
    "# ---------------- USER TOWER ----------------\n",
    "user_input = layers.Input(shape=(num_user_features,), name='user_input')\n",
    "x = layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.001))(user_input)\n",
    "x = layers.Dropout(drop)(x)\n",
    "x = layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "x = layers.Dropout(drop)(x)\n",
    "x = layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "x = layers.Dropout(drop)(x)\n",
    "x = layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "x = layers.Dropout(drop)(x)\n",
    "x = layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.0001))(x)\n",
    "x = layers.Dropout(drop)(x)\n",
    "x = layers.Dense(16, activation='relu')(x)\n",
    "x = layers.Dropout(drop)(x)\n",
    "\n",
    "user_embedding = layers.Dense(16, activation='linear', name='user_embedding')(x)\n",
    "\n",
    "# ---------------- MOVIE TOWER ----------------\n",
    "movie_input = layers.Input(shape=(num_movie_features,), name='movie_input')\n",
    "\n",
    "x2= layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.001))(movie_input)\n",
    "x2 = layers.Dropout(drop)(x2)\n",
    "x2 = layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001))(x2)\n",
    "x2 = layers.Dropout(drop)(x2)\n",
    "x2 = layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001))(x2)\n",
    "x2 = layers.Dropout(drop)(x2)\n",
    "x2 = layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.001))(x2)\n",
    "x2 = layers.Dropout(drop)(x2)\n",
    "x2 = layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.0001))(x2)\n",
    "x2 = layers.Dropout(drop)(x2)\n",
    "x2 = layers.Dense(16, activation='relu')(x2)\n",
    "x2 = layers.Dropout(drop)(x2)\n",
    "\n",
    "movie_embedding = layers.Dense(16, activation='linear', name='movie_embedding')(x2)\n",
    "\n",
    "# ---------------- FINAL MODEL ----------------\n",
    "dot_product = layers.Dot(axes=1, name='dot_product')([user_embedding, movie_embedding])\n",
    "\n",
    "model4 = models.Model(inputs=[user_input, movie_input], outputs=dot_product)\n",
    "\n",
    "# Compile model\n",
    "model4.compile( loss='mse', metrics=['mae', 'mse'])\n",
    "\n",
    "# Pregled modela\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac880995-1262-4aa8-a3a8-21e74034d1fd",
   "metadata": {},
   "source": [
    "# # --- EarlyStopping ---\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# --- ReduceLROnPlateau ---\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# --- Treniraj model ---\n",
    "history4 = model4.fit(\n",
    "    [X_user_numpy, X_movie_numpy],\n",
    "    y,\n",
    "    epochs=20,\n",
    "    batch_size=128,\n",
    "    validation_split=0.15,\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "f8c39df8-24db-4942-aa3f-9768d167c425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m12223/12223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 5ms/step - loss: 0.1483 - mae: 0.2898 - mse: 0.1433 - val_loss: 0.1417 - val_mae: 0.2840 - val_mse: 0.1367 - learning_rate: 2.5000e-04\n",
      "Epoch 2/20\n",
      "\u001b[1m12223/12223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 6ms/step - loss: 0.1486 - mae: 0.2899 - mse: 0.1436 - val_loss: 0.1388 - val_mae: 0.2768 - val_mse: 0.1338 - learning_rate: 2.5000e-04\n",
      "Epoch 3/20\n",
      "\u001b[1m12223/12223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 5ms/step - loss: 0.1484 - mae: 0.2898 - mse: 0.1434 - val_loss: 0.1424 - val_mae: 0.2842 - val_mse: 0.1374 - learning_rate: 2.5000e-04\n",
      "Epoch 4/20\n",
      "\u001b[1m12223/12223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 5ms/step - loss: 0.1486 - mae: 0.2900 - mse: 0.1435 - val_loss: 0.1395 - val_mae: 0.2728 - val_mse: 0.1346 - learning_rate: 2.5000e-04\n",
      "Epoch 5/20\n",
      "\u001b[1m12218/12223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1487 - mae: 0.2901 - mse: 0.1437\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m12223/12223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 6ms/step - loss: 0.1487 - mae: 0.2901 - mse: 0.1437 - val_loss: 0.1388 - val_mae: 0.2776 - val_mse: 0.1338 - learning_rate: 2.5000e-04\n",
      "Epoch 6/20\n",
      "\u001b[1m12223/12223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 5ms/step - loss: 0.1472 - mae: 0.2885 - mse: 0.1424 - val_loss: 0.1383 - val_mae: 0.2753 - val_mse: 0.1336 - learning_rate: 1.2500e-04\n",
      "Epoch 7/20\n",
      "\u001b[1m12223/12223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 5ms/step - loss: 0.1467 - mae: 0.2880 - mse: 0.1421 - val_loss: 0.1382 - val_mae: 0.2741 - val_mse: 0.1336 - learning_rate: 1.2500e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m12223/12223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1006s\u001b[0m 82ms/step - loss: 0.1466 - mae: 0.2882 - mse: 0.1421 - val_loss: 0.1383 - val_mae: 0.2719 - val_mse: 0.1338 - learning_rate: 1.2500e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m12223/12223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 5ms/step - loss: 0.1471 - mae: 0.2887 - mse: 0.1426 - val_loss: 0.1370 - val_mae: 0.2708 - val_mse: 0.1325 - learning_rate: 1.2500e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m12223/12223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 5ms/step - loss: 0.1466 - mae: 0.2883 - mse: 0.1422 - val_loss: 0.1375 - val_mae: 0.2738 - val_mse: 0.1332 - learning_rate: 1.2500e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m12223/12223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 5ms/step - loss: 0.1467 - mae: 0.2885 - mse: 0.1423 - val_loss: 0.1385 - val_mae: 0.2711 - val_mse: 0.1342 - learning_rate: 1.2500e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m12214/12223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1466 - mae: 0.2884 - mse: 0.1423\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m12223/12223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 5ms/step - loss: 0.1466 - mae: 0.2884 - mse: 0.1423 - val_loss: 0.1375 - val_mae: 0.2724 - val_mse: 0.1332 - learning_rate: 1.2500e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m12223/12223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 5ms/step - loss: 0.1460 - mae: 0.2879 - mse: 0.1418 - val_loss: 0.1382 - val_mae: 0.2723 - val_mse: 0.1341 - learning_rate: 6.2500e-05\n",
      "Epoch 14/20\n",
      "\u001b[1m12223/12223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 5ms/step - loss: 0.1456 - mae: 0.2874 - mse: 0.1415 - val_loss: 0.1365 - val_mae: 0.2729 - val_mse: 0.1324 - learning_rate: 6.2500e-05\n",
      "Epoch 15/20\n",
      "\u001b[1m12223/12223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 5ms/step - loss: 0.1456 - mae: 0.2872 - mse: 0.1415 - val_loss: 0.1367 - val_mae: 0.2752 - val_mse: 0.1327 - learning_rate: 6.2500e-05\n",
      "Epoch 16/20\n",
      "\u001b[1m12223/12223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 5ms/step - loss: 0.1456 - mae: 0.2875 - mse: 0.1416 - val_loss: 0.1361 - val_mae: 0.2723 - val_mse: 0.1322 - learning_rate: 6.2500e-05\n",
      "Epoch 17/20\n",
      "\u001b[1m12223/12223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 5ms/step - loss: 0.1454 - mae: 0.2874 - mse: 0.1414 - val_loss: 0.1364 - val_mae: 0.2743 - val_mse: 0.1324 - learning_rate: 6.2500e-05\n",
      "Epoch 18/20\n",
      "\u001b[1m12223/12223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 5ms/step - loss: 0.1451 - mae: 0.2871 - mse: 0.1411 - val_loss: 0.1363 - val_mae: 0.2737 - val_mse: 0.1323 - learning_rate: 6.2500e-05\n",
      "Epoch 19/20\n",
      "\u001b[1m12216/12223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1458 - mae: 0.2879 - mse: 0.1419\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m12223/12223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 5ms/step - loss: 0.1458 - mae: 0.2879 - mse: 0.1419 - val_loss: 0.1375 - val_mae: 0.2721 - val_mse: 0.1336 - learning_rate: 6.2500e-05\n",
      "Epoch 20/20\n",
      "\u001b[1m12223/12223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 5ms/step - loss: 0.1450 - mae: 0.2870 - mse: 0.1411 - val_loss: 0.1359 - val_mae: 0.2713 - val_mse: 0.1321 - learning_rate: 3.1250e-05\n",
      "Restoring model weights from the end of the best epoch: 20.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- EarlyStopping ---\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# --- ReduceLROnPlateau ---\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# --- Treniraj model ---\n",
    "history4 = model4.fit(\n",
    "    [X_user_numpy, X_movie_numpy],\n",
    "    y,\n",
    "    epochs=20,\n",
    "    batch_size=128,\n",
    "    validation_split=0.15,\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "779f991e-0191-43b6-aab4-5036149e8a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m12223/12223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 5ms/step - loss: 0.1445 - mae: 0.2864 - mse: 0.1407 - val_loss: 0.1360 - val_mae: 0.2739 - val_mse: 0.1322 - learning_rate: 3.1250e-05\n",
      "Epoch 2/20\n",
      "\u001b[1m12223/12223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 5ms/step - loss: 0.1449 - mae: 0.2869 - mse: 0.1411 - val_loss: 0.1364 - val_mae: 0.2749 - val_mse: 0.1326 - learning_rate: 3.1250e-05\n",
      "Epoch 3/20\n",
      "\u001b[1m12223/12223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 5ms/step - loss: 0.1445 - mae: 0.2867 - mse: 0.1408 - val_loss: 0.1365 - val_mae: 0.2753 - val_mse: 0.1327 - learning_rate: 3.1250e-05\n",
      "Epoch 4/20\n",
      "\u001b[1m12223/12223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 6ms/step - loss: 0.1450 - mae: 0.2872 - mse: 0.1413 - val_loss: 0.1356 - val_mae: 0.2735 - val_mse: 0.1319 - learning_rate: 3.1250e-05\n",
      "Epoch 5/20\n",
      "\u001b[1m12223/12223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 6ms/step - loss: 0.1447 - mae: 0.2869 - mse: 0.1410 - val_loss: 0.1354 - val_mae: 0.2722 - val_mse: 0.1317 - learning_rate: 3.1250e-05\n",
      "Epoch 6/20\n",
      "\u001b[1m12223/12223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 6ms/step - loss: 0.1446 - mae: 0.2867 - mse: 0.1409 - val_loss: 0.1361 - val_mae: 0.2720 - val_mse: 0.1325 - learning_rate: 3.1250e-05\n",
      "Epoch 7/20\n",
      "\u001b[1m12223/12223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 7ms/step - loss: 0.1451 - mae: 0.2873 - mse: 0.1415 - val_loss: 0.1359 - val_mae: 0.2726 - val_mse: 0.1323 - learning_rate: 3.1250e-05\n",
      "Epoch 8/20\n",
      "\u001b[1m12222/12223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1449 - mae: 0.2873 - mse: 0.1412\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\u001b[1m12223/12223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 6ms/step - loss: 0.1449 - mae: 0.2873 - mse: 0.1412 - val_loss: 0.1357 - val_mae: 0.2724 - val_mse: 0.1321 - learning_rate: 3.1250e-05\n",
      "Epoch 9/20\n",
      "\u001b[1m12223/12223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 6ms/step - loss: 0.1442 - mae: 0.2863 - mse: 0.1405 - val_loss: 0.1357 - val_mae: 0.2728 - val_mse: 0.1321 - learning_rate: 1.5625e-05\n",
      "Epoch 10/20\n",
      "\u001b[1m12223/12223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 6ms/step - loss: 0.1445 - mae: 0.2867 - mse: 0.1410 - val_loss: 0.1360 - val_mae: 0.2735 - val_mse: 0.1324 - learning_rate: 1.5625e-05\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- EarlyStopping ---\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# --- ReduceLROnPlateau ---\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# --- Treniraj model ---\n",
    "history4 = model4.fit(\n",
    "    [X_user_numpy, X_movie_numpy],\n",
    "    y,\n",
    "    epochs=20,\n",
    "    batch_size=128,\n",
    "    validation_split=0.15,\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "b36c56e3-c039-4805-9c7e-f43132f915e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m48891/48891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 5ms/step - loss: 0.1450 - mae: 0.2869 - mse: 0.1413 - val_loss: 0.1360 - val_mae: 0.2716 - val_mse: 0.1323 - learning_rate: 1.5625e-05\n",
      "Epoch 2/20\n",
      "\u001b[1m48891/48891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 4ms/step - loss: 0.1449 - mae: 0.2869 - mse: 0.1412 - val_loss: 0.1360 - val_mae: 0.2733 - val_mse: 0.1323 - learning_rate: 1.5625e-05\n",
      "Epoch 3/20\n",
      "\u001b[1m48891/48891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 4ms/step - loss: 0.1450 - mae: 0.2870 - mse: 0.1413 - val_loss: 0.1366 - val_mae: 0.2750 - val_mse: 0.1329 - learning_rate: 1.5625e-05\n",
      "Epoch 4/20\n",
      "\u001b[1m48891/48891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 4ms/step - loss: 0.1448 - mae: 0.2869 - mse: 0.1411 - val_loss: 0.1359 - val_mae: 0.2726 - val_mse: 0.1321 - learning_rate: 1.5625e-05\n",
      "Epoch 5/20\n",
      "\u001b[1m48891/48891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 4ms/step - loss: 0.1452 - mae: 0.2871 - mse: 0.1414 - val_loss: 0.1362 - val_mae: 0.2735 - val_mse: 0.1324 - learning_rate: 1.5625e-05\n",
      "Epoch 6/20\n",
      "\u001b[1m48891/48891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 4ms/step - loss: 0.1449 - mae: 0.2868 - mse: 0.1411 - val_loss: 0.1364 - val_mae: 0.2735 - val_mse: 0.1325 - learning_rate: 1.5625e-05\n",
      "Epoch 7/20\n",
      "\u001b[1m48888/48891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1452 - mae: 0.2872 - mse: 0.1414\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\u001b[1m48891/48891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 4ms/step - loss: 0.1452 - mae: 0.2872 - mse: 0.1414 - val_loss: 0.1362 - val_mae: 0.2724 - val_mse: 0.1324 - learning_rate: 1.5625e-05\n",
      "Epoch 8/20\n",
      "\u001b[1m48891/48891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 4ms/step - loss: 0.1449 - mae: 0.2868 - mse: 0.1410 - val_loss: 0.1360 - val_mae: 0.2722 - val_mse: 0.1322 - learning_rate: 7.8125e-06\n",
      "Epoch 9/20\n",
      "\u001b[1m48891/48891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 4ms/step - loss: 0.1446 - mae: 0.2864 - mse: 0.1408 - val_loss: 0.1361 - val_mae: 0.2730 - val_mse: 0.1323 - learning_rate: 7.8125e-06\n",
      "Epoch 9: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n"
     ]
    }
   ],
   "source": [
    "history4 = model4.fit(\n",
    "    [X_user_numpy, X_movie_numpy],\n",
    "    y,\n",
    "    epochs=20,\n",
    "    batch_size= 32,\n",
    "    validation_split=0.15,\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "a1407ad0-13e2-4715-95f2-5817074133c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.save('0305.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "16de378c-7b40-4b2b-b9ee-4348f51ea558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0305hist.pkl']"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(history4, '0305hist.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "621b8306-03c4-451c-9cfa-2ebbce80799b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m57519/57519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 2ms/step - loss: 0.1391 - mae: 0.2839 - mse: 0.1353\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.13894513249397278, 0.28180503845214844, 0.13514649868011475]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.evaluate([X_user_numpy, X_movie_numpy], y = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "34d9683c-be1c-4ede-934e-01773b54972a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 1)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>mae</th></tr><tr><td>f64</td></tr></thead><tbody><tr><td>0.286651</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 1)\n",
       "┌──────────┐\n",
       "│ mae      │\n",
       "│ ---      │\n",
       "│ f64      │\n",
       "╞══════════╡\n",
       "│ 0.286651 │\n",
       "└──────────┘"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.DataFrame(history4.history).select(['mae').min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "7d9ad9e2-fd65-4cde-a8c8-883ef97dcd3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (9, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>loss</th><th>mae</th><th>mse</th><th>val_loss</th><th>val_mae</th><th>val_mse</th><th>learning_rate</th></tr><tr><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>0.144856</td><td>0.28691</td><td>0.141164</td><td>0.136026</td><td>0.271619</td><td>0.132293</td><td>0.000016</td></tr><tr><td>0.145055</td><td>0.287072</td><td>0.141323</td><td>0.136023</td><td>0.273272</td><td>0.132283</td><td>0.000016</td></tr><tr><td>0.145118</td><td>0.287098</td><td>0.14136</td><td>0.136615</td><td>0.275028</td><td>0.132867</td><td>0.000016</td></tr><tr><td>0.145056</td><td>0.286985</td><td>0.141282</td><td>0.135919</td><td>0.27263</td><td>0.13212</td><td>0.000016</td></tr><tr><td>0.145044</td><td>0.286964</td><td>0.141253</td><td>0.136156</td><td>0.273478</td><td>0.132369</td><td>0.000016</td></tr><tr><td>0.145181</td><td>0.287078</td><td>0.14137</td><td>0.136367</td><td>0.27347</td><td>0.13254</td><td>0.000016</td></tr><tr><td>0.145163</td><td>0.287058</td><td>0.141338</td><td>0.136179</td><td>0.272438</td><td>0.13235</td><td>0.000016</td></tr><tr><td>0.144879</td><td>0.286755</td><td>0.14106</td><td>0.136005</td><td>0.272152</td><td>0.132173</td><td>0.000008</td></tr><tr><td>0.144898</td><td>0.286651</td><td>0.141079</td><td>0.136129</td><td>0.273005</td><td>0.132308</td><td>0.000008</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (9, 7)\n",
       "┌──────────┬──────────┬──────────┬──────────┬──────────┬──────────┬───────────────┐\n",
       "│ loss     ┆ mae      ┆ mse      ┆ val_loss ┆ val_mae  ┆ val_mse  ┆ learning_rate │\n",
       "│ ---      ┆ ---      ┆ ---      ┆ ---      ┆ ---      ┆ ---      ┆ ---           │\n",
       "│ f64      ┆ f64      ┆ f64      ┆ f64      ┆ f64      ┆ f64      ┆ f64           │\n",
       "╞══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪═══════════════╡\n",
       "│ 0.144856 ┆ 0.28691  ┆ 0.141164 ┆ 0.136026 ┆ 0.271619 ┆ 0.132293 ┆ 0.000016      │\n",
       "│ 0.145055 ┆ 0.287072 ┆ 0.141323 ┆ 0.136023 ┆ 0.273272 ┆ 0.132283 ┆ 0.000016      │\n",
       "│ 0.145118 ┆ 0.287098 ┆ 0.14136  ┆ 0.136615 ┆ 0.275028 ┆ 0.132867 ┆ 0.000016      │\n",
       "│ 0.145056 ┆ 0.286985 ┆ 0.141282 ┆ 0.135919 ┆ 0.27263  ┆ 0.13212  ┆ 0.000016      │\n",
       "│ 0.145044 ┆ 0.286964 ┆ 0.141253 ┆ 0.136156 ┆ 0.273478 ┆ 0.132369 ┆ 0.000016      │\n",
       "│ 0.145181 ┆ 0.287078 ┆ 0.14137  ┆ 0.136367 ┆ 0.27347  ┆ 0.13254  ┆ 0.000016      │\n",
       "│ 0.145163 ┆ 0.287058 ┆ 0.141338 ┆ 0.136179 ┆ 0.272438 ┆ 0.13235  ┆ 0.000016      │\n",
       "│ 0.144879 ┆ 0.286755 ┆ 0.14106  ┆ 0.136005 ┆ 0.272152 ┆ 0.132173 ┆ 0.000008      │\n",
       "│ 0.144898 ┆ 0.286651 ┆ 0.141079 ┆ 0.136129 ┆ 0.273005 ┆ 0.132308 ┆ 0.000008      │\n",
       "└──────────┴──────────┴──────────┴──────────┴──────────┴──────────┴───────────────┘"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.DataFrame(history4.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8b61a4-eeee-4498-8ef2-2818833f8e6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b7bf695-f566-41c3-9d58-225d33ad75b4",
   "metadata": {},
   "source": [
    "ONAJ KOJI JE PRE RADIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "cdd65ba1-5011-415a-a812-650f47be7f0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_14\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_14\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ movie_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_154 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,688</span> │ user_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_160 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,072</span> │ movie_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_148 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_154[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_154 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_160[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_155 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_148[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_161 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_154[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_149 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_155[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_155 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_161[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_156 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ dropout_149[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_162 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ dropout_155[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_150 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_156[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_156 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_162[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_157 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ dropout_150[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_163 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ dropout_156[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_151 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_157[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_157 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_163[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_158 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dropout_151[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_164 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dropout_157[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_152 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_158[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_158 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_164[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_159 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │ dropout_152[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_165 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │ dropout_158[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_153 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_159[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_159 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_165[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ user_embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │ dropout_153[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ movie_embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │ dropout_159[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dot_product (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ user_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
       "│                               │                           │                 │ movie_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_input (\u001b[38;5;33mInputLayer\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ movie_input (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_154 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │           \u001b[38;5;34m2,688\u001b[0m │ user_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_160 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │           \u001b[38;5;34m3,072\u001b[0m │ movie_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_148 (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ dense_154[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_154 (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ dense_160[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_155 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m8,256\u001b[0m │ dropout_148[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_161 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m8,256\u001b[0m │ dropout_154[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_149 (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_155[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_155 (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_161[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_156 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m4,160\u001b[0m │ dropout_149[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_162 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m4,160\u001b[0m │ dropout_155[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_150 (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_156[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_156 (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_162[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_157 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m4,160\u001b[0m │ dropout_150[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_163 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m4,160\u001b[0m │ dropout_156[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_151 (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_157[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_157 (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_163[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_158 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │           \u001b[38;5;34m2,080\u001b[0m │ dropout_151[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_164 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │           \u001b[38;5;34m2,080\u001b[0m │ dropout_157[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_152 (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_158[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_158 (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_164[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_159 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │           \u001b[38;5;34m1,056\u001b[0m │ dropout_152[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_165 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │           \u001b[38;5;34m1,056\u001b[0m │ dropout_158[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_153 (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_159[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_159 (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_165[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ user_embedding (\u001b[38;5;33mDense\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │           \u001b[38;5;34m1,056\u001b[0m │ dropout_153[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ movie_embedding (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │           \u001b[38;5;34m1,056\u001b[0m │ dropout_159[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dot_product (\u001b[38;5;33mDot\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │ user_embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
       "│                               │                           │                 │ movie_embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">47,296</span> (184.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m47,296\u001b[0m (184.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">47,296</span> (184.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m47,296\u001b[0m (184.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_user_features = X_user_numpy.shape[1]   \n",
    "num_movie_features = X_movie_numpy.shape[1]\n",
    "drop = 0.2\n",
    "# ---------------- USER TOWER ----------------\n",
    "user_input = layers.Input(shape=(num_user_features,), name='user_input')\n",
    "\n",
    "x = layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01))(user_input)\n",
    "x = layers.Dropout(drop)(x)\n",
    "x = layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "x = layers.Dropout(drop)(x)\n",
    "x = layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "x = layers.Dropout(drop)(x)\n",
    "x = layers.Dense(64, activation='relu',kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "x = layers.Dropout(drop)(x)\n",
    "x = layers.Dense(32, activation='relu',kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "x = layers.Dropout(drop)(x)\n",
    "x = layers.Dense(32, activation='relu',kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "x = layers.Dropout(drop)(x)\n",
    "\n",
    "user_embedding = layers.Dense(32, activation='linear', name='user_embedding')(x)\n",
    "\n",
    "# ---------------- MOVIE TOWER ----------------\n",
    "movie_input = layers.Input(shape=(num_movie_features,), name='movie_input')\n",
    "\n",
    "x2= layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01))(movie_input)\n",
    "x2 = layers.Dropout(drop)(x2)\n",
    "x2 = layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.01))(x2)\n",
    "x2 = layers.Dropout(drop)(x2)\n",
    "x2 = layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.01))(x2)\n",
    "x2 = layers.Dropout(drop)(x2)\n",
    "x2 = layers.Dense(64, activation='relu',kernel_regularizer=regularizers.l2(0.001))(x2)\n",
    "x2 = layers.Dropout(drop)(x2)\n",
    "x2 = layers.Dense(32, activation='relu',kernel_regularizer=regularizers.l2(0.001))(x2)\n",
    "x2 = layers.Dropout(drop)(x2)\n",
    "x2 = layers.Dense(32, activation='relu',kernel_regularizer=regularizers.l2(0.001))(x2)\n",
    "x2 = layers.Dropout(drop)(x2)\n",
    "\n",
    "movie_embedding = layers.Dense(32, activation='linear', name='movie_embedding')(x2)\n",
    "\n",
    "# ---------------- FINAL MODEL ----------------\n",
    "dot_product = layers.Dot(axes=1, name='dot_product')([user_embedding, movie_embedding])\n",
    "\n",
    "model = models.Model(inputs=[user_input, movie_input], outputs=dot_product)\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae', 'mse'])\n",
    "\n",
    "# Pregled modela\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e0c8177b-4a7b-469c-accb-4f6c869c7027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m2876/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 8ms/step - loss: 2.7322 - mae: 0.8596 - mse: 1.2939 - val_loss: 0.7894 - val_mae: 0.6414 - val_mse: 0.7034 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m2876/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - loss: 0.8218 - mae: 0.6678 - mse: 0.7514 - val_loss: 0.7500 - val_mae: 0.6442 - val_mse: 0.7034 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m2876/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - loss: 0.7869 - mae: 0.6627 - mse: 0.7423 - val_loss: 0.7332 - val_mae: 0.6333 - val_mse: 0.6930 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m2876/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 7ms/step - loss: 0.7809 - mae: 0.6618 - mse: 0.7404 - val_loss: 0.7315 - val_mae: 0.6331 - val_mse: 0.6931 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m2876/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 7ms/step - loss: 0.7777 - mae: 0.6608 - mse: 0.7392 - val_loss: 0.7250 - val_mae: 0.6279 - val_mse: 0.6881 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m2876/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 0.7753 - mae: 0.6603 - mse: 0.7380 - val_loss: 0.7398 - val_mae: 0.6450 - val_mse: 0.7031 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m2876/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 0.7733 - mae: 0.6600 - mse: 0.7368 - val_loss: 0.7431 - val_mae: 0.6478 - val_mse: 0.7070 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m2871/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.7745 - mae: 0.6602 - mse: 0.7382\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m2876/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 0.7745 - mae: 0.6602 - mse: 0.7382 - val_loss: 0.7265 - val_mae: 0.6332 - val_mse: 0.6900 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m2876/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 0.7629 - mae: 0.6551 - mse: 0.7283 - val_loss: 0.7374 - val_mae: 0.6432 - val_mse: 0.7044 - learning_rate: 5.0000e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m2876/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 7ms/step - loss: 0.7615 - mae: 0.6553 - mse: 0.7287 - val_loss: 0.7179 - val_mae: 0.6253 - val_mse: 0.6857 - learning_rate: 5.0000e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m2876/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 0.7629 - mae: 0.6562 - mse: 0.7307 - val_loss: 0.7311 - val_mae: 0.6417 - val_mse: 0.6995 - learning_rate: 5.0000e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m2876/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 0.7609 - mae: 0.6553 - mse: 0.7292 - val_loss: 0.7390 - val_mae: 0.6505 - val_mse: 0.7079 - learning_rate: 5.0000e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m2868/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.7580 - mae: 0.6544 - mse: 0.7268\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m2876/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 0.7580 - mae: 0.6544 - mse: 0.7268 - val_loss: 0.7191 - val_mae: 0.6309 - val_mse: 0.6882 - learning_rate: 5.0000e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m2876/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 7ms/step - loss: 0.7541 - mae: 0.6523 - mse: 0.7237 - val_loss: 0.7208 - val_mae: 0.6220 - val_mse: 0.6911 - learning_rate: 2.5000e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m2876/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 0.7526 - mae: 0.6521 - mse: 0.7231 - val_loss: 0.7149 - val_mae: 0.6253 - val_mse: 0.6856 - learning_rate: 2.5000e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m2876/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - loss: 0.7507 - mae: 0.6515 - mse: 0.7217 - val_loss: 0.7176 - val_mae: 0.6275 - val_mse: 0.6885 - learning_rate: 2.5000e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m2876/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 0.7531 - mae: 0.6527 - mse: 0.7243 - val_loss: 0.7226 - val_mae: 0.6364 - val_mse: 0.6940 - learning_rate: 2.5000e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m2870/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.7512 - mae: 0.6520 - mse: 0.7227\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m2876/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 0.7512 - mae: 0.6520 - mse: 0.7227 - val_loss: 0.7182 - val_mae: 0.6293 - val_mse: 0.6896 - learning_rate: 2.5000e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m2876/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - loss: 0.7452 - mae: 0.6491 - mse: 0.7172 - val_loss: 0.7296 - val_mae: 0.6426 - val_mse: 0.7023 - learning_rate: 1.2500e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m2876/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 7ms/step - loss: 0.7457 - mae: 0.6497 - mse: 0.7183 - val_loss: 0.7257 - val_mae: 0.6355 - val_mse: 0.6986 - learning_rate: 1.2500e-04\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# --- ReduceLROnPlateau ---\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# --- Treniraj model ---\n",
    "history = model.fit(\n",
    "    [X_user_numpy, X_movie_numpy],\n",
    "    y,\n",
    "    epochs=20,\n",
    "    batch_size=512,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "46e2ca84-b1d3-48c4-9961-82fb5b8c9d1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_17\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_17\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ movie_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_190 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,688</span> │ user_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_196 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,072</span> │ movie_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_24        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ dense_190[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_30        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ dense_196[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ activation_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ activation_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_30[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_184 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_190 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_30[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_191 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_184[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_197 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_190[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_25        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ dense_191[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_31        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ dense_197[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ activation_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ activation_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_31[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_185 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_191 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_31[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_192 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ dropout_185[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_198 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ dropout_191[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_26        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ dense_192[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_32        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ dense_198[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ activation_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ activation_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_32[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_186 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_192 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_32[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_193 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ dropout_186[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_199 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ dropout_192[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_27        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ dense_193[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_33        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ dense_199[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ activation_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ activation_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_33[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_187 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_193 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_33[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_194 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dropout_187[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_200 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dropout_193[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_28        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ dense_194[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_34        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ dense_200[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ activation_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_28[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ activation_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_34[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_188 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_28[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_194 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_34[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_195 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │ dropout_188[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_201 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │ dropout_194[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_29        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ dense_195[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_35        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ dense_201[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ activation_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_29[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ activation_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_35[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_189 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_29[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_195 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_35[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ user_embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │ dropout_189[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ movie_embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │ dropout_195[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dot_product (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ user_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
       "│                               │                           │                 │ movie_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_input (\u001b[38;5;33mInputLayer\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ movie_input (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_190 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │           \u001b[38;5;34m2,688\u001b[0m │ user_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_196 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │           \u001b[38;5;34m3,072\u001b[0m │ movie_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_24        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │             \u001b[38;5;34m512\u001b[0m │ dense_190[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_30        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │             \u001b[38;5;34m512\u001b[0m │ dense_196[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ activation_24 (\u001b[38;5;33mActivation\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ batch_normalization_24[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ activation_30 (\u001b[38;5;33mActivation\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ batch_normalization_30[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_184 (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ activation_24[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_190 (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ activation_30[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_191 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m8,256\u001b[0m │ dropout_184[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_197 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m8,256\u001b[0m │ dropout_190[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_25        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │             \u001b[38;5;34m256\u001b[0m │ dense_191[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_31        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │             \u001b[38;5;34m256\u001b[0m │ dense_197[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ activation_25 (\u001b[38;5;33mActivation\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ batch_normalization_25[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ activation_31 (\u001b[38;5;33mActivation\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ batch_normalization_31[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_185 (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ activation_25[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_191 (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ activation_31[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_192 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m4,160\u001b[0m │ dropout_185[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_198 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m4,160\u001b[0m │ dropout_191[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_26        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │             \u001b[38;5;34m256\u001b[0m │ dense_192[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_32        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │             \u001b[38;5;34m256\u001b[0m │ dense_198[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ activation_26 (\u001b[38;5;33mActivation\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ batch_normalization_26[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ activation_32 (\u001b[38;5;33mActivation\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ batch_normalization_32[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_186 (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ activation_26[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_192 (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ activation_32[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_193 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m4,160\u001b[0m │ dropout_186[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_199 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m4,160\u001b[0m │ dropout_192[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_27        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │             \u001b[38;5;34m256\u001b[0m │ dense_193[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_33        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │             \u001b[38;5;34m256\u001b[0m │ dense_199[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ activation_27 (\u001b[38;5;33mActivation\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ batch_normalization_27[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ activation_33 (\u001b[38;5;33mActivation\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ batch_normalization_33[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_187 (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ activation_27[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_193 (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ activation_33[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_194 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │           \u001b[38;5;34m2,080\u001b[0m │ dropout_187[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_200 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │           \u001b[38;5;34m2,080\u001b[0m │ dropout_193[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_28        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │             \u001b[38;5;34m128\u001b[0m │ dense_194[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_34        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │             \u001b[38;5;34m128\u001b[0m │ dense_200[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ activation_28 (\u001b[38;5;33mActivation\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ batch_normalization_28[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ activation_34 (\u001b[38;5;33mActivation\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ batch_normalization_34[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_188 (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ activation_28[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_194 (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ activation_34[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_195 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │           \u001b[38;5;34m1,056\u001b[0m │ dropout_188[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_201 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │           \u001b[38;5;34m1,056\u001b[0m │ dropout_194[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_29        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │             \u001b[38;5;34m128\u001b[0m │ dense_195[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_35        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │             \u001b[38;5;34m128\u001b[0m │ dense_201[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ activation_29 (\u001b[38;5;33mActivation\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ batch_normalization_29[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ activation_35 (\u001b[38;5;33mActivation\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ batch_normalization_35[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_189 (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ activation_29[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_195 (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ activation_35[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ user_embedding (\u001b[38;5;33mDense\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │           \u001b[38;5;34m1,056\u001b[0m │ dropout_189[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ movie_embedding (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │           \u001b[38;5;34m1,056\u001b[0m │ dropout_195[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dot_product (\u001b[38;5;33mDot\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │ user_embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
       "│                               │                           │                 │ movie_embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">50,368</span> (196.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m50,368\u001b[0m (196.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">48,832</span> (190.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m48,832\u001b[0m (190.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> (6.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,536\u001b[0m (6.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_user_features = X_user_numpy.shape[1]   \n",
    "num_movie_features = X_movie_numpy.shape[1]\n",
    "drop = 0.2\n",
    "# ---------------- USER TOWER ----------------\n",
    "user_input = layers.Input(shape=(num_user_features,), name='user_input')\n",
    "\n",
    "x = layers.Dense(128, kernel_regularizer=regularizers.l2(0.001))(user_input)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('relu')(x)\n",
    "x = layers.Dropout(drop)(x)\n",
    "\n",
    "x = layers.Dense(64, kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('relu')(x)\n",
    "x = layers.Dropout(drop)(x)\n",
    "\n",
    "x = layers.Dense(64, kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('relu')(x)\n",
    "x = layers.Dropout(drop)(x)\n",
    "\n",
    "x = layers.Dense(64, kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('relu')(x)\n",
    "x = layers.Dropout(drop)(x)\n",
    "\n",
    "x = layers.Dense(32)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('tanh')(x)\n",
    "x = layers.Dropout(drop)(x)\n",
    "\n",
    "x = layers.Dense(32)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('tanh')(x)\n",
    "x = layers.Dropout(drop)(x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "user_embedding = layers.Dense(32, activation='linear', name='user_embedding')(x)\n",
    "\n",
    "# ---------------- MOVIE TOWER ----------------\n",
    "movie_input = layers.Input(shape=(num_movie_features,), name='movie_input')\n",
    "\n",
    "x2 = layers.Dense(128, kernel_regularizer=regularizers.l2(0.001))(movie_input)\n",
    "x2 = layers.BatchNormalization()(x2)\n",
    "x2 = layers.Activation('relu')(x2)\n",
    "x2 = layers.Dropout(drop)(x2)\n",
    "\n",
    "x2 = layers.Dense(64, kernel_regularizer=regularizers.l2(0.001))(x2)\n",
    "x2 = layers.BatchNormalization()(x2)\n",
    "x2 = layers.Activation('relu')(x2)\n",
    "x2 = layers.Dropout(drop)(x2)\n",
    "\n",
    "x2 = layers.Dense(64, kernel_regularizer=regularizers.l2(0.001))(x2)\n",
    "x2 = layers.BatchNormalization()(x2)\n",
    "x2 = layers.Activation('relu')(x2)\n",
    "x2 = layers.Dropout(drop)(x2)\n",
    "\n",
    "x2 = layers.Dense(64, kernel_regularizer=regularizers.l2(0.001))(x2)\n",
    "x2 = layers.BatchNormalization()(x2)\n",
    "x2 = layers.Activation('relu')(x2)\n",
    "x2 = layers.Dropout(drop)(x2)\n",
    "\n",
    "x2 = layers.Dense(32)(x2)\n",
    "x2 = layers.BatchNormalization()(x2)\n",
    "x2 = layers.Activation('tanh')(x2)\n",
    "x2 = layers.Dropout(drop)(x2)\n",
    "\n",
    "x2 = layers.Dense(32)(x2)\n",
    "x2 = layers.BatchNormalization()(x2)\n",
    "x2 = layers.Activation('tanh')(x2)\n",
    "x2 = layers.Dropout(drop)(x2)\n",
    "\n",
    "movie_embedding = layers.Dense(32, activation='linear', name='movie_embedding')(x2)\n",
    "\n",
    "\n",
    "movie_embedding = layers.Dense(32, activation='linear', name='movie_embedding')(x2)\n",
    "\n",
    "# ---------------- FINAL MODEL ----------------\n",
    "dot_product = layers.Dot(axes=1, name='dot_product')([user_embedding, movie_embedding])\n",
    "\n",
    "model = models.Model(inputs=[user_input, movie_input], outputs=dot_product)\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae', 'mse'])\n",
    "\n",
    "# Pregled modela\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "6c95205c-412c-4eaf-a8b5-ddd0704244b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m2876/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 12ms/step - loss: 1.1139 - mae: 0.5424 - mse: 0.6770 - val_loss: 0.2881 - val_mae: 0.2897 - val_mse: 0.1415 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m2876/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 14ms/step - loss: 0.2321 - mae: 0.2960 - mse: 0.1480 - val_loss: 0.1464 - val_mae: 0.2759 - val_mse: 0.1395 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m2876/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 13ms/step - loss: 0.1495 - mae: 0.2901 - mse: 0.1434 - val_loss: 0.1397 - val_mae: 0.2725 - val_mse: 0.1340 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m2876/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 12ms/step - loss: 0.1472 - mae: 0.2882 - mse: 0.1416 - val_loss: 0.1432 - val_mae: 0.2752 - val_mse: 0.1378 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m2876/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 12ms/step - loss: 0.1453 - mae: 0.2863 - mse: 0.1399 - val_loss: 0.1506 - val_mae: 0.2794 - val_mse: 0.1454 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m2876/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1449 - mae: 0.2857 - mse: 0.1396\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m2876/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 11ms/step - loss: 0.1449 - mae: 0.2857 - mse: 0.1396 - val_loss: 0.1475 - val_mae: 0.2772 - val_mse: 0.1422 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m2876/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 11ms/step - loss: 0.1417 - mae: 0.2831 - mse: 0.1375 - val_loss: 0.1476 - val_mae: 0.2780 - val_mse: 0.1440 - learning_rate: 5.0000e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m2876/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 12ms/step - loss: 0.1410 - mae: 0.2828 - mse: 0.1375 - val_loss: 0.1367 - val_mae: 0.2704 - val_mse: 0.1332 - learning_rate: 5.0000e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m2876/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 12ms/step - loss: 0.1403 - mae: 0.2820 - mse: 0.1367 - val_loss: 0.1364 - val_mae: 0.2703 - val_mse: 0.1329 - learning_rate: 5.0000e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m2876/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 12ms/step - loss: 0.1402 - mae: 0.2818 - mse: 0.1366 - val_loss: 0.1382 - val_mae: 0.2718 - val_mse: 0.1346 - learning_rate: 5.0000e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m2876/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 11ms/step - loss: 0.1403 - mae: 0.2818 - mse: 0.1367 - val_loss: 0.1447 - val_mae: 0.2744 - val_mse: 0.1411 - learning_rate: 5.0000e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m2876/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.1402 - mae: 0.2817 - mse: 0.1366\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m2876/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 13ms/step - loss: 0.1402 - mae: 0.2817 - mse: 0.1366 - val_loss: 0.1428 - val_mae: 0.2738 - val_mse: 0.1392 - learning_rate: 5.0000e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m2876/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 12ms/step - loss: 0.1384 - mae: 0.2801 - mse: 0.1352 - val_loss: 0.1365 - val_mae: 0.2719 - val_mse: 0.1338 - learning_rate: 2.5000e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m2876/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 12ms/step - loss: 0.1370 - mae: 0.2790 - mse: 0.1344 - val_loss: 0.1366 - val_mae: 0.2702 - val_mse: 0.1340 - learning_rate: 2.5000e-04\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    [X_user_numpy, X_movie_numpy],\n",
    "    y,\n",
    "    epochs=20,\n",
    "    batch_size=512,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f16b643-0228-4c54-920e-8a15d82241c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "aeb10816-dac4-48ad-98c8-1a4e0aca7e3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_19\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_19\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ movie_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_220 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,688</span> │ user_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_226 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,072</span> │ movie_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_54        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ dense_220[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_60        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ dense_226[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ activation_54 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_54[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ activation_60 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_60[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_214 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_54[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_220 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_60[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_221 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_214[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_227 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_220[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_55        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ dense_221[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_61        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ dense_227[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ activation_55 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_55[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ activation_61 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_61[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_215 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_55[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_221 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_61[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_222 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ dropout_215[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_228 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ dropout_221[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_56        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ dense_222[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_62        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ dense_228[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ activation_56 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_56[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ activation_62 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_62[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_216 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_56[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_222 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_62[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_223 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ dropout_216[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_229 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ dropout_222[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_57        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ dense_223[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_63        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ dense_229[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ activation_57 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_57[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ activation_63 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_63[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_217 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_57[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_223 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_63[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_224 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dropout_217[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_230 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dropout_223[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_58        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ dense_224[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_64        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ dense_230[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ activation_58 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_58[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ activation_64 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_64[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_218 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_58[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_224 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_64[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_225 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │ dropout_218[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_231 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │ dropout_224[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_59        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ dense_225[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_65        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ dense_231[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ activation_59 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_59[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ activation_65 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_65[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_219 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_59[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_225 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_65[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ user_embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │ dropout_219[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ movie_embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │ dropout_225[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lambda_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ user_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lambda_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ movie_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dot_product (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lambda_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],            │\n",
       "│                               │                           │                 │ lambda_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_input (\u001b[38;5;33mInputLayer\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ movie_input (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_220 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │           \u001b[38;5;34m2,688\u001b[0m │ user_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_226 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │           \u001b[38;5;34m3,072\u001b[0m │ movie_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_54        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │             \u001b[38;5;34m512\u001b[0m │ dense_220[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_60        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │             \u001b[38;5;34m512\u001b[0m │ dense_226[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ activation_54 (\u001b[38;5;33mActivation\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ batch_normalization_54[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ activation_60 (\u001b[38;5;33mActivation\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ batch_normalization_60[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_214 (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ activation_54[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_220 (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ activation_60[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_221 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m8,256\u001b[0m │ dropout_214[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_227 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m8,256\u001b[0m │ dropout_220[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_55        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │             \u001b[38;5;34m256\u001b[0m │ dense_221[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_61        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │             \u001b[38;5;34m256\u001b[0m │ dense_227[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ activation_55 (\u001b[38;5;33mActivation\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ batch_normalization_55[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ activation_61 (\u001b[38;5;33mActivation\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ batch_normalization_61[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_215 (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ activation_55[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_221 (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ activation_61[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_222 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m4,160\u001b[0m │ dropout_215[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_228 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m4,160\u001b[0m │ dropout_221[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_56        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │             \u001b[38;5;34m256\u001b[0m │ dense_222[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_62        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │             \u001b[38;5;34m256\u001b[0m │ dense_228[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ activation_56 (\u001b[38;5;33mActivation\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ batch_normalization_56[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ activation_62 (\u001b[38;5;33mActivation\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ batch_normalization_62[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_216 (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ activation_56[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_222 (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ activation_62[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_223 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m4,160\u001b[0m │ dropout_216[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_229 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m4,160\u001b[0m │ dropout_222[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_57        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │             \u001b[38;5;34m256\u001b[0m │ dense_223[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_63        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │             \u001b[38;5;34m256\u001b[0m │ dense_229[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ activation_57 (\u001b[38;5;33mActivation\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ batch_normalization_57[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ activation_63 (\u001b[38;5;33mActivation\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ batch_normalization_63[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_217 (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ activation_57[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_223 (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ activation_63[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_224 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │           \u001b[38;5;34m2,080\u001b[0m │ dropout_217[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_230 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │           \u001b[38;5;34m2,080\u001b[0m │ dropout_223[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_58        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │             \u001b[38;5;34m128\u001b[0m │ dense_224[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_64        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │             \u001b[38;5;34m128\u001b[0m │ dense_230[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ activation_58 (\u001b[38;5;33mActivation\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ batch_normalization_58[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ activation_64 (\u001b[38;5;33mActivation\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ batch_normalization_64[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_218 (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ activation_58[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_224 (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ activation_64[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_225 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │           \u001b[38;5;34m1,056\u001b[0m │ dropout_218[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_231 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │           \u001b[38;5;34m1,056\u001b[0m │ dropout_224[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_59        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │             \u001b[38;5;34m128\u001b[0m │ dense_225[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_65        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │             \u001b[38;5;34m128\u001b[0m │ dense_231[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ activation_59 (\u001b[38;5;33mActivation\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ batch_normalization_59[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ activation_65 (\u001b[38;5;33mActivation\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ batch_normalization_65[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_219 (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ activation_59[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_225 (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ activation_65[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ user_embedding (\u001b[38;5;33mDense\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │           \u001b[38;5;34m1,056\u001b[0m │ dropout_219[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ movie_embedding (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │           \u001b[38;5;34m1,056\u001b[0m │ dropout_225[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lambda_2 (\u001b[38;5;33mLambda\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ user_embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lambda_3 (\u001b[38;5;33mLambda\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ movie_embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dot_product (\u001b[38;5;33mDot\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │ lambda_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],            │\n",
       "│                               │                           │                 │ lambda_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">50,368</span> (196.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m50,368\u001b[0m (196.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">48,832</span> (190.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m48,832\u001b[0m (190.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> (6.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,536\u001b[0m (6.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_user_features = X_user_numpy.shape[1]   \n",
    "num_movie_features = X_movie_numpy.shape[1]\n",
    "drop = 0.2\n",
    "# ---------------- USER TOWER ----------------\n",
    "user_input = layers.Input(shape=(num_user_features,), name='user_input')\n",
    "\n",
    "x = layers.Dense(128, kernel_regularizer=regularizers.l2(0.001))(user_input)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('relu')(x)\n",
    "x = layers.Dropout(drop)(x)\n",
    "\n",
    "x = layers.Dense(64, kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('relu')(x)\n",
    "x = layers.Dropout(drop)(x)\n",
    "\n",
    "x = layers.Dense(64, kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('relu')(x)\n",
    "x = layers.Dropout(drop)(x)\n",
    "\n",
    "x = layers.Dense(64, kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('relu')(x)\n",
    "x = layers.Dropout(drop)(x)\n",
    "\n",
    "x = layers.Dense(32)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('tanh')(x)\n",
    "x = layers.Dropout(drop)(x)\n",
    "\n",
    "x = layers.Dense(32)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('tanh')(x)\n",
    "x = layers.Dropout(drop)(x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "user_embedding = layers.Dense(32, activation='linear', name='user_embedding')(x)\n",
    "user_embedding = user_embedding = layers.Lambda(lambda x: tf.linalg.l2_normalize(x, axis=1))(user_embedding)\n",
    "# ---------------- MOVIE TOWER ----------------\n",
    "movie_input = layers.Input(shape=(num_movie_features,), name='movie_input')\n",
    "\n",
    "x2 = layers.Dense(128, kernel_regularizer=regularizers.l2(0.001))(movie_input)\n",
    "x2 = layers.BatchNormalization()(x2)\n",
    "x2 = layers.Activation('relu')(x2)\n",
    "x2 = layers.Dropout(drop)(x2)\n",
    "\n",
    "x2 = layers.Dense(64, kernel_regularizer=regularizers.l2(0.001))(x2)\n",
    "x2 = layers.BatchNormalization()(x2)\n",
    "x2 = layers.Activation('relu')(x2)\n",
    "x2 = layers.Dropout(drop)(x2)\n",
    "\n",
    "x2 = layers.Dense(64, kernel_regularizer=regularizers.l2(0.001))(x2)\n",
    "x2 = layers.BatchNormalization()(x2)\n",
    "x2 = layers.Activation('relu')(x2)\n",
    "x2 = layers.Dropout(drop)(x2)\n",
    "\n",
    "x2 = layers.Dense(64, kernel_regularizer=regularizers.l2(0.001))(x2)\n",
    "x2 = layers.BatchNormalization()(x2)\n",
    "x2 = layers.Activation('relu')(x2)\n",
    "x2 = layers.Dropout(drop)(x2)\n",
    "\n",
    "x2 = layers.Dense(32)(x2)\n",
    "x2 = layers.BatchNormalization()(x2)\n",
    "x2 = layers.Activation('tanh')(x2)\n",
    "x2 = layers.Dropout(drop)(x2)\n",
    "\n",
    "x2 = layers.Dense(32)(x2)\n",
    "x2 = layers.BatchNormalization()(x2)\n",
    "x2 = layers.Activation('tanh')(x2)\n",
    "x2 = layers.Dropout(drop)(x2)\n",
    "\n",
    "movie_embedding = layers.Dense(32, activation='linear', name='movie_embedding')(x2)\n",
    "\n",
    "movie_embedding = layers.Lambda(lambda x: tf.linalg.l2_normalize(x, axis=1))(movie_embedding)\n",
    "# ---------------- FINAL MODEL ----------------\n",
    "dot_product = layers.Dot(axes=1, name='dot_product')([user_embedding, movie_embedding])\n",
    "\n",
    "model = models.Model(inputs=[user_input, movie_input], outputs=dot_product)\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae', 'mse'])\n",
    "\n",
    "# Pregled modela\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "a74cc263-a3ec-416c-a86c-bb43a241d261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m5752/5752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 10ms/step - loss: 0.3060 - mae: 0.3230 - mse: 0.1741 - val_loss: 0.1423 - val_mae: 0.2730 - val_mse: 0.1355 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m5752/5752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 9ms/step - loss: 0.1478 - mae: 0.2877 - mse: 0.1412 - val_loss: 0.1418 - val_mae: 0.2730 - val_mse: 0.1354 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m5752/5752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 9ms/step - loss: 0.1468 - mae: 0.2867 - mse: 0.1405 - val_loss: 0.1508 - val_mae: 0.2786 - val_mse: 0.1451 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m5752/5752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 9ms/step - loss: 0.1461 - mae: 0.2864 - mse: 0.1404 - val_loss: 0.1602 - val_mae: 0.2887 - val_mse: 0.1548 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m5752/5752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1455 - mae: 0.2862 - mse: 0.1401\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m5752/5752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 9ms/step - loss: 0.1455 - mae: 0.2862 - mse: 0.1401 - val_loss: 0.1458 - val_mae: 0.2747 - val_mse: 0.1406 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m5752/5752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 9ms/step - loss: 0.1425 - mae: 0.2840 - mse: 0.1385 - val_loss: 0.1544 - val_mae: 0.2837 - val_mse: 0.1509 - learning_rate: 5.0000e-04\n",
      "Epoch 7/20\n",
      "\u001b[1m5752/5752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 9ms/step - loss: 0.1409 - mae: 0.2828 - mse: 0.1374 - val_loss: 0.1368 - val_mae: 0.2707 - val_mse: 0.1332 - learning_rate: 5.0000e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m5752/5752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 9ms/step - loss: 0.1409 - mae: 0.2827 - mse: 0.1374 - val_loss: 0.1404 - val_mae: 0.2716 - val_mse: 0.1369 - learning_rate: 5.0000e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m5752/5752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 9ms/step - loss: 0.1409 - mae: 0.2828 - mse: 0.1374 - val_loss: 0.1417 - val_mae: 0.2717 - val_mse: 0.1382 - learning_rate: 5.0000e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m5752/5752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1405 - mae: 0.2821 - mse: 0.1369\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m5752/5752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 9ms/step - loss: 0.1405 - mae: 0.2821 - mse: 0.1369 - val_loss: 0.1407 - val_mae: 0.2707 - val_mse: 0.1373 - learning_rate: 5.0000e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m5752/5752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 9ms/step - loss: 0.1392 - mae: 0.2813 - mse: 0.1363 - val_loss: 0.1372 - val_mae: 0.2686 - val_mse: 0.1348 - learning_rate: 2.5000e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m5752/5752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 9ms/step - loss: 0.1381 - mae: 0.2805 - mse: 0.1356 - val_loss: 0.1366 - val_mae: 0.2679 - val_mse: 0.1342 - learning_rate: 2.5000e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m5752/5752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 9ms/step - loss: 0.1379 - mae: 0.2804 - mse: 0.1355 - val_loss: 0.1364 - val_mae: 0.2682 - val_mse: 0.1340 - learning_rate: 2.5000e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m5752/5752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 9ms/step - loss: 0.1380 - mae: 0.2807 - mse: 0.1356 - val_loss: 0.1363 - val_mae: 0.2680 - val_mse: 0.1339 - learning_rate: 2.5000e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m5752/5752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 9ms/step - loss: 0.1380 - mae: 0.2803 - mse: 0.1356 - val_loss: 0.1391 - val_mae: 0.2696 - val_mse: 0.1367 - learning_rate: 2.5000e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m5752/5752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 9ms/step - loss: 0.1378 - mae: 0.2803 - mse: 0.1354 - val_loss: 0.1387 - val_mae: 0.2702 - val_mse: 0.1362 - learning_rate: 2.5000e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m5752/5752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 9ms/step - loss: 0.1377 - mae: 0.2801 - mse: 0.1352 - val_loss: 0.1357 - val_mae: 0.2681 - val_mse: 0.1332 - learning_rate: 2.5000e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m5752/5752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 9ms/step - loss: 0.1374 - mae: 0.2797 - mse: 0.1350 - val_loss: 0.1369 - val_mae: 0.2686 - val_mse: 0.1345 - learning_rate: 2.5000e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m5752/5752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 9ms/step - loss: 0.1377 - mae: 0.2802 - mse: 0.1352 - val_loss: 0.1342 - val_mae: 0.2675 - val_mse: 0.1317 - learning_rate: 2.5000e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m5752/5752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 9ms/step - loss: 0.1379 - mae: 0.2802 - mse: 0.1355 - val_loss: 0.1360 - val_mae: 0.2675 - val_mse: 0.1335 - learning_rate: 2.5000e-04\n",
      "Restoring model weights from the end of the best epoch: 19.\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    [X_user_numpy, X_movie_numpy],\n",
    "    y,\n",
    "    epochs=20,\n",
    "    batch_size=256,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "67fb6693-1682-462a-8398-62e83a91b968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'], label='train loss')\n",
    "plt.plot(history.history['val_loss'], label='val loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b30687e-92af-4cc4-98c6-a4fe912d85e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5e0271-ce18-4fb6-8a73-5650410850b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "f7d354b7-27e1-48a7-b073-9c73334ec5bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_21\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_21\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ movie_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_244 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">5,376</span> │ user_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_250 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">6,144</span> │ movie_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_78        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ dense_244[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_84        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ dense_250[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ activation_78 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_78[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ activation_84 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_84[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_238 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_78[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_244 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_84[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_245 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ dropout_238[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_251 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ dropout_244[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_79        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ dense_245[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_85        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ dense_251[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ activation_79 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_79[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ activation_85 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_85[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_239 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_79[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_245 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_85[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_246 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │ dropout_239[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_252 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │ dropout_245[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_80        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ dense_246[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_86        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ dense_252[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ activation_80 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_80[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ activation_86 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_86[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_240 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_80[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_246 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_86[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_247 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_240[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_253 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_246[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_81        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ dense_247[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_87        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ dense_253[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ activation_81 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_81[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ activation_87 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_87[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_241 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_81[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_247 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_87[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_248 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ dropout_241[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_254 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ dropout_247[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_82        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ dense_248[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_88        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ dense_254[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ activation_82 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_82[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ activation_88 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_88[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_242 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_82[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_248 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_88[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_249 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dropout_242[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_255 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dropout_248[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_83        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ dense_249[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_89        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ dense_255[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ activation_83 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_83[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ activation_89 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_89[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_243 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_83[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_249 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_89[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ user_embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │ dropout_243[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ movie_embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │ dropout_249[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lambda_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ user_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lambda_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ movie_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dot_product (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lambda_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],            │\n",
       "│                               │                           │                 │ lambda_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_input (\u001b[38;5;33mInputLayer\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ movie_input (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_244 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)               │           \u001b[38;5;34m5,376\u001b[0m │ user_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_250 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)               │           \u001b[38;5;34m6,144\u001b[0m │ movie_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_78        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)               │           \u001b[38;5;34m1,024\u001b[0m │ dense_244[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_84        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)               │           \u001b[38;5;34m1,024\u001b[0m │ dense_250[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ activation_78 (\u001b[38;5;33mActivation\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ batch_normalization_78[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ activation_84 (\u001b[38;5;33mActivation\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ batch_normalization_84[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_238 (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ activation_78[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_244 (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ activation_84[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_245 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │          \u001b[38;5;34m32,896\u001b[0m │ dropout_238[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_251 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │          \u001b[38;5;34m32,896\u001b[0m │ dropout_244[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_79        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │             \u001b[38;5;34m512\u001b[0m │ dense_245[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_85        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │             \u001b[38;5;34m512\u001b[0m │ dense_251[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ activation_79 (\u001b[38;5;33mActivation\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ batch_normalization_79[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ activation_85 (\u001b[38;5;33mActivation\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ batch_normalization_85[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_239 (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ activation_79[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_245 (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ activation_85[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_246 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │          \u001b[38;5;34m16,512\u001b[0m │ dropout_239[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_252 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │          \u001b[38;5;34m16,512\u001b[0m │ dropout_245[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_80        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │             \u001b[38;5;34m512\u001b[0m │ dense_246[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_86        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │             \u001b[38;5;34m512\u001b[0m │ dense_252[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ activation_80 (\u001b[38;5;33mActivation\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ batch_normalization_80[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ activation_86 (\u001b[38;5;33mActivation\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ batch_normalization_86[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_240 (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ activation_80[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_246 (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ activation_86[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_247 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m8,256\u001b[0m │ dropout_240[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_253 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m8,256\u001b[0m │ dropout_246[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_81        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │             \u001b[38;5;34m256\u001b[0m │ dense_247[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_87        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │             \u001b[38;5;34m256\u001b[0m │ dense_253[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ activation_81 (\u001b[38;5;33mActivation\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ batch_normalization_81[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ activation_87 (\u001b[38;5;33mActivation\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ batch_normalization_87[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_241 (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ activation_81[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_247 (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ activation_87[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_248 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m4,160\u001b[0m │ dropout_241[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_254 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m4,160\u001b[0m │ dropout_247[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_82        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │             \u001b[38;5;34m256\u001b[0m │ dense_248[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_88        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │             \u001b[38;5;34m256\u001b[0m │ dense_254[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ activation_82 (\u001b[38;5;33mActivation\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ batch_normalization_82[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ activation_88 (\u001b[38;5;33mActivation\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ batch_normalization_88[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_242 (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ activation_82[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_248 (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ activation_88[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_249 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │           \u001b[38;5;34m2,080\u001b[0m │ dropout_242[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_255 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │           \u001b[38;5;34m2,080\u001b[0m │ dropout_248[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_83        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │             \u001b[38;5;34m128\u001b[0m │ dense_249[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_89        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │             \u001b[38;5;34m128\u001b[0m │ dense_255[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ activation_83 (\u001b[38;5;33mActivation\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ batch_normalization_83[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ activation_89 (\u001b[38;5;33mActivation\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ batch_normalization_89[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_243 (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ activation_83[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_249 (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ activation_89[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ user_embedding (\u001b[38;5;33mDense\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │           \u001b[38;5;34m1,056\u001b[0m │ dropout_243[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ movie_embedding (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │           \u001b[38;5;34m1,056\u001b[0m │ dropout_249[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lambda_6 (\u001b[38;5;33mLambda\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ user_embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lambda_7 (\u001b[38;5;33mLambda\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ movie_embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dot_product (\u001b[38;5;33mDot\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │ lambda_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],            │\n",
       "│                               │                           │                 │ lambda_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">146,816</span> (573.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m146,816\u001b[0m (573.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">144,128</span> (563.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m144,128\u001b[0m (563.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,688</span> (10.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,688\u001b[0m (10.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_user_features = X_user_numpy.shape[1]   \n",
    "num_movie_features = X_movie_numpy.shape[1]\n",
    "drop = 0.2\n",
    "# ---------------- USER TOWER ----------------\n",
    "user_input = layers.Input(shape=(num_user_features,), name='user_input')\n",
    "\n",
    "x = layers.Dense(256, kernel_regularizer=regularizers.l2(0.001))(user_input)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('relu')(x)\n",
    "x = layers.Dropout(drop)(x)\n",
    "\n",
    "x = layers.Dense(128, kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('relu')(x)\n",
    "x = layers.Dropout(drop)(x)\n",
    "\n",
    "x = layers.Dense(128, kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('relu')(x)\n",
    "x = layers.Dropout(drop)(x)\n",
    "\n",
    "x = layers.Dense(64, kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('relu')(x)\n",
    "x = layers.Dropout(drop)(x)\n",
    "\n",
    "x = layers.Dense(64)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('tanh')(x)\n",
    "x = layers.Dropout(drop)(x)\n",
    "\n",
    "x = layers.Dense(32)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('tanh')(x)\n",
    "x = layers.Dropout(drop)(x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "user_embedding = layers.Dense(32, activation='linear', name='user_embedding')(x)\n",
    "user_embedding = user_embedding = layers.Lambda(lambda x: tf.linalg.l2_normalize(x, axis=1))(user_embedding)\n",
    "# ---------------- MOVIE TOWER ----------------\n",
    "movie_input = layers.Input(shape=(num_movie_features,), name='movie_input')\n",
    "\n",
    "x2 = layers.Dense(256, kernel_regularizer=regularizers.l2(0.001))(movie_input)\n",
    "x2 = layers.BatchNormalization()(x2)\n",
    "x2 = layers.Activation('relu')(x2)\n",
    "x2 = layers.Dropout(drop)(x2)\n",
    "\n",
    "x2 = layers.Dense(128, kernel_regularizer=regularizers.l2(0.001))(x2)\n",
    "x2 = layers.BatchNormalization()(x2)\n",
    "x2 = layers.Activation('relu')(x2)\n",
    "x2 = layers.Dropout(drop)(x2)\n",
    "\n",
    "x2 = layers.Dense(128, kernel_regularizer=regularizers.l2(0.001))(x2)\n",
    "x2 = layers.BatchNormalization()(x2)\n",
    "x2 = layers.Activation('relu')(x2)\n",
    "x2 = layers.Dropout(drop)(x2)\n",
    "\n",
    "x2 = layers.Dense(64, kernel_regularizer=regularizers.l2(0.001))(x2)\n",
    "x2 = layers.BatchNormalization()(x2)\n",
    "x2 = layers.Activation('relu')(x2)\n",
    "x2 = layers.Dropout(drop)(x2)\n",
    "\n",
    "x2 = layers.Dense(64)(x2)\n",
    "x2 = layers.BatchNormalization()(x2)\n",
    "x2 = layers.Activation('tanh')(x2)\n",
    "x2 = layers.Dropout(drop)(x2)\n",
    "\n",
    "x2 = layers.Dense(32)(x2)\n",
    "x2 = layers.BatchNormalization()(x2)\n",
    "x2 = layers.Activation('tanh')(x2)\n",
    "x2 = layers.Dropout(drop)(x2)\n",
    "\n",
    "movie_embedding = layers.Dense(32, activation='linear', name='movie_embedding')(x2)\n",
    "\n",
    "movie_embedding = layers.Lambda(lambda x: tf.linalg.l2_normalize(x, axis=1))(movie_embedding)\n",
    "# ---------------- FINAL MODEL ----------------\n",
    "dot_product = layers.Dot(axes=1, name='dot_product')([user_embedding, movie_embedding])\n",
    "\n",
    "model2 = models.Model(inputs=[user_input, movie_input], outputs=dot_product)\n",
    "\n",
    "# Compile model\n",
    "model2.compile(optimizer=keras.optimizers.Adagrad(learning_rate=0.01), loss='mse', metrics=['mae', 'mse'])\n",
    "\n",
    "# Pregled modela\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "3db54bb2-1250-474f-a8d2-81c56016078d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m5752/5752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 11ms/step - loss: 0.9596 - mae: 0.3909 - mse: 0.2414 - val_loss: 0.5717 - val_mae: 0.2902 - val_mse: 0.1533 - learning_rate: 0.0100\n",
      "Epoch 2/20\n",
      "\u001b[1m5752/5752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 11ms/step - loss: 0.5131 - mae: 0.3075 - mse: 0.1575 - val_loss: 0.3519 - val_mae: 0.2779 - val_mse: 0.1426 - learning_rate: 0.0100\n",
      "Epoch 3/20\n",
      "\u001b[1m5752/5752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 11ms/step - loss: 0.3270 - mae: 0.2979 - mse: 0.1487 - val_loss: 0.2462 - val_mae: 0.2756 - val_mse: 0.1403 - learning_rate: 0.0100\n",
      "Epoch 4/20\n",
      "\u001b[1m5752/5752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 11ms/step - loss: 0.2353 - mae: 0.2934 - mse: 0.1447 - val_loss: 0.1973 - val_mae: 0.2771 - val_mse: 0.1428 - learning_rate: 0.0100\n",
      "Epoch 5/20\n",
      "\u001b[1m5752/5752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 12ms/step - loss: 0.1890 - mae: 0.2902 - mse: 0.1422 - val_loss: 0.1668 - val_mae: 0.2727 - val_mse: 0.1381 - learning_rate: 0.0100\n",
      "Epoch 6/20\n",
      "\u001b[1m5752/5752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 11ms/step - loss: 0.1654 - mae: 0.2879 - mse: 0.1405 - val_loss: 0.1542 - val_mae: 0.2727 - val_mse: 0.1384 - learning_rate: 0.0100\n",
      "Epoch 7/20\n",
      "\u001b[1m5752/5752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 11ms/step - loss: 0.1531 - mae: 0.2864 - mse: 0.1393 - val_loss: 0.1424 - val_mae: 0.2681 - val_mse: 0.1331 - learning_rate: 0.0100\n",
      "Epoch 8/20\n",
      "\u001b[1m5752/5752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 11ms/step - loss: 0.1468 - mae: 0.2855 - mse: 0.1385 - val_loss: 0.1395 - val_mae: 0.2680 - val_mse: 0.1336 - learning_rate: 0.0100\n",
      "Epoch 9/20\n",
      "\u001b[1m5752/5752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 11ms/step - loss: 0.1432 - mae: 0.2843 - mse: 0.1377 - val_loss: 0.1403 - val_mae: 0.2694 - val_mse: 0.1360 - learning_rate: 0.0100\n",
      "Epoch 10/20\n",
      "\u001b[1m5752/5752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 11ms/step - loss: 0.1414 - mae: 0.2839 - mse: 0.1373 - val_loss: 0.1353 - val_mae: 0.2692 - val_mse: 0.1318 - learning_rate: 0.0100\n",
      "Epoch 11/20\n",
      "\u001b[1m5752/5752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 11ms/step - loss: 0.1399 - mae: 0.2830 - mse: 0.1366 - val_loss: 0.1438 - val_mae: 0.2735 - val_mse: 0.1407 - learning_rate: 0.0100\n",
      "Epoch 12/20\n",
      "\u001b[1m5752/5752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 11ms/step - loss: 0.1394 - mae: 0.2828 - mse: 0.1365 - val_loss: 0.1363 - val_mae: 0.2698 - val_mse: 0.1336 - learning_rate: 0.0100\n",
      "Epoch 13/20\n",
      "\u001b[1m5752/5752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1390 - mae: 0.2824 - mse: 0.1363\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\u001b[1m5752/5752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 11ms/step - loss: 0.1390 - mae: 0.2824 - mse: 0.1363 - val_loss: 0.1383 - val_mae: 0.2700 - val_mse: 0.1358 - learning_rate: 0.0100\n",
      "Epoch 14/20\n",
      "\u001b[1m5752/5752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 11ms/step - loss: 0.1374 - mae: 0.2808 - mse: 0.1349 - val_loss: 0.1386 - val_mae: 0.2694 - val_mse: 0.1363 - learning_rate: 0.0050\n",
      "Epoch 15/20\n",
      "\u001b[1m5752/5752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 11ms/step - loss: 0.1373 - mae: 0.2806 - mse: 0.1351 - val_loss: 0.1377 - val_mae: 0.2689 - val_mse: 0.1356 - learning_rate: 0.0050\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n"
     ]
    }
   ],
   "source": [
    "history = model2.fit(\n",
    "    [X_user_numpy, X_movie_numpy],\n",
    "    y,\n",
    "    epochs=20,\n",
    "    batch_size=256,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2976aed-ceca-405e-9e07-2fadd661fe3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c88b8f-8361-4aba-a76f-6f9e1b0f6c11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2506fdca-428f-4eb1-9a6f-6a00482a1cb5",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "tanh() missing 1 required positional argument: 'x'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[99]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mkeras\u001b[49m\u001b[43m.\u001b[49m\u001b[43mactivations\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtanh\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: tanh() missing 1 required positional argument: 'x'"
     ]
    }
   ],
   "source": [
    "keras.activations.tanh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbc0315-4690-4200-87ca-be04c0633ab1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "id": "ed45d261-449a-4b69-a340-d50931379839",
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.save('model4_bestModel.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "id": "47a8f7b5-fb52-4813-b9af-8043452613a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model4_history.pkl']"
      ]
     },
     "execution_count": 569,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(history4, 'model4_history.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "id": "e75a4e6f-470e-412c-8fae-083bae44f822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "id": "455625b7-6dc1-4feb-aaa5-db75321ce6ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'Film.ipynb',\n",
       " 'logs',\n",
       " 'ml-32m',\n",
       " 'model2.keras',\n",
       " 'model4_bestModel.keras',\n",
       " 'model4_history.pkl',\n",
       " 'model_content_based.h5',\n",
       " 'model_content_based.keras']"
      ]
     },
     "execution_count": 577,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "id": "675caebe-e612-4f00-9f03-c292f9a753b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = keras.models.load_model('model4_bestModel.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "id": "24c40d7d-0250-4361-a5b7-d029db33ab06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 600,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "id": "0f71ba72-365f-4757-bf50-7ebb2f3a36c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 128)\n",
      "(128,)\n",
      "(23, 128)\n",
      "(128,)\n",
      "(128, 64)\n",
      "(64,)\n",
      "(128, 64)\n",
      "(64,)\n",
      "(64, 32)\n",
      "(32,)\n",
      "(64, 32)\n",
      "(32,)\n",
      "(32, 32)\n",
      "(32,)\n",
      "(32, 32)\n",
      "(32,)\n"
     ]
    }
   ],
   "source": [
    "for i in b.get_weights():\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ede90c1e-03aa-4395-a4fa-34a0b2ca8a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('model4_bestModel.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1082e412-c564-46c3-83f4-478814c64a39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method TensorFlowTrainer.evaluate of <Functional name=functional_21, built=True>>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53515764-ea70-4a99-a994-1f2049a096ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = joblib.load('model4_history.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "46f69607-2690-404d-9dd7-608c08394c04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (40, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>loss</th><th>mae</th><th>mse</th><th>val_loss</th><th>val_mae</th><th>val_mse</th><th>learning_rate</th></tr><tr><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>0.770369</td><td>0.65542</td><td>0.743842</td><td>0.720746</td><td>0.63967</td><td>0.70435</td><td>0.001</td></tr><tr><td>0.670304</td><td>0.613519</td><td>0.654273</td><td>0.687662</td><td>0.616345</td><td>0.671941</td><td>0.001</td></tr><tr><td>0.658134</td><td>0.606981</td><td>0.642408</td><td>0.695963</td><td>0.62438</td><td>0.680245</td><td>0.001</td></tr><tr><td>0.651583</td><td>0.603703</td><td>0.635826</td><td>0.670734</td><td>0.603242</td><td>0.654754</td><td>0.001</td></tr><tr><td>0.650193</td><td>0.602461</td><td>0.634437</td><td>0.693338</td><td>0.633178</td><td>0.678167</td><td>0.001</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>0.580292</td><td>0.567976</td><td>0.575258</td><td>0.619839</td><td>0.585411</td><td>0.614832</td><td>0.000031</td></tr><tr><td>0.580261</td><td>0.567877</td><td>0.575282</td><td>0.62281</td><td>0.586901</td><td>0.617861</td><td>0.000031</td></tr><tr><td>0.578901</td><td>0.566954</td><td>0.573978</td><td>0.623231</td><td>0.587159</td><td>0.618342</td><td>0.000031</td></tr><tr><td>0.578956</td><td>0.567044</td><td>0.57408</td><td>0.621133</td><td>0.586614</td><td>0.616272</td><td>0.000016</td></tr><tr><td>0.578518</td><td>0.566792</td><td>0.573674</td><td>0.622389</td><td>0.588401</td><td>0.617569</td><td>0.000016</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (40, 7)\n",
       "┌──────────┬──────────┬──────────┬──────────┬──────────┬──────────┬───────────────┐\n",
       "│ loss     ┆ mae      ┆ mse      ┆ val_loss ┆ val_mae  ┆ val_mse  ┆ learning_rate │\n",
       "│ ---      ┆ ---      ┆ ---      ┆ ---      ┆ ---      ┆ ---      ┆ ---           │\n",
       "│ f64      ┆ f64      ┆ f64      ┆ f64      ┆ f64      ┆ f64      ┆ f64           │\n",
       "╞══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪═══════════════╡\n",
       "│ 0.770369 ┆ 0.65542  ┆ 0.743842 ┆ 0.720746 ┆ 0.63967  ┆ 0.70435  ┆ 0.001         │\n",
       "│ 0.670304 ┆ 0.613519 ┆ 0.654273 ┆ 0.687662 ┆ 0.616345 ┆ 0.671941 ┆ 0.001         │\n",
       "│ 0.658134 ┆ 0.606981 ┆ 0.642408 ┆ 0.695963 ┆ 0.62438  ┆ 0.680245 ┆ 0.001         │\n",
       "│ 0.651583 ┆ 0.603703 ┆ 0.635826 ┆ 0.670734 ┆ 0.603242 ┆ 0.654754 ┆ 0.001         │\n",
       "│ 0.650193 ┆ 0.602461 ┆ 0.634437 ┆ 0.693338 ┆ 0.633178 ┆ 0.678167 ┆ 0.001         │\n",
       "│ …        ┆ …        ┆ …        ┆ …        ┆ …        ┆ …        ┆ …             │\n",
       "│ 0.580292 ┆ 0.567976 ┆ 0.575258 ┆ 0.619839 ┆ 0.585411 ┆ 0.614832 ┆ 0.000031      │\n",
       "│ 0.580261 ┆ 0.567877 ┆ 0.575282 ┆ 0.62281  ┆ 0.586901 ┆ 0.617861 ┆ 0.000031      │\n",
       "│ 0.578901 ┆ 0.566954 ┆ 0.573978 ┆ 0.623231 ┆ 0.587159 ┆ 0.618342 ┆ 0.000031      │\n",
       "│ 0.578956 ┆ 0.567044 ┆ 0.57408  ┆ 0.621133 ┆ 0.586614 ┆ 0.616272 ┆ 0.000016      │\n",
       "│ 0.578518 ┆ 0.566792 ┆ 0.573674 ┆ 0.622389 ┆ 0.588401 ┆ 0.617569 ┆ 0.000016      │\n",
       "└──────────┴──────────┴──────────┴──────────┴──────────┴──────────┴───────────────┘"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.DataFrame(mod.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bef90bef-e23e-422d-a093-b11c07baab6e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'History' object has no attribute 'evaluate'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmod\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevaluate\u001b[49m\n",
      "\u001b[31mAttributeError\u001b[39m: 'History' object has no attribute 'evaluate'"
     ]
    }
   ],
   "source": [
    "mod."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f517689d-f456-47ff-bd9e-67a99a15823d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966d4a8c-2521-49ed-9fc6-91a1040447dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a739d5-0b59-419c-9e15-bfc70186498d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9464e371-038e-4a86-941b-14e0a89bae54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd8c4a8-eafa-40d7-a582-feb1edd298f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf422fc-ea70-44d8-80bc-6abd40f41694",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94eaa403-10c5-42dc-921f-f478c37d2502",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "5f6644aa-a0f7-4a86-a13e-2abfcc2f8da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.1426981]], dtype=float32)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict((X_user[10].reshape(1,-1), X_movie[10].reshape(1,-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "e3d250dc-dc01-4539-bf63-eb82df18f9d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12.24547033,  0.03811556,  1.08235658,  0.        ,  0.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  0.        ,\n",
       "         0.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ]])"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_movie[10].reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "074c3ba9-8cbb-47d8-8672-cc5e605fd6a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'reshape'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[345]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mX_user\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreshape\u001b[49m(\u001b[32m1\u001b[39m,-\u001b[32m1\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'DataFrame' object has no attribute 'reshape'"
     ]
    }
   ],
   "source": [
    "X_user[10].reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "a3c6ae7d-6eef-4c44-8972-70a4cacf6aa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.54627892, -1.66744998,  0.12091797,  0.44143685,  0.46259695,\n",
       "       -0.29703452, -1.59569312, -1.05931267, -2.93611269,  0.26693204,\n",
       "       -0.56776599, -1.25123463, -0.56450595, -0.91585002, -1.27535158,\n",
       "       -1.73221951, -1.31843408, -1.85172194, -1.04109284, -0.77862885])"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_user[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "fee97974-89f1-4b38-b815-a86d66f4a6ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 21)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>userId</th><th>Horror</th><th>Romance</th><th>Thriller</th><th>Drama</th><th>Action</th><th>Musical</th><th>Sci-Fi</th><th>Comedy</th><th>Adventure</th><th>Animation</th><th>Crime</th><th>Fantasy</th><th>Film-Noir</th><th>IMAX</th><th>War</th><th>Documentary</th><th>Mystery</th><th>Western</th><th>Children</th><th>(no genres listed)</th></tr><tr><td>i64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>66699</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.5</td><td>0.0</td><td>0.0</td><td>1.5</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.5</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 21)\n",
       "┌────────┬────────┬─────────┬──────────┬───┬─────────┬─────────┬──────────┬────────────────────┐\n",
       "│ userId ┆ Horror ┆ Romance ┆ Thriller ┆ … ┆ Mystery ┆ Western ┆ Children ┆ (no genres listed) │\n",
       "│ ---    ┆ ---    ┆ ---     ┆ ---      ┆   ┆ ---     ┆ ---     ┆ ---      ┆ ---                │\n",
       "│ i64    ┆ f64    ┆ f64     ┆ f64      ┆   ┆ f64     ┆ f64     ┆ f64      ┆ f64                │\n",
       "╞════════╪════════╪═════════╪══════════╪═══╪═════════╪═════════╪══════════╪════════════════════╡\n",
       "│ 66699  ┆ 0.0    ┆ 0.0     ┆ 0.0      ┆ … ┆ 0.0     ┆ 0.0     ┆ 0.0      ┆ 0.0                │\n",
       "└────────┴────────┴─────────┴──────────┴───┴─────────┴─────────┴──────────┴────────────────────┘"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_feature[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "6b8fad40-0fd2-41e8-a3fc-8c6d378ae75a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 24)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>movieId</th><th>title</th><th>year</th><th>avg_rating</th><th>(no genres listed)</th><th>Action</th><th>Adventure</th><th>Animation</th><th>Children</th><th>Comedy</th><th>Crime</th><th>Documentary</th><th>Drama</th><th>Fantasy</th><th>Film-Noir</th><th>Horror</th><th>IMAX</th><th>Musical</th><th>Mystery</th><th>Romance</th><th>Sci-Fi</th><th>Thriller</th><th>War</th><th>Western</th></tr><tr><td>i64</td><td>str</td><td>i16</td><td>f64</td><td>i8</td><td>i8</td><td>i8</td><td>i8</td><td>i8</td><td>i8</td><td>i8</td><td>i8</td><td>i8</td><td>i8</td><td>i8</td><td>i8</td><td>i8</td><td>i8</td><td>i8</td><td>i8</td><td>i8</td><td>i8</td><td>i8</td><td>i8</td></tr></thead><tbody><tr><td>11</td><td>&quot;American President, The (1995)&quot;</td><td>1995</td><td>3.6875</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 24)\n",
       "┌─────────┬────────────────────────────────┬──────┬────────────┬───┬────────┬──────────┬─────┬─────────┐\n",
       "│ movieId ┆ title                          ┆ year ┆ avg_rating ┆ … ┆ Sci-Fi ┆ Thriller ┆ War ┆ Western │\n",
       "│ ---     ┆ ---                            ┆ ---  ┆ ---        ┆   ┆ ---    ┆ ---      ┆ --- ┆ ---     │\n",
       "│ i64     ┆ str                            ┆ i16  ┆ f64        ┆   ┆ i8     ┆ i8       ┆ i8  ┆ i8      │\n",
       "╞═════════╪════════════════════════════════╪══════╪════════════╪═══╪════════╪══════════╪═════╪═════════╡\n",
       "│ 11      ┆ American President, The (1995) ┆ 1995 ┆ 3.6875     ┆ … ┆ 0      ┆ 0        ┆ 0   ┆ 0       │\n",
       "└─────────┴────────────────────────────────┴──────┴────────────┴───┴────────┴──────────┴─────┴─────────┘"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_features[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "951f47b4-e92f-4163-97fa-a8f336abf896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.2768624]], dtype=float32)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "674980dc-26a0-45b0-9ab2-919451345e71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.2768624]], dtype=float32)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "b69e529a-7165-47a3-be8a-b4fc9771ff5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 20), (1, 20))"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_user[10:11].shape, X_user[10].reshape(1,-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1722e44f-7dd4-4bc3-b89d-76eaa0ee2722",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "d037da4b-0a30-41b4-ac75-1bbeec64eacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = SS_user.inverse_transform(X_user[10:11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "a4d4ab01-eb01-4817-b1da-08c5566241d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0. ,  0. ,  2.5,  2.5,  2.5,  2.5,  0. , -0. ,  0. ,  2.5,  0. ,\n",
       "         0. , -0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ]])"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "1b35510f-d356-4c41-a9d5-ae57c45d1702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.8997e+04, 1.9950e+03, 3.7875e+00]])"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SS_movie.inverse_transform(X_movie[10:11,:3]).round(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "9bbfc064-a7fc-4ec4-84e2-16a3a3153c5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20,), (23,))"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_user[10].shape, X_movie[10].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "65384437-9bee-4e4d-890c-3c25efc6f09e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<zip at 0x218b3213e80>"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip(X_user[10], X_movie[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "fcefdc6a-e473-464e-987f-1e2a88a83044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(582540, 1)"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "85885a99-c2f9-4484-8204-e6fa473ca910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor shape=(None, 32), dtype=float32, sparse=False, ragged=False, name=keras_tensor_30>"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
