{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "566393ff-82bf-460b-b577-53e0fcc1c3d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 785) (10000, 785) (10000, 785)\n",
      "1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((50000, 785), (10000, 785), (10000, 785), (50000, 1), (10000, 1), (10000, 1))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "import joblib\n",
    "from numba import njit\n",
    "\n",
    "x, y = fetch_openml('mnist_784', version=1, return_X_y=True, as_frame= False)\n",
    "\n",
    "y = y.astype(int).reshape(-1,1)\n",
    "y = np.where(y == 5, 1, 0)\n",
    "\n",
    "y = y.reshape(-1,1)\n",
    "\n",
    "data = np.hstack((y, x))\n",
    "\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(data)\n",
    "\n",
    "datatrain = data[:50000]\n",
    "datadev = data[50000:60000]\n",
    "datatest = data[60000:]\n",
    "\n",
    "print(datatrain.shape, datadev.shape, datatest.shape)\n",
    "\n",
    "def feature(df):\n",
    "    return np.hstack((np.ones((df.shape[0],1)), df[:,1:] / 255))\n",
    "\n",
    "def target(data):\n",
    "    y = data[:,0].reshape(-1,1)\n",
    "    return y\n",
    "\n",
    "xtrain, xdev, xtest = tuple(feature(skup) for skup in [datatrain, datadev, datatest])\n",
    "\n",
    "ytrain, ydev, ytest = tuple(target(skup) for skup in [datatrain, datadev, datatest])\n",
    "print(xtrain.max())\n",
    "xtrain.shape, xdev.shape, xtest.shape, ytrain.shape, ydev.shape, ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fa5f885-0aa2-4678-a0a8-d2af003ba6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logit():\n",
    "    \n",
    "    def __init__(self, lr=0.1, regularizacija='', reg=0.01, maxIter=None, nIter = None):      \n",
    "        '''Za regularizaciju uneti string 'l1' ili 'l2'\n",
    "        reg je regularizacioni parametar lambda \n",
    "        learning rate: pocetna brzina ucenja (polovi se na svakih 1000 iteracija) '''\n",
    "        \n",
    "        self.lr = lr\n",
    "        self.regularizacija = regularizacija\n",
    "        self.reg = reg\n",
    "        self.maxIter = maxIter\n",
    "        self.preciznostTrain= None\n",
    "        self.preciznostDev = None\n",
    "        self.historyW = []\n",
    "\n",
    "    def predict(self, x, y =None):\n",
    "        \"\"\"Racuna binarne predikcije za ulazne podatke x.\n",
    "        Ako je prosleđen y, vraća dvojku (preciznost, predikcije).\"\"\"\n",
    "        \n",
    "        z = np.clip(x @ self.w, -500, 500)\n",
    "        p = 1 / (1 + np.exp(-z))\n",
    "        pred = (p > 0.5).astype(int)\n",
    "        if y is not None:\n",
    "            return (np.mean(pred == y.reshape(-1,1)), pred)\n",
    "        else:\n",
    "            return pred\n",
    "    def predictProba(self,x):\n",
    "        \"\"\"Vraca predikcije verovatnoca za ulazne podatke x. \"\"\"\n",
    "        \n",
    "        z = np.clip(x @ self.w, -500, 500)\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "        \n",
    "    def fit(self, x, y, xdev, ydev, randomState = 42):\n",
    "        \"\"\"Treniranje modela koristeći grupni gradijentni spust (batch gradient descent).\n",
    "        Funkcija prati preciznost na trening i dev skupu.\n",
    "        Svakih 100 iteracija se čuvaju trenutne težine u self.historyW.\n",
    "        Ako preciznost na dev skupu opadne u odnosu na \n",
    "        4 evaluacije unazad, smatra se da je dostigao plato i\n",
    "        model se vraca na težine iz te iteracije i vraca\n",
    "        dvojku (preciznost na trening skupu, preciznost na dev skupu).\"\"\"\n",
    "        \n",
    "        m, n = x.shape\n",
    "        np.random.seed(randomState)\n",
    "        self.w = np.random.rand(n,1) - .5\n",
    "        trainscore = []\n",
    "        devscore = [0 for _ in range(4)]\n",
    "        i = 0\n",
    "        lr = self.lr\n",
    "        epsilon=.0000001\n",
    "        \n",
    "        while True:\n",
    "            z = np.clip(x @ self.w, -500, 500)\n",
    "            pred = 1 / (1 + np.exp(-z))\n",
    "            gradijenti = (x.T @ (pred - y.reshape(-1, 1))) / m\n",
    "            \n",
    "            \n",
    "            if self.regularizacija.lower() == 'l1':\n",
    "                l = -np.mean(y * np.log(pred + epsilon) + (1 - y) * np.log(1 - pred + epsilon)) + (self.reg / m) * np.sum(np.abs(self.w[1:]))\n",
    "                gradijenti[1:] += (self.reg / m) * np.sign(self.w[1:])\n",
    "            elif self.regularizacija.lower() == 'l2':\n",
    "                l = -np.mean(y * np.log(pred + epsilon) + (1 - y) * np.log(1 - pred + epsilon)) + (self.reg / (2 * m)) * np.sum(np.square(self.w[1:]))\n",
    "                gradijenti[1:] += (self.reg / m) * self.w[1:]\n",
    "               \n",
    "            else:\n",
    "                l = -np.mean(y * np.log(pred + epsilon) + (1 - y) * np.log(1 - pred + epsilon))\n",
    "\n",
    "            self.w -= lr * gradijenti\n",
    "            grad_norm = np.linalg.norm(gradijenti)\n",
    "            \n",
    "            if i % 100 == 0:\n",
    "                self.historyW.append(self.w.copy())\n",
    "                preciznostTrain, _ = self.predict(x,y)\n",
    "                trainscore.append(preciznostTrain)\n",
    "                \n",
    "                preciznostDev, _ = self.predict(xdev, ydev)\n",
    "                devscore.append(preciznostDev)\n",
    "            \n",
    "            if i > 300 and (devscore[-1] - devscore[-5]) <= 0:\n",
    "                print(f\"Optimalni parametri su iz {i-300} iteracije\")\n",
    "                self.w = self.historyW[-4]\n",
    "                break\n",
    "            \n",
    "            if self.maxIter is not None and i >= self.maxIter:\n",
    "                print(f\"Maksimalan broj iteracija ({self.maxIter}) dostignut.\")\n",
    "                break\n",
    "            \n",
    "            if i % 1000 == 0 and i > 0:\n",
    "                lr *= 0.5\n",
    "                print(f\"Learning rate: {lr}, iteracija {i}\")\n",
    "                \n",
    "\n",
    "            i += 1\n",
    "        self.nIter = i - 300\n",
    "        self.preciznostTrain, _ = self.predict(x,y)\n",
    "        print(\"Preciznost na trening setu:\", self.preciznostTrain)\n",
    "\n",
    "        self.preciznostDev, _ = self.predict(xdev,ydev)\n",
    "        print(\"Preciznost na dev setu:\", self.preciznostDev)\n",
    "        \n",
    "        return self.preciznostTrain, self.preciznostDev\n",
    "\n",
    "    \n",
    "    def fitReg(self, x, y, xdev, ydev, listaRegularizacije):\n",
    "        '''Radi grid search za regularizacioni parametar lambda iz liste\n",
    "        Vraca recnik lokalno optimalnih parametar a{lambda : rezultat na dev skupu} '''\n",
    "        \n",
    "        rezultati = []\n",
    "        for i in range(len(listaRegularizacije)):\n",
    "            self.reg = listaRegularizacije[i]\n",
    "            _, devScore = self.fit(x, y, xdev, ydev)\n",
    "            rezultati.append(devScore)\n",
    "            \n",
    "        self.w = self.historyW[np.argmax(rezultati)]\n",
    "        self.reg = listaRegularizacije[np.argmax(rezultati)]\n",
    "        self.fit(x, y, xdev, ydev)\n",
    "        return {self.reg : rezultati[np.argmax(rezultati)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7eedf2cb-eb88-4472-a472-3af5527c76c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def numba_fit_loop(x, y, w, lr = 0.1, reg = 1, reg_type = 0, num_iterations = 10000, epsilon = 0.0000001):\n",
    "    m = x.shape[0]\n",
    "    for _ in range(num_iterations):\n",
    "        z = x.dot(w)\n",
    "        z = np.clip(z, -500, 500)\n",
    "        pred = 1 / (1 + np.exp(-z))\n",
    "        grad = x.T.dot(pred - y.reshape(-1, 1)) / m\n",
    "        if reg_type == 1:\n",
    "            for j in range(1, w.shape[0]):\n",
    "                if w[j, 0] > 0:\n",
    "                    grad[j, 0] += reg / m\n",
    "                elif w[j, 0] < 0:\n",
    "                    grad[j, 0] -= reg / m\n",
    "        elif reg_type == 2: \n",
    "            for j in range(1, w.shape[0]):\n",
    "                grad[j, 0] += (reg / m) * w[j, 0]\n",
    "        w = w - lr * grad\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "153649a8-63e4-48f8-a896-752329442026",
   "metadata": {},
   "outputs": [],
   "source": [
    "w  = np.random.rand(xtrain.shape[1], 1) - 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5cb4ddf-b06b-4d7f-b466-4928db226f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bogdan.sliskovic\\AppData\\Local\\Temp\\ipykernel_3292\\3052692771.py:5: NumbaPerformanceWarning: \u001b[1m\u001b[1m\u001b[1mnp.dot() is faster on contiguous arrays, called on (Array(float64, 2, 'A', False, aligned=True), Array(float64, 2, 'C', False, aligned=True))\u001b[0m\u001b[0m\u001b[0m\n",
      "  z = x.dot(w)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed (after compilation) = 208.52888459991664s\n"
     ]
    }
   ],
   "source": [
    "start = time.perf_counter()\n",
    "numba_fit_loop(xtrain[:1000], ytrain[:1000])\n",
    "end = time.perf_counter()\n",
    "print(f\"Elapsed (after compilation) = {end - start}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55f1e43a-54da-4db9-a6aa-fdbfd04972bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed (after compilation) = 184.44717329996638s\n"
     ]
    }
   ],
   "source": [
    "start = time.perf_counter()\n",
    "numba_fit_loop(xtrain[:1000], ytrain[:1000])\n",
    "end = time.perf_counter()\n",
    "print(f\"Elapsed (after compilation) = {end - start}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31c6ad6c-7770-46bd-a848-b1fd38e13957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(xtrain.flags['C_CONTIGUOUS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15682bce-054d-46f4-af8c-1eb25e5ff945",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_contig.flags['C_CONTIGUOUS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "958b2f1b-f927-4679-b506-525f97b2bb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_contig = np.ascontiguousarray(xtrain[:1000])\n",
    "y_contig = np.ascontiguousarray(ytrain[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0429eabf-95af-4fc4-b94a-72f49a62d1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.perf_counter()\n",
    "numba_fit_loop(xtrain, ytrain, w)\n",
    "end = time.perf_counter()\n",
    "print(f\"Elapsed (after compilation) = {end - start}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5f6f005-b2b9-4767-97f1-989a929bcf06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 785), (50000, 1))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain.shape, ytrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca37acac-5ee1-465f-bd93-4abd793a35c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = numba_fit_loop(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870666b9-cfe7-4426-a28f-97da2221e859",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.random.rand(xtrain.shape[1], 1) - 0.5\n",
    "start = time.perf_counter()\n",
    "numba_fit_loop(xtrain, ytrain, w, 0.1, 0, 0, 10000, 0.000007)\n",
    "end = time.perf_counter()\n",
    "print(f\"Elapsed (after compilation) = {end - start}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e996d4f9-594b-4937-9dbd-f027b9f4c69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cd3268-a65c-43ee-bc3e-4b7d8e9af5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "start = time.perf_counter()\n",
    "go_fast(x)\n",
    "end = time.perf_counter()\n",
    "print(\"Elapsed (after compilation) = {}s\".format((end - start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22051b1c-b695-4257-ad88-fa911ab16462",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
